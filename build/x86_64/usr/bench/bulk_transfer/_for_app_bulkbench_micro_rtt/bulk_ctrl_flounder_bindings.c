/*
 * Copyright (c) 2010, ETH Zurich.
 * All rights reserved.
 * 
 * INTERFACE NAME: bulk_ctrl
 * INTEFACE FILE: ../if/bulk_ctrl.if
 * INTERFACE DESCRIPTION: bulk control channel interface
 * 
 * This file is distributed under the terms in the attached LICENSE
 * file. If you do not find this file, copies can be found by
 * writing to:
 * ETH Zurich D-INFK, Universitaetstr.6, CH-8092 Zurich.
 * Attn: Systems Group.
 * 
 * THIS FILE IS AUTOMATICALLY GENERATED BY FLOUNDER: DO NOT EDIT!
 */

#include <barrelfish/barrelfish.h>
#include <flounder/flounder_support.h>
#include <if/bulk_ctrl_defs.h>

/*
 * Export function
 */
 errval_t bulk_ctrl_export(void *st, idc_export_callback_fn *export_cb, bulk_ctrl_connect_fn *connect_cb, struct waitset *ws, idc_export_flags_t flags)
{
    struct bulk_ctrl_export *e = malloc(sizeof(struct bulk_ctrl_export ));
    if (e == NULL) {
        return(LIB_ERR_MALLOC_FAIL);
    }
    
    // fill in common parts of export struct
    e->connect_cb = connect_cb;
    e->waitset = ws;
    e->st = st;
    (e->common).export_callback = export_cb;
    (e->common).flags = flags;
    (e->common).connect_cb_st = e;
    (e->common).export_cb_st = st;
    
    // fill in connect handler for each enabled backend
    #ifdef CONFIG_FLOUNDER_BACKEND_LMP
    (e->common).lmp_connect_callback = bulk_ctrl_lmp_connect_handler;
    #endif // CONFIG_FLOUNDER_BACKEND_LMP
    #ifdef CONFIG_FLOUNDER_BACKEND_UMP
    (e->common).ump_connect_callback = bulk_ctrl_ump_connect_handler;
    #endif // CONFIG_FLOUNDER_BACKEND_UMP
    #ifdef CONFIG_FLOUNDER_BACKEND_UMP_IPI
    (e->common).ump_connect_callback = bulk_ctrl_ump_ipi_connect_handler;
    #endif // CONFIG_FLOUNDER_BACKEND_UMP_IPI
    #ifdef CONFIG_FLOUNDER_BACKEND_MULTIHOP
    (e->common).multihop_connect_callback = bulk_ctrl_multihop_connect_handler;
    #endif // CONFIG_FLOUNDER_BACKEND_MULTIHOP
    
    return(idc_export_service(&(e->common)));
}


/*
 * Functions to accept/connect over a already shared frame
 */
 errval_t bulk_ctrl_accept(struct bulk_ctrl_frameinfo *_frameinfo, void *st, bulk_ctrl_bind_continuation_fn *_continuation, struct waitset *ws, idc_export_flags_t flags)
{
    #ifdef CONFIG_FLOUNDER_BACKEND_UMP
    return(bulk_ctrl_ump_accept(_frameinfo, st, _continuation, ws, flags));
    #else
    assert(!("UMP backend not enabled!"));
    return(ERR_NOTIMP);
    #endif // CONFIG_FLOUNDER_BACKEND_UMP
}


/*
 * Generic bind function
 */
static  void bulk_ctrl_bind_continuation_direct(void *st, errval_t err, struct bulk_ctrl_binding *_binding)
{
    // This bind cont function uses the different backends in the following order:
    // lmp ump_ipi ump multihop
    
    struct flounder_generic_bind_attempt *b = st;
    switch (b->driver_num) {
    case 0:
        (b->driver_num)++;
        #ifdef CONFIG_FLOUNDER_BACKEND_LMP
        // try next backend
        b->binding = malloc(sizeof(struct bulk_ctrl_lmp_binding ));
        assert((b->binding) != NULL);
        err = bulk_ctrl_lmp_bind(b->binding, b->iref, bulk_ctrl_bind_continuation_direct, b, b->waitset, b->flags, DEFAULT_LMP_BUF_WORDS);
        if (err_is_fail(err)) {
            free(b->binding);
            _binding = NULL;
            goto out;
        } else {
            return;
        }
        #else
        // skip non-enabled backend (fall through)
        #endif // CONFIG_FLOUNDER_BACKEND_LMP
    case 1:
        #ifdef CONFIG_FLOUNDER_BACKEND_LMP
        if (err_is_ok(err)) {
            goto out;
        } else {
            free(b->binding);
            if (err_no(err) == MON_ERR_IDC_BIND_NOT_SAME_CORE) {
                goto try_next_1;
            } else {
                // report permanent failure to user
                _binding = NULL;
                goto out;
            }
        }
        try_next_1:
        #endif // CONFIG_FLOUNDER_BACKEND_LMP
        (b->driver_num)++;
        #ifdef CONFIG_FLOUNDER_BACKEND_UMP_IPI
        // try next backend
        b->binding = malloc(sizeof(struct bulk_ctrl_ump_ipi_binding ));
        assert((b->binding) != NULL);
        err = bulk_ctrl_ump_ipi_bind(b->binding, b->iref, bulk_ctrl_bind_continuation_direct, b, b->waitset, b->flags, DEFAULT_UMP_BUFLEN, DEFAULT_UMP_BUFLEN);
        if (err_is_fail(err)) {
            free(b->binding);
            _binding = NULL;
            goto out;
        } else {
            return;
        }
        #else
        // skip non-enabled backend (fall through)
        #endif // CONFIG_FLOUNDER_BACKEND_UMP_IPI
    case 2:
        #ifdef CONFIG_FLOUNDER_BACKEND_UMP_IPI
        if (err_is_ok(err)) {
            goto out;
        } else {
            free(b->binding);
            if (true) {
                goto try_next_2;
            } else {
                // report permanent failure to user
                _binding = NULL;
                goto out;
            }
        }
        try_next_2:
        #endif // CONFIG_FLOUNDER_BACKEND_UMP_IPI
        (b->driver_num)++;
        #ifdef CONFIG_FLOUNDER_BACKEND_UMP
        // try next backend
        b->binding = malloc(sizeof(struct bulk_ctrl_ump_binding ));
        assert((b->binding) != NULL);
        err = bulk_ctrl_ump_bind(b->binding, b->iref, bulk_ctrl_bind_continuation_direct, b, b->waitset, b->flags, DEFAULT_UMP_BUFLEN, DEFAULT_UMP_BUFLEN);
        if (err_is_fail(err)) {
            free(b->binding);
            _binding = NULL;
            goto out;
        } else {
            return;
        }
        #else
        // skip non-enabled backend (fall through)
        #endif // CONFIG_FLOUNDER_BACKEND_UMP
    case 3:
        #ifdef CONFIG_FLOUNDER_BACKEND_UMP
        if (err_is_ok(err)) {
            goto out;
        } else {
            free(b->binding);
            if (true) {
                goto try_next_3;
            } else {
                // report permanent failure to user
                _binding = NULL;
                goto out;
            }
        }
        try_next_3:
        #endif // CONFIG_FLOUNDER_BACKEND_UMP
        (b->driver_num)++;
        #ifdef CONFIG_FLOUNDER_BACKEND_MULTIHOP
        // try next backend
        b->binding = malloc(sizeof(struct bulk_ctrl_multihop_binding ));
        assert((b->binding) != NULL);
        err = bulk_ctrl_multihop_bind(b->binding, b->iref, bulk_ctrl_bind_continuation_direct, b, b->waitset, b->flags);
        if (err_is_fail(err)) {
            free(b->binding);
            _binding = NULL;
            goto out;
        } else {
            return;
        }
        #else
        // skip non-enabled backend (fall through)
        #endif // CONFIG_FLOUNDER_BACKEND_MULTIHOP
    case 4:
        #ifdef CONFIG_FLOUNDER_BACKEND_MULTIHOP
        if (err_is_ok(err)) {
            goto out;
        } else {
            free(b->binding);
            if (!true) {
                _binding = NULL;
                goto out;
            }
        }
        #endif // CONFIG_FLOUNDER_BACKEND_MULTIHOP
        err = FLOUNDER_ERR_GENERIC_BIND_NO_MORE_DRIVERS;
        _binding = NULL;
        goto out;
    default:
        assert(!("invalid state"));
    }
    
    out:
    ((bulk_ctrl_bind_continuation_fn *)(b->callback))(b->st, err, _binding);
    free(b);
}

static  void bulk_ctrl_bind_contination_multihop(void *st, errval_t err, struct bulk_ctrl_binding *_binding)
{
    // This bind cont function uses the different backends in the following order:
    // lmp multihop ump_ipi ump
    
    struct flounder_generic_bind_attempt *b = st;
    switch (b->driver_num) {
    case 0:
        (b->driver_num)++;
        #ifdef CONFIG_FLOUNDER_BACKEND_LMP
        // try next backend
        b->binding = malloc(sizeof(struct bulk_ctrl_lmp_binding ));
        assert((b->binding) != NULL);
        err = bulk_ctrl_lmp_bind(b->binding, b->iref, bulk_ctrl_bind_contination_multihop, b, b->waitset, b->flags, DEFAULT_LMP_BUF_WORDS);
        if (err_is_fail(err)) {
            free(b->binding);
            _binding = NULL;
            goto out;
        } else {
            return;
        }
        #else
        // skip non-enabled backend (fall through)
        #endif // CONFIG_FLOUNDER_BACKEND_LMP
    case 1:
        #ifdef CONFIG_FLOUNDER_BACKEND_LMP
        if (err_is_ok(err)) {
            goto out;
        } else {
            free(b->binding);
            if (err_no(err) == MON_ERR_IDC_BIND_NOT_SAME_CORE) {
                goto try_next_1;
            } else {
                // report permanent failure to user
                _binding = NULL;
                goto out;
            }
        }
        try_next_1:
        #endif // CONFIG_FLOUNDER_BACKEND_LMP
        (b->driver_num)++;
        #ifdef CONFIG_FLOUNDER_BACKEND_MULTIHOP
        // try next backend
        b->binding = malloc(sizeof(struct bulk_ctrl_multihop_binding ));
        assert((b->binding) != NULL);
        err = bulk_ctrl_multihop_bind(b->binding, b->iref, bulk_ctrl_bind_contination_multihop, b, b->waitset, b->flags);
        if (err_is_fail(err)) {
            free(b->binding);
            _binding = NULL;
            goto out;
        } else {
            return;
        }
        #else
        // skip non-enabled backend (fall through)
        #endif // CONFIG_FLOUNDER_BACKEND_MULTIHOP
    case 2:
        #ifdef CONFIG_FLOUNDER_BACKEND_MULTIHOP
        if (err_is_ok(err)) {
            goto out;
        } else {
            free(b->binding);
            if (true) {
                goto try_next_2;
            } else {
                // report permanent failure to user
                _binding = NULL;
                goto out;
            }
        }
        try_next_2:
        #endif // CONFIG_FLOUNDER_BACKEND_MULTIHOP
        (b->driver_num)++;
        #ifdef CONFIG_FLOUNDER_BACKEND_UMP_IPI
        // try next backend
        b->binding = malloc(sizeof(struct bulk_ctrl_ump_ipi_binding ));
        assert((b->binding) != NULL);
        err = bulk_ctrl_ump_ipi_bind(b->binding, b->iref, bulk_ctrl_bind_contination_multihop, b, b->waitset, b->flags, DEFAULT_UMP_BUFLEN, DEFAULT_UMP_BUFLEN);
        if (err_is_fail(err)) {
            free(b->binding);
            _binding = NULL;
            goto out;
        } else {
            return;
        }
        #else
        // skip non-enabled backend (fall through)
        #endif // CONFIG_FLOUNDER_BACKEND_UMP_IPI
    case 3:
        #ifdef CONFIG_FLOUNDER_BACKEND_UMP_IPI
        if (err_is_ok(err)) {
            goto out;
        } else {
            free(b->binding);
            if (true) {
                goto try_next_3;
            } else {
                // report permanent failure to user
                _binding = NULL;
                goto out;
            }
        }
        try_next_3:
        #endif // CONFIG_FLOUNDER_BACKEND_UMP_IPI
        (b->driver_num)++;
        #ifdef CONFIG_FLOUNDER_BACKEND_UMP
        // try next backend
        b->binding = malloc(sizeof(struct bulk_ctrl_ump_binding ));
        assert((b->binding) != NULL);
        err = bulk_ctrl_ump_bind(b->binding, b->iref, bulk_ctrl_bind_contination_multihop, b, b->waitset, b->flags, DEFAULT_UMP_BUFLEN, DEFAULT_UMP_BUFLEN);
        if (err_is_fail(err)) {
            free(b->binding);
            _binding = NULL;
            goto out;
        } else {
            return;
        }
        #else
        // skip non-enabled backend (fall through)
        #endif // CONFIG_FLOUNDER_BACKEND_UMP
    case 4:
        #ifdef CONFIG_FLOUNDER_BACKEND_UMP
        if (err_is_ok(err)) {
            goto out;
        } else {
            free(b->binding);
            if (!true) {
                _binding = NULL;
                goto out;
            }
        }
        #endif // CONFIG_FLOUNDER_BACKEND_UMP
        err = FLOUNDER_ERR_GENERIC_BIND_NO_MORE_DRIVERS;
        _binding = NULL;
        goto out;
    default:
        assert(!("invalid state"));
    }
    
    out:
    ((bulk_ctrl_bind_continuation_fn *)(b->callback))(b->st, err, _binding);
    free(b);
}

 errval_t bulk_ctrl_bind(iref_t iref, bulk_ctrl_bind_continuation_fn *_continuation, void *st, struct waitset *waitset, idc_bind_flags_t flags)
{
    // allocate state
    struct flounder_generic_bind_attempt *b = malloc(sizeof(struct flounder_generic_bind_attempt ));
    if (b == NULL) {
        return(LIB_ERR_MALLOC_FAIL);
    }
    
    // fill in binding state
    b->iref = iref;
    b->waitset = waitset;
    b->driver_num = 0;
    b->callback = _continuation;
    b->st = st;
    b->flags = flags;
    
    if (flags & IDC_BIND_FLAG_MULTIHOP) {
        bulk_ctrl_bind_contination_multihop(b, SYS_ERR_OK, NULL);
    } else {
        bulk_ctrl_bind_continuation_direct(b, SYS_ERR_OK, NULL);
    }
    
    return(SYS_ERR_OK);
}

 errval_t bulk_ctrl_connect(struct bulk_ctrl_frameinfo *_frameinfo, bulk_ctrl_bind_continuation_fn *_continuation, void *st, struct waitset *ws, idc_bind_flags_t flags)
{
    #ifdef CONFIG_FLOUNDER_BACKEND_UMP
    return(bulk_ctrl_ump_connect(_frameinfo, _continuation, st, ws, flags));
    #else
    assert(!("UMP backend not enabled!"));
    return(ERR_NOTIMP);
    #endif // CONFIG_FLOUNDER_BACKEND_UMP
}

/*
 * Copyright (c) 2010, ETH Zurich.
 * All rights reserved.
 * 
 * INTERFACE NAME: bulk_ctrl
 * INTEFACE FILE: ../if/bulk_ctrl.if
 * INTERFACE DESCRIPTION: bulk control channel interface
 * 
 * This file is distributed under the terms in the attached LICENSE
 * file. If you do not find this file, copies can be found by
 * writing to:
 * ETH Zurich D-INFK, Universitaetstr.6, CH-8092 Zurich.
 * Attn: Systems Group.
 * 
 * THIS FILE IS AUTOMATICALLY GENERATED BY FLOUNDER: DO NOT EDIT!
 */

/*
 * Generated Stub for LMP on x86_64
 */

#include <string.h>
#include <barrelfish/barrelfish.h>
#include <flounder/flounder_support.h>
#include <flounder/flounder_support_lmp.h>
#include <if/bulk_ctrl_defs.h>

/*
 * Send handler functions
 */
static  void bulk_ctrl_negotiate_call__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send2(&(b->chan), b->flags, NULL_CAP, bulk_ctrl_negotiate_call__msgnum | (((uintptr_t )(((_binding->tx_union).negotiate_call).role)) << 16), ((_binding->tx_union).negotiate_call).trust);
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_negotiate_call__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_negotiate_response__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send4(&(b->chan), b->flags, NULL_CAP, bulk_ctrl_negotiate_response__msgnum | (((uintptr_t )(((_binding->tx_union).negotiate_response).match_direction)) << 16), ((_binding->tx_union).negotiate_response).match_role, ((_binding->tx_union).negotiate_response).error, ((_binding->tx_union).negotiate_response).meta_size);
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_negotiate_response__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_assign_pool_call__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send5(&(b->chan), b->flags, (((_binding->tx_union).assign_pool_call).pool).cap, bulk_ctrl_assign_pool_call__msgnum | (((uintptr_t )((((_binding->tx_union).assign_pool_call).pool).pool_id_machine)) << 16), ((((_binding->tx_union).assign_pool_call).pool).pool_id_dom) | (((uintptr_t )((((_binding->tx_union).assign_pool_call).pool).pool_id_local)) << 32), ((((_binding->tx_union).assign_pool_call).pool).trust) | (((uintptr_t )((((_binding->tx_union).assign_pool_call).pool).buffer_size)) << 32), (((_binding->tx_union).assign_pool_call).pool).num_buffers, ((_binding->tx_union).assign_pool_call).id);
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_assign_pool_call__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_assign_pool_response__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send3(&(b->chan), b->flags, NULL_CAP, bulk_ctrl_assign_pool_response__msgnum, ((_binding->tx_union).assign_pool_response).error, ((_binding->tx_union).assign_pool_response).id);
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_assign_pool_response__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_move_untrusted_call__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send3(&(b->chan), (b->flags) & (~LMP_FLAG_SYNC), ((_binding->tx_union).move_untrusted_call).cap, bulk_ctrl_move_untrusted_call__msgnum | (((uintptr_t )((((_binding->tx_union).move_untrusted_call).poolid).pool_id_machine)) << 16), ((((_binding->tx_union).move_untrusted_call).poolid).pool_id_dom) | (((uintptr_t )((((_binding->tx_union).move_untrusted_call).poolid).pool_id_local)) << 32), (((_binding->tx_union).move_untrusted_call).bufferid) | (((uintptr_t )(((_binding->tx_union).move_untrusted_call).tid)) << 32));
        if (err_is_ok(err)) {
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        } else {
            break;
        }
    case 1:
        err = flounder_stub_lmp_send_buf(&(b->chan), b->flags, ((_binding->tx_union).move_untrusted_call).meta, ((_binding->tx_union).move_untrusted_call).metasize, &(_binding->tx_str_pos));
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_move_untrusted_call__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_move_trusted_call__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send3(&(b->chan), (b->flags) & (~LMP_FLAG_SYNC), NULL_CAP, bulk_ctrl_move_trusted_call__msgnum | (((uintptr_t )((((_binding->tx_union).move_trusted_call).poolid).pool_id_machine)) << 16), ((((_binding->tx_union).move_trusted_call).poolid).pool_id_dom) | (((uintptr_t )((((_binding->tx_union).move_trusted_call).poolid).pool_id_local)) << 32), (((_binding->tx_union).move_trusted_call).bufferid) | (((uintptr_t )(((_binding->tx_union).move_trusted_call).tid)) << 32));
        if (err_is_ok(err)) {
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        } else {
            break;
        }
    case 1:
        err = flounder_stub_lmp_send_buf(&(b->chan), b->flags, ((_binding->tx_union).move_trusted_call).meta, ((_binding->tx_union).move_trusted_call).metasize, &(_binding->tx_str_pos));
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_move_trusted_call__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_move_response__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send2(&(b->chan), b->flags, NULL_CAP, bulk_ctrl_move_response__msgnum | (((uintptr_t )(((_binding->tx_union).move_response).tid)) << 16), ((_binding->tx_union).move_response).error);
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_move_response__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_copy_untrusted_call__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send3(&(b->chan), (b->flags) & (~LMP_FLAG_SYNC), ((_binding->tx_union).copy_untrusted_call).cap, bulk_ctrl_copy_untrusted_call__msgnum | (((uintptr_t )((((_binding->tx_union).copy_untrusted_call).poolid).pool_id_machine)) << 16), ((((_binding->tx_union).copy_untrusted_call).poolid).pool_id_dom) | (((uintptr_t )((((_binding->tx_union).copy_untrusted_call).poolid).pool_id_local)) << 32), (((_binding->tx_union).copy_untrusted_call).bufferid) | (((uintptr_t )(((_binding->tx_union).copy_untrusted_call).tid)) << 32));
        if (err_is_ok(err)) {
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        } else {
            break;
        }
    case 1:
        err = flounder_stub_lmp_send_buf(&(b->chan), b->flags, ((_binding->tx_union).copy_untrusted_call).meta, ((_binding->tx_union).copy_untrusted_call).metasize, &(_binding->tx_str_pos));
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_copy_untrusted_call__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_copy_trusted_call__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send3(&(b->chan), (b->flags) & (~LMP_FLAG_SYNC), NULL_CAP, bulk_ctrl_copy_trusted_call__msgnum | (((uintptr_t )((((_binding->tx_union).copy_trusted_call).poolid).pool_id_machine)) << 16), ((((_binding->tx_union).copy_trusted_call).poolid).pool_id_dom) | (((uintptr_t )((((_binding->tx_union).copy_trusted_call).poolid).pool_id_local)) << 32), (((_binding->tx_union).copy_trusted_call).bufferid) | (((uintptr_t )(((_binding->tx_union).copy_trusted_call).tid)) << 32));
        if (err_is_ok(err)) {
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        } else {
            break;
        }
    case 1:
        err = flounder_stub_lmp_send_buf(&(b->chan), b->flags, ((_binding->tx_union).copy_trusted_call).meta, ((_binding->tx_union).copy_trusted_call).metasize, &(_binding->tx_str_pos));
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_copy_trusted_call__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_copy_response__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send2(&(b->chan), b->flags, NULL_CAP, bulk_ctrl_copy_response__msgnum | (((uintptr_t )(((_binding->tx_union).copy_response).tid)) << 16), ((_binding->tx_union).copy_response).error);
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_copy_response__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_pass_untrusted_call__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send3(&(b->chan), (b->flags) & (~LMP_FLAG_SYNC), ((_binding->tx_union).pass_untrusted_call).cap, bulk_ctrl_pass_untrusted_call__msgnum | (((uintptr_t )((((_binding->tx_union).pass_untrusted_call).poolid).pool_id_machine)) << 16), ((((_binding->tx_union).pass_untrusted_call).poolid).pool_id_dom) | (((uintptr_t )((((_binding->tx_union).pass_untrusted_call).poolid).pool_id_local)) << 32), (((_binding->tx_union).pass_untrusted_call).bufferid) | (((uintptr_t )(((_binding->tx_union).pass_untrusted_call).tid)) << 32));
        if (err_is_ok(err)) {
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        } else {
            break;
        }
    case 1:
        err = flounder_stub_lmp_send_buf(&(b->chan), b->flags, ((_binding->tx_union).pass_untrusted_call).meta, ((_binding->tx_union).pass_untrusted_call).metasize, &(_binding->tx_str_pos));
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_pass_untrusted_call__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_pass_trusted_call__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send3(&(b->chan), (b->flags) & (~LMP_FLAG_SYNC), NULL_CAP, bulk_ctrl_pass_trusted_call__msgnum | (((uintptr_t )((((_binding->tx_union).pass_trusted_call).poolid).pool_id_machine)) << 16), ((((_binding->tx_union).pass_trusted_call).poolid).pool_id_dom) | (((uintptr_t )((((_binding->tx_union).pass_trusted_call).poolid).pool_id_local)) << 32), (((_binding->tx_union).pass_trusted_call).bufferid) | (((uintptr_t )(((_binding->tx_union).pass_trusted_call).tid)) << 32));
        if (err_is_ok(err)) {
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        } else {
            break;
        }
    case 1:
        err = flounder_stub_lmp_send_buf(&(b->chan), b->flags, ((_binding->tx_union).pass_trusted_call).meta, ((_binding->tx_union).pass_trusted_call).metasize, &(_binding->tx_str_pos));
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_pass_trusted_call__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_pass_response__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send2(&(b->chan), b->flags, NULL_CAP, bulk_ctrl_pass_response__msgnum | (((uintptr_t )(((_binding->tx_union).pass_response).tid)) << 16), ((_binding->tx_union).pass_response).error);
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_pass_response__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_release_call__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send3(&(b->chan), b->flags, NULL_CAP, bulk_ctrl_release_call__msgnum | (((uintptr_t )((((_binding->tx_union).release_call).poolid).pool_id_machine)) << 16), ((((_binding->tx_union).release_call).poolid).pool_id_dom) | (((uintptr_t )((((_binding->tx_union).release_call).poolid).pool_id_local)) << 32), (((_binding->tx_union).release_call).bufferid) | (((uintptr_t )(((_binding->tx_union).release_call).tid)) << 32));
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_release_call__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}

static  void bulk_ctrl_release_response__lmp_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        err = lmp_chan_send2(&(b->chan), b->flags, NULL_CAP, bulk_ctrl_release_response__msgnum | (((uintptr_t )(((_binding->tx_union).release_response).tid)) << 16), ((_binding->tx_union).release_response).error);
        if (err_is_ok(err)) {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        } else {
            break;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    if (lmp_err_is_transient(err)) {
        // Construct retry closure and register it
        struct event_closure retry_closure = (struct event_closure){  .handler = bulk_ctrl_release_response__lmp_send_handler,  .arg = arg };
        err = lmp_chan_register_send(&(b->chan), _binding->waitset, retry_closure);
        assert(err_is_ok(err));
    } else {
        // Report error to user
        (_binding->error_handler)(_binding, err);
        _binding->tx_msgnum = 0;
        flounder_support_trigger_chan(&(_binding->register_chanstate));
        flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
    }
}


/*
 * Message sender functions
 */
static  errval_t bulk_ctrl_negotiate_call__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_role_t role, bulk_ctrl_trust_t trust)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_negotiate_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).negotiate_call).role = role;
    ((_binding->tx_union).negotiate_call).trust = trust;
    FL_DEBUG("lmp TX bulk_ctrl.negotiate_call\n");
    
    // try to send!
    bulk_ctrl_negotiate_call__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_negotiate_response__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, bulk_ctrl_direction_t match_direction, bulk_ctrl_role_t match_role, uint64_t meta_size)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_negotiate_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).negotiate_response).error = error;
    ((_binding->tx_union).negotiate_response).match_direction = match_direction;
    ((_binding->tx_union).negotiate_response).match_role = match_role;
    ((_binding->tx_union).negotiate_response).meta_size = meta_size;
    FL_DEBUG("lmp TX bulk_ctrl.negotiate_response\n");
    
    // try to send!
    bulk_ctrl_negotiate_response__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_assign_pool_call__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_pool_t pool, uint64_t id)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_assign_pool_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).assign_pool_call).pool = pool;
    ((_binding->tx_union).assign_pool_call).id = id;
    FL_DEBUG("lmp TX bulk_ctrl.assign_pool_call\n");
    
    // try to send!
    bulk_ctrl_assign_pool_call__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_assign_pool_response__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint64_t id)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_assign_pool_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).assign_pool_response).error = error;
    ((_binding->tx_union).assign_pool_response).id = id;
    FL_DEBUG("lmp TX bulk_ctrl.assign_pool_response\n");
    
    // try to send!
    bulk_ctrl_assign_pool_response__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_move_untrusted_call__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, struct capref cap, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_move_untrusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).move_untrusted_call).poolid = poolid;
    ((_binding->tx_union).move_untrusted_call).bufferid = bufferid;
    ((_binding->tx_union).move_untrusted_call).tid = tid;
    ((_binding->tx_union).move_untrusted_call).cap = cap;
    ((_binding->tx_union).move_untrusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).move_untrusted_call).metasize = metasize;
    FL_DEBUG("lmp TX bulk_ctrl.move_untrusted_call\n");
    
    // try to send!
    bulk_ctrl_move_untrusted_call__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_move_trusted_call__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_move_trusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).move_trusted_call).poolid = poolid;
    ((_binding->tx_union).move_trusted_call).bufferid = bufferid;
    ((_binding->tx_union).move_trusted_call).tid = tid;
    ((_binding->tx_union).move_trusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).move_trusted_call).metasize = metasize;
    FL_DEBUG("lmp TX bulk_ctrl.move_trusted_call\n");
    
    // try to send!
    bulk_ctrl_move_trusted_call__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_move_response__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_move_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).move_response).error = error;
    ((_binding->tx_union).move_response).tid = tid;
    FL_DEBUG("lmp TX bulk_ctrl.move_response\n");
    
    // try to send!
    bulk_ctrl_move_response__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_copy_untrusted_call__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, struct capref cap, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_copy_untrusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).copy_untrusted_call).poolid = poolid;
    ((_binding->tx_union).copy_untrusted_call).bufferid = bufferid;
    ((_binding->tx_union).copy_untrusted_call).tid = tid;
    ((_binding->tx_union).copy_untrusted_call).cap = cap;
    ((_binding->tx_union).copy_untrusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).copy_untrusted_call).metasize = metasize;
    FL_DEBUG("lmp TX bulk_ctrl.copy_untrusted_call\n");
    
    // try to send!
    bulk_ctrl_copy_untrusted_call__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_copy_trusted_call__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_copy_trusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).copy_trusted_call).poolid = poolid;
    ((_binding->tx_union).copy_trusted_call).bufferid = bufferid;
    ((_binding->tx_union).copy_trusted_call).tid = tid;
    ((_binding->tx_union).copy_trusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).copy_trusted_call).metasize = metasize;
    FL_DEBUG("lmp TX bulk_ctrl.copy_trusted_call\n");
    
    // try to send!
    bulk_ctrl_copy_trusted_call__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_copy_response__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_copy_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).copy_response).error = error;
    ((_binding->tx_union).copy_response).tid = tid;
    FL_DEBUG("lmp TX bulk_ctrl.copy_response\n");
    
    // try to send!
    bulk_ctrl_copy_response__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_pass_untrusted_call__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, struct capref cap, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_pass_untrusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).pass_untrusted_call).poolid = poolid;
    ((_binding->tx_union).pass_untrusted_call).bufferid = bufferid;
    ((_binding->tx_union).pass_untrusted_call).tid = tid;
    ((_binding->tx_union).pass_untrusted_call).cap = cap;
    ((_binding->tx_union).pass_untrusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).pass_untrusted_call).metasize = metasize;
    FL_DEBUG("lmp TX bulk_ctrl.pass_untrusted_call\n");
    
    // try to send!
    bulk_ctrl_pass_untrusted_call__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_pass_trusted_call__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_pass_trusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).pass_trusted_call).poolid = poolid;
    ((_binding->tx_union).pass_trusted_call).bufferid = bufferid;
    ((_binding->tx_union).pass_trusted_call).tid = tid;
    ((_binding->tx_union).pass_trusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).pass_trusted_call).metasize = metasize;
    FL_DEBUG("lmp TX bulk_ctrl.pass_trusted_call\n");
    
    // try to send!
    bulk_ctrl_pass_trusted_call__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_pass_response__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_pass_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).pass_response).error = error;
    ((_binding->tx_union).pass_response).tid = tid;
    FL_DEBUG("lmp TX bulk_ctrl.pass_response\n");
    
    // try to send!
    bulk_ctrl_pass_response__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_release_call__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_release_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).release_call).poolid = poolid;
    ((_binding->tx_union).release_call).bufferid = bufferid;
    ((_binding->tx_union).release_call).tid = tid;
    FL_DEBUG("lmp TX bulk_ctrl.release_call\n");
    
    // try to send!
    bulk_ctrl_release_call__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_release_response__lmp_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_release_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).release_response).error = error;
    ((_binding->tx_union).release_response).tid = tid;
    FL_DEBUG("lmp TX bulk_ctrl.release_response\n");
    
    // try to send!
    bulk_ctrl_release_response__lmp_send_handler(_binding);
    
    return(SYS_ERR_OK);
}


/*
 * Send vtable
 */
static  struct bulk_ctrl_tx_vtbl bulk_ctrl_lmp_tx_vtbl = {
    .negotiate_call = bulk_ctrl_negotiate_call__lmp_send,
    .negotiate_response = bulk_ctrl_negotiate_response__lmp_send,
    .assign_pool_call = bulk_ctrl_assign_pool_call__lmp_send,
    .assign_pool_response = bulk_ctrl_assign_pool_response__lmp_send,
    .move_untrusted_call = bulk_ctrl_move_untrusted_call__lmp_send,
    .move_trusted_call = bulk_ctrl_move_trusted_call__lmp_send,
    .move_response = bulk_ctrl_move_response__lmp_send,
    .copy_untrusted_call = bulk_ctrl_copy_untrusted_call__lmp_send,
    .copy_trusted_call = bulk_ctrl_copy_trusted_call__lmp_send,
    .copy_response = bulk_ctrl_copy_response__lmp_send,
    .pass_untrusted_call = bulk_ctrl_pass_untrusted_call__lmp_send,
    .pass_trusted_call = bulk_ctrl_pass_trusted_call__lmp_send,
    .pass_response = bulk_ctrl_pass_response__lmp_send,
    .release_call = bulk_ctrl_release_call__lmp_send,
    .release_response = bulk_ctrl_release_response__lmp_send,
};
/*
 * Receive handler
 */
 void bulk_ctrl_lmp_rx_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_lmp_binding *b = arg;
    errval_t err;
    
    struct lmp_recv_msg msg = LMP_RECV_MSG_INIT;
    struct capref cap;
    struct event_closure recv_closure = (struct event_closure){  .handler = bulk_ctrl_lmp_rx_handler,  .arg = arg };
    
    do {
        // try to retrieve a message from the channel
        err = lmp_chan_recv(&(b->chan), &msg, &cap);
        // check if we succeeded
        if (err_is_fail(err)) {
            if (err_no(err) == LIB_ERR_NO_LMP_MSG) {
                // no message
                break;
            } else {
                // real error
                (_binding->error_handler)(_binding, err_push(err, LIB_ERR_LMP_CHAN_RECV));
                return;
            }
        }
        
        // allocate a new receive slot if needed
        if (!capref_is_null(cap)) {
            err = lmp_chan_alloc_recv_slot(&(b->chan));
            if (err_is_fail(err)) {
                (_binding->error_handler)(_binding, err_push(err, LIB_ERR_LMP_ALLOC_RECV_SLOT));
            }
        }
        
        // is this the start of a new message?
        if ((_binding->rx_msgnum) == 0) {
            // check message length
            if (((msg.buf).msglen) == 0) {
                (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_EMPTY_MSG);
                break;
            }
            // unmarshall message number from first word, set fragment to 0
            _binding->rx_msgnum = (((msg.words)[0]) & 0xffff);
            _binding->rx_msg_fragment = 0;
        }
        
        // switch on message number and fragment number
        switch (_binding->rx_msgnum) {
        case bulk_ctrl_negotiate_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                ((_binding->rx_union).negotiate_call).role = ((((msg.words)[0]) >> 16) & 0xffffffff);
                ((_binding->rx_union).negotiate_call).trust = (((msg.words)[1]) & 0xffffffff);
                
                FL_DEBUG("lmp RX bulk_ctrl.negotiate_call\n");
                assert(((_binding->rx_vtbl).negotiate_call) != NULL);
                ((_binding->rx_vtbl).negotiate_call)(_binding, ((_binding->rx_union).negotiate_call).role, ((_binding->rx_union).negotiate_call).trust);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_negotiate_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) != 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                ((_binding->rx_union).negotiate_response).match_direction = ((((msg.words)[0]) >> 16) & 0xffffffff);
                ((_binding->rx_union).negotiate_response).match_role = (((msg.words)[1]) & 0xffffffff);
                ((_binding->rx_union).negotiate_response).error = ((msg.words)[2]);
                ((_binding->rx_union).negotiate_response).meta_size = ((msg.words)[3]);
                
                FL_DEBUG("lmp RX bulk_ctrl.negotiate_response\n");
                assert(((_binding->rx_vtbl).negotiate_response) != NULL);
                ((_binding->rx_vtbl).negotiate_response)(_binding, ((_binding->rx_union).negotiate_response).error, ((_binding->rx_union).negotiate_response).match_direction, ((_binding->rx_union).negotiate_response).match_role, ((_binding->rx_union).negotiate_response).meta_size);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_assign_pool_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) != 5) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                (((_binding->rx_union).assign_pool_call).pool).pool_id_machine = ((((msg.words)[0]) >> 16) & 0xffffffff);
                (((_binding->rx_union).assign_pool_call).pool).pool_id_dom = (((msg.words)[1]) & 0xffffffff);
                (((_binding->rx_union).assign_pool_call).pool).pool_id_local = ((((msg.words)[1]) >> 32) & 0xffffffff);
                (((_binding->rx_union).assign_pool_call).pool).trust = (((msg.words)[2]) & 0xffffffff);
                (((_binding->rx_union).assign_pool_call).pool).buffer_size = ((((msg.words)[2]) >> 32) & 0xffffffff);
                (((_binding->rx_union).assign_pool_call).pool).num_buffers = (((msg.words)[3]) & 0xffffffff);
                ((_binding->rx_union).assign_pool_call).id = ((msg.words)[4]);
                (((_binding->rx_union).assign_pool_call).pool).cap = cap;
                
                FL_DEBUG("lmp RX bulk_ctrl.assign_pool_call\n");
                assert(((_binding->rx_vtbl).assign_pool_call) != NULL);
                ((_binding->rx_vtbl).assign_pool_call)(_binding, ((_binding->rx_union).assign_pool_call).pool, ((_binding->rx_union).assign_pool_call).id);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_assign_pool_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                ((_binding->rx_union).assign_pool_response).error = ((msg.words)[1]);
                ((_binding->rx_union).assign_pool_response).id = ((msg.words)[2]);
                
                FL_DEBUG("lmp RX bulk_ctrl.assign_pool_response\n");
                assert(((_binding->rx_vtbl).assign_pool_response) != NULL);
                ((_binding->rx_vtbl).assign_pool_response)(_binding, ((_binding->rx_union).assign_pool_response).error, ((_binding->rx_union).assign_pool_response).id);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_move_untrusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                (((_binding->rx_union).move_untrusted_call).poolid).pool_id_machine = ((((msg.words)[0]) >> 16) & 0xffffffff);
                (((_binding->rx_union).move_untrusted_call).poolid).pool_id_dom = (((msg.words)[1]) & 0xffffffff);
                (((_binding->rx_union).move_untrusted_call).poolid).pool_id_local = ((((msg.words)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).move_untrusted_call).bufferid = (((msg.words)[2]) & 0xffffffff);
                ((_binding->rx_union).move_untrusted_call).tid = ((((msg.words)[2]) >> 32) & 0xffffffff);
                ((_binding->rx_union).move_untrusted_call).cap = cap;
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_lmp_recv_buf(&msg, (void **)(&(((_binding->rx_union).move_untrusted_call).meta)), &(((_binding->rx_union).move_untrusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    FL_DEBUG("lmp RX bulk_ctrl.move_untrusted_call\n");
                    assert(((_binding->rx_vtbl).move_untrusted_call) != NULL);
                    ((_binding->rx_vtbl).move_untrusted_call)(_binding, ((_binding->rx_union).move_untrusted_call).poolid, ((_binding->rx_union).move_untrusted_call).bufferid, ((_binding->rx_union).move_untrusted_call).tid, ((_binding->rx_union).move_untrusted_call).cap, ((_binding->rx_union).move_untrusted_call).meta, ((_binding->rx_union).move_untrusted_call).metasize);
                    _binding->rx_msgnum = 0;
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_move_trusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                (((_binding->rx_union).move_trusted_call).poolid).pool_id_machine = ((((msg.words)[0]) >> 16) & 0xffffffff);
                (((_binding->rx_union).move_trusted_call).poolid).pool_id_dom = (((msg.words)[1]) & 0xffffffff);
                (((_binding->rx_union).move_trusted_call).poolid).pool_id_local = ((((msg.words)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).move_trusted_call).bufferid = (((msg.words)[2]) & 0xffffffff);
                ((_binding->rx_union).move_trusted_call).tid = ((((msg.words)[2]) >> 32) & 0xffffffff);
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_lmp_recv_buf(&msg, (void **)(&(((_binding->rx_union).move_trusted_call).meta)), &(((_binding->rx_union).move_trusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    FL_DEBUG("lmp RX bulk_ctrl.move_trusted_call\n");
                    assert(((_binding->rx_vtbl).move_trusted_call) != NULL);
                    ((_binding->rx_vtbl).move_trusted_call)(_binding, ((_binding->rx_union).move_trusted_call).poolid, ((_binding->rx_union).move_trusted_call).bufferid, ((_binding->rx_union).move_trusted_call).tid, ((_binding->rx_union).move_trusted_call).meta, ((_binding->rx_union).move_trusted_call).metasize);
                    _binding->rx_msgnum = 0;
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_move_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                ((_binding->rx_union).move_response).tid = ((((msg.words)[0]) >> 16) & 0xffffffff);
                ((_binding->rx_union).move_response).error = ((msg.words)[1]);
                
                FL_DEBUG("lmp RX bulk_ctrl.move_response\n");
                assert(((_binding->rx_vtbl).move_response) != NULL);
                ((_binding->rx_vtbl).move_response)(_binding, ((_binding->rx_union).move_response).error, ((_binding->rx_union).move_response).tid);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_copy_untrusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                (((_binding->rx_union).copy_untrusted_call).poolid).pool_id_machine = ((((msg.words)[0]) >> 16) & 0xffffffff);
                (((_binding->rx_union).copy_untrusted_call).poolid).pool_id_dom = (((msg.words)[1]) & 0xffffffff);
                (((_binding->rx_union).copy_untrusted_call).poolid).pool_id_local = ((((msg.words)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).copy_untrusted_call).bufferid = (((msg.words)[2]) & 0xffffffff);
                ((_binding->rx_union).copy_untrusted_call).tid = ((((msg.words)[2]) >> 32) & 0xffffffff);
                ((_binding->rx_union).copy_untrusted_call).cap = cap;
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_lmp_recv_buf(&msg, (void **)(&(((_binding->rx_union).copy_untrusted_call).meta)), &(((_binding->rx_union).copy_untrusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    FL_DEBUG("lmp RX bulk_ctrl.copy_untrusted_call\n");
                    assert(((_binding->rx_vtbl).copy_untrusted_call) != NULL);
                    ((_binding->rx_vtbl).copy_untrusted_call)(_binding, ((_binding->rx_union).copy_untrusted_call).poolid, ((_binding->rx_union).copy_untrusted_call).bufferid, ((_binding->rx_union).copy_untrusted_call).tid, ((_binding->rx_union).copy_untrusted_call).cap, ((_binding->rx_union).copy_untrusted_call).meta, ((_binding->rx_union).copy_untrusted_call).metasize);
                    _binding->rx_msgnum = 0;
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_copy_trusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                (((_binding->rx_union).copy_trusted_call).poolid).pool_id_machine = ((((msg.words)[0]) >> 16) & 0xffffffff);
                (((_binding->rx_union).copy_trusted_call).poolid).pool_id_dom = (((msg.words)[1]) & 0xffffffff);
                (((_binding->rx_union).copy_trusted_call).poolid).pool_id_local = ((((msg.words)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).copy_trusted_call).bufferid = (((msg.words)[2]) & 0xffffffff);
                ((_binding->rx_union).copy_trusted_call).tid = ((((msg.words)[2]) >> 32) & 0xffffffff);
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_lmp_recv_buf(&msg, (void **)(&(((_binding->rx_union).copy_trusted_call).meta)), &(((_binding->rx_union).copy_trusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    FL_DEBUG("lmp RX bulk_ctrl.copy_trusted_call\n");
                    assert(((_binding->rx_vtbl).copy_trusted_call) != NULL);
                    ((_binding->rx_vtbl).copy_trusted_call)(_binding, ((_binding->rx_union).copy_trusted_call).poolid, ((_binding->rx_union).copy_trusted_call).bufferid, ((_binding->rx_union).copy_trusted_call).tid, ((_binding->rx_union).copy_trusted_call).meta, ((_binding->rx_union).copy_trusted_call).metasize);
                    _binding->rx_msgnum = 0;
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_copy_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                ((_binding->rx_union).copy_response).tid = ((((msg.words)[0]) >> 16) & 0xffffffff);
                ((_binding->rx_union).copy_response).error = ((msg.words)[1]);
                
                FL_DEBUG("lmp RX bulk_ctrl.copy_response\n");
                assert(((_binding->rx_vtbl).copy_response) != NULL);
                ((_binding->rx_vtbl).copy_response)(_binding, ((_binding->rx_union).copy_response).error, ((_binding->rx_union).copy_response).tid);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_pass_untrusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                (((_binding->rx_union).pass_untrusted_call).poolid).pool_id_machine = ((((msg.words)[0]) >> 16) & 0xffffffff);
                (((_binding->rx_union).pass_untrusted_call).poolid).pool_id_dom = (((msg.words)[1]) & 0xffffffff);
                (((_binding->rx_union).pass_untrusted_call).poolid).pool_id_local = ((((msg.words)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).pass_untrusted_call).bufferid = (((msg.words)[2]) & 0xffffffff);
                ((_binding->rx_union).pass_untrusted_call).tid = ((((msg.words)[2]) >> 32) & 0xffffffff);
                ((_binding->rx_union).pass_untrusted_call).cap = cap;
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_lmp_recv_buf(&msg, (void **)(&(((_binding->rx_union).pass_untrusted_call).meta)), &(((_binding->rx_union).pass_untrusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    FL_DEBUG("lmp RX bulk_ctrl.pass_untrusted_call\n");
                    assert(((_binding->rx_vtbl).pass_untrusted_call) != NULL);
                    ((_binding->rx_vtbl).pass_untrusted_call)(_binding, ((_binding->rx_union).pass_untrusted_call).poolid, ((_binding->rx_union).pass_untrusted_call).bufferid, ((_binding->rx_union).pass_untrusted_call).tid, ((_binding->rx_union).pass_untrusted_call).cap, ((_binding->rx_union).pass_untrusted_call).meta, ((_binding->rx_union).pass_untrusted_call).metasize);
                    _binding->rx_msgnum = 0;
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_pass_trusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                (((_binding->rx_union).pass_trusted_call).poolid).pool_id_machine = ((((msg.words)[0]) >> 16) & 0xffffffff);
                (((_binding->rx_union).pass_trusted_call).poolid).pool_id_dom = (((msg.words)[1]) & 0xffffffff);
                (((_binding->rx_union).pass_trusted_call).poolid).pool_id_local = ((((msg.words)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).pass_trusted_call).bufferid = (((msg.words)[2]) & 0xffffffff);
                ((_binding->rx_union).pass_trusted_call).tid = ((((msg.words)[2]) >> 32) & 0xffffffff);
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_lmp_recv_buf(&msg, (void **)(&(((_binding->rx_union).pass_trusted_call).meta)), &(((_binding->rx_union).pass_trusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    FL_DEBUG("lmp RX bulk_ctrl.pass_trusted_call\n");
                    assert(((_binding->rx_vtbl).pass_trusted_call) != NULL);
                    ((_binding->rx_vtbl).pass_trusted_call)(_binding, ((_binding->rx_union).pass_trusted_call).poolid, ((_binding->rx_union).pass_trusted_call).bufferid, ((_binding->rx_union).pass_trusted_call).tid, ((_binding->rx_union).pass_trusted_call).meta, ((_binding->rx_union).pass_trusted_call).metasize);
                    _binding->rx_msgnum = 0;
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_pass_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                ((_binding->rx_union).pass_response).tid = ((((msg.words)[0]) >> 16) & 0xffffffff);
                ((_binding->rx_union).pass_response).error = ((msg.words)[1]);
                
                FL_DEBUG("lmp RX bulk_ctrl.pass_response\n");
                assert(((_binding->rx_vtbl).pass_response) != NULL);
                ((_binding->rx_vtbl).pass_response)(_binding, ((_binding->rx_union).pass_response).error, ((_binding->rx_union).pass_response).tid);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_release_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                (((_binding->rx_union).release_call).poolid).pool_id_machine = ((((msg.words)[0]) >> 16) & 0xffffffff);
                (((_binding->rx_union).release_call).poolid).pool_id_dom = (((msg.words)[1]) & 0xffffffff);
                (((_binding->rx_union).release_call).poolid).pool_id_local = ((((msg.words)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).release_call).bufferid = (((msg.words)[2]) & 0xffffffff);
                ((_binding->rx_union).release_call).tid = ((((msg.words)[2]) >> 32) & 0xffffffff);
                
                FL_DEBUG("lmp RX bulk_ctrl.release_call\n");
                assert(((_binding->rx_vtbl).release_call) != NULL);
                ((_binding->rx_vtbl).release_call)(_binding, ((_binding->rx_union).release_call).poolid, ((_binding->rx_union).release_call).bufferid, ((_binding->rx_union).release_call).tid);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_release_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                // check length
                if (((msg.buf).msglen) > 4) {
                    (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_LENGTH);
                    goto out;
                }
                
                ((_binding->rx_union).release_response).tid = ((((msg.words)[0]) >> 16) & 0xffffffff);
                ((_binding->rx_union).release_response).error = ((msg.words)[1]);
                
                FL_DEBUG("lmp RX bulk_ctrl.release_response\n");
                assert(((_binding->rx_vtbl).release_response) != NULL);
                ((_binding->rx_vtbl).release_response)(_binding, ((_binding->rx_union).release_response).error, ((_binding->rx_union).release_response).tid);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        default:
            (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_MSGNUM);
            goto out;
        }
    } while (err_is_ok(err));
    out:
    // re-register for another receive notification
    err = lmp_chan_register_recv(&(b->chan), _binding->waitset, recv_closure);
    assert(err_is_ok(err));
}


/*
 * Control functions
 */
static  bool bulk_ctrl_lmp_can_send(struct bulk_ctrl_binding *b)
{
    return((b->tx_msgnum) == 0);
}

static  errval_t bulk_ctrl_lmp_register_send(struct bulk_ctrl_binding *b, struct waitset *ws, struct event_closure _continuation)
{
    return(flounder_support_register(ws, &(b->register_chanstate), _continuation, bulk_ctrl_lmp_can_send(b)));
}

static  void bulk_ctrl_lmp_default_error_handler(struct bulk_ctrl_binding *b, errval_t err)
{
    DEBUG_ERR(err, "asynchronous error in Flounder-generated bulk_ctrl lmp binding (default handler)");
    abort();
}

static  errval_t bulk_ctrl_lmp_change_waitset(struct bulk_ctrl_binding *_binding, struct waitset *ws)
{
    struct bulk_ctrl_lmp_binding *b = (void *)(_binding);
    
    // Migrate register and TX continuation notifications
    flounder_support_migrate_notify(&(_binding->register_chanstate), ws);
    flounder_support_migrate_notify(&(_binding->tx_cont_chanstate), ws);
    
    // change waitset on binding
    _binding->waitset = ws;
    
    // Migrate send and receive notifications
    lmp_chan_migrate_recv(&(b->chan), ws);
    lmp_chan_migrate_send(&(b->chan), ws);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_lmp_control(struct bulk_ctrl_binding *_binding, idc_control_t control)
{
    struct bulk_ctrl_lmp_binding *b = (void *)(_binding);
    
    b->flags = idc_control_to_lmp_flags(control, b->flags);
    
    return(SYS_ERR_OK);
}

/*
 * Functions to initialise/destroy the binding state
 */
 void bulk_ctrl_lmp_init(struct bulk_ctrl_lmp_binding *b, struct waitset *waitset)
{
    (b->b).st = NULL;
    (b->b).waitset = waitset;
    event_mutex_init(&((b->b).mutex), waitset);
    (b->b).can_send = bulk_ctrl_lmp_can_send;
    (b->b).register_send = bulk_ctrl_lmp_register_send;
    (b->b).error_handler = bulk_ctrl_lmp_default_error_handler;
    (b->b).tx_vtbl = bulk_ctrl_lmp_tx_vtbl;
    memset(&((b->b).rx_vtbl), 0, sizeof((b->b).rx_vtbl));
    flounder_support_waitset_chanstate_init(&((b->b).register_chanstate));
    flounder_support_waitset_chanstate_init(&((b->b).tx_cont_chanstate));
    (b->b).tx_msgnum = 0;
    (b->b).rx_msgnum = 0;
    (b->b).tx_msg_fragment = 0;
    (b->b).rx_msg_fragment = 0;
    (b->b).tx_str_pos = 0;
    (b->b).rx_str_pos = 0;
    (b->b).tx_str_len = 0;
    (b->b).rx_str_len = 0;
    (b->b).bind_cont = NULL;
    lmp_chan_init(&(b->chan));
    (b->b).change_waitset = bulk_ctrl_lmp_change_waitset;
    (b->b).control = bulk_ctrl_lmp_control;
    b->flags = LMP_SEND_FLAGS_DEFAULT;
}

 void bulk_ctrl_lmp_destroy(struct bulk_ctrl_lmp_binding *b)
{
    flounder_support_waitset_chanstate_destroy(&((b->b).register_chanstate));
    flounder_support_waitset_chanstate_destroy(&((b->b).tx_cont_chanstate));
    lmp_chan_destroy(&(b->chan));
}


/*
 * Bind function
 */
static  void bulk_ctrl_lmp_bind_continuation(void *st, errval_t err, struct lmp_chan *chan)
{
    struct bulk_ctrl_lmp_binding *b = st;
    
    if (err_is_ok(err)) {
        // allocate a cap receive slot
        err = lmp_chan_alloc_recv_slot(chan);
        if (err_is_fail(err)) {
            err = err_push(err, LIB_ERR_LMP_ALLOC_RECV_SLOT);
            goto fail;
        }
        
        // register for receive
        err = lmp_chan_register_recv(chan, (b->b).waitset, (struct event_closure){  .handler = bulk_ctrl_lmp_rx_handler,  .arg = b });
        if (err_is_fail(err)) {
            err = err_push(err, LIB_ERR_CHAN_REGISTER_RECV);
            goto fail;
        }
    } else {
        fail:
        bulk_ctrl_lmp_destroy(b);
    }
    
    ((b->b).bind_cont)((b->b).st, err, &(b->b));
}

 errval_t bulk_ctrl_lmp_bind(struct bulk_ctrl_lmp_binding *b, iref_t iref, bulk_ctrl_bind_continuation_fn *_continuation, void *st, struct waitset *waitset, idc_bind_flags_t flags, size_t lmp_buflen)
{
    errval_t err;
    bulk_ctrl_lmp_init(b, waitset);
    (b->b).st = st;
    (b->b).bind_cont = _continuation;
    err = lmp_chan_bind(&(b->chan), (struct lmp_bind_continuation){  .handler = bulk_ctrl_lmp_bind_continuation,  .st = b }, &((b->b).event_qnode), iref, lmp_buflen);
    if (err_is_fail(err)) {
        bulk_ctrl_lmp_destroy(b);
    }
    return(err);
}


/*
 * Connect callback for export
 */
 errval_t bulk_ctrl_lmp_connect_handler(void *st, size_t buflen_words, struct capref endpoint, struct lmp_chan **retchan)
{
    struct bulk_ctrl_export *e = st;
    errval_t err;
    
    // allocate storage for binding
    struct bulk_ctrl_lmp_binding *b = malloc(sizeof(struct bulk_ctrl_lmp_binding ));
    if (b == NULL) {
        return(LIB_ERR_MALLOC_FAIL);
    }
    
    struct bulk_ctrl_binding *_binding = &(b->b);
    bulk_ctrl_lmp_init(b, e->waitset);
    
    // run user's connect handler
    assert(e->connect_cb);
    err = ((e->connect_cb)(e->st, _binding));
    if (err_is_fail(err)) {
        // connection refused
        bulk_ctrl_lmp_destroy(b);
        return(err);
    }
    
    // accept the connection and setup the channel
    // FIXME: user policy needed to decide on the size of the message buffer?
    err = lmp_chan_accept(&(b->chan), buflen_words, endpoint);
    if (err_is_fail(err)) {
        err = err_push(err, LIB_ERR_LMP_CHAN_ACCEPT);
        (_binding->error_handler)(_binding, err);
        return(err);
    }
    
    // allocate a cap receive slot
    err = lmp_chan_alloc_recv_slot(&(b->chan));
    if (err_is_fail(err)) {
        err = err_push(err, LIB_ERR_LMP_ALLOC_RECV_SLOT);
        (_binding->error_handler)(_binding, err);
        return(err);
    }
    
    // register for receive
    err = lmp_chan_register_recv(&(b->chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_lmp_rx_handler,  .arg = b });
    if (err_is_fail(err)) {
        err = err_push(err, LIB_ERR_CHAN_REGISTER_RECV);
        (_binding->error_handler)(_binding, err);
        return(err);
    }
    
    *retchan = (&(b->chan));
    
    return(SYS_ERR_OK);
}

/*
 * Copyright (c) 2010, ETH Zurich.
 * All rights reserved.
 * 
 * INTERFACE NAME: bulk_ctrl
 * INTEFACE FILE: ../if/bulk_ctrl.if
 * INTERFACE DESCRIPTION: bulk control channel interface
 * 
 * This file is distributed under the terms in the attached LICENSE
 * file. If you do not find this file, copies can be found by
 * writing to:
 * ETH Zurich D-INFK, Universitaetstr.6, CH-8092 Zurich.
 * Attn: Systems Group.
 * 
 * THIS FILE IS AUTOMATICALLY GENERATED BY FLOUNDER: DO NOT EDIT!
 */

#ifdef CONFIG_FLOUNDER_BACKEND_UMP

/*
 * Generated Stub for UMP
 */

#include <barrelfish/barrelfish.h>
#include <barrelfish/monitor_client.h>
#include <flounder/flounder_support.h>
#include <flounder/flounder_support_ump.h>
#include <if/bulk_ctrl_defs.h>

/*
 * Send handler function
 */
static  void bulk_ctrl_ump_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_ump_binding *b = arg;
    errval_t err;
    err = SYS_ERR_OK;
    
    volatile struct ump_message *msg;
    struct ump_control ctrl;
    bool tx_notify = false;
    
    // do we need to (and can we) send a cap ack?
    if ((((b->ump_state).capst).tx_cap_ack) && flounder_stub_ump_can_send(&(b->ump_state))) {
        flounder_stub_ump_send_cap_ack(&(b->ump_state));
        ((b->ump_state).capst).tx_cap_ack = false;
        tx_notify = true;
    }
    
    // Switch on current outgoing message number
    switch (_binding->tx_msgnum) {
    case 0:
        break;
    case bulk_ctrl_negotiate_call__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_negotiate_call__msgnum);
            (msg->data)[0] = ((((_binding->tx_union).negotiate_call).role) | (((uintptr_t )(((_binding->tx_union).negotiate_call).trust)) << 32));
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 1:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_negotiate_response__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_negotiate_response__msgnum);
            (msg->data)[0] = ((((_binding->tx_union).negotiate_response).match_direction) | (((uintptr_t )(((_binding->tx_union).negotiate_response).match_role)) << 32));
            (msg->data)[1] = (((_binding->tx_union).negotiate_response).error);
            (msg->data)[2] = (((_binding->tx_union).negotiate_response).meta_size);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 1:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_assign_pool_call__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_assign_pool_call__msgnum);
            (msg->data)[0] = (((((_binding->tx_union).assign_pool_call).pool).pool_id_machine) | (((uintptr_t )((((_binding->tx_union).assign_pool_call).pool).pool_id_dom)) << 32));
            (msg->data)[1] = (((((_binding->tx_union).assign_pool_call).pool).pool_id_local) | (((uintptr_t )((((_binding->tx_union).assign_pool_call).pool).trust)) << 32));
            (msg->data)[2] = (((((_binding->tx_union).assign_pool_call).pool).buffer_size) | (((uintptr_t )((((_binding->tx_union).assign_pool_call).pool).num_buffers)) << 32));
            (msg->data)[3] = (((_binding->tx_union).assign_pool_call).id);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            if ((((b->ump_state).capst).tx_capnum) == 2) {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            return;
        case 1:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 1);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_assign_pool_response__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_assign_pool_response__msgnum);
            (msg->data)[0] = (((_binding->tx_union).assign_pool_response).error);
            (msg->data)[1] = (((_binding->tx_union).assign_pool_response).id);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 1:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_move_untrusted_call__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_move_untrusted_call__msgnum);
            (msg->data)[0] = (((((_binding->tx_union).move_untrusted_call).poolid).pool_id_machine) | (((uintptr_t )((((_binding->tx_union).move_untrusted_call).poolid).pool_id_dom)) << 32));
            (msg->data)[1] = (((((_binding->tx_union).move_untrusted_call).poolid).pool_id_local) | (((uintptr_t )(((_binding->tx_union).move_untrusted_call).bufferid)) << 32));
            (msg->data)[2] = (((_binding->tx_union).move_untrusted_call).tid);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        case 1:
            err = flounder_stub_ump_send_buf(&(b->ump_state), bulk_ctrl_move_untrusted_call__msgnum, ((_binding->tx_union).move_untrusted_call).meta, ((_binding->tx_union).move_untrusted_call).metasize, &(_binding->tx_str_pos));
            if (err_is_fail(err)) {
                if (err_no(err) == FLOUNDER_ERR_BUF_SEND_MORE) {
                    tx_notify = true;
                } else {
                    // Permanent error, report to user
                    (_binding->error_handler)(_binding, err);
                    _binding->tx_msgnum = 0;
                    flounder_support_trigger_chan(&(_binding->register_chanstate));
                    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                }
                break;
            }
            (_binding->tx_msg_fragment)++;
            if ((((b->ump_state).capst).tx_capnum) == 2) {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            return;
        case 2:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 1);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_move_trusted_call__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_move_trusted_call__msgnum);
            (msg->data)[0] = (((((_binding->tx_union).move_trusted_call).poolid).pool_id_machine) | (((uintptr_t )((((_binding->tx_union).move_trusted_call).poolid).pool_id_dom)) << 32));
            (msg->data)[1] = (((((_binding->tx_union).move_trusted_call).poolid).pool_id_local) | (((uintptr_t )(((_binding->tx_union).move_trusted_call).bufferid)) << 32));
            (msg->data)[2] = (((_binding->tx_union).move_trusted_call).tid);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        case 1:
            err = flounder_stub_ump_send_buf(&(b->ump_state), bulk_ctrl_move_trusted_call__msgnum, ((_binding->tx_union).move_trusted_call).meta, ((_binding->tx_union).move_trusted_call).metasize, &(_binding->tx_str_pos));
            if (err_is_fail(err)) {
                if (err_no(err) == FLOUNDER_ERR_BUF_SEND_MORE) {
                    tx_notify = true;
                } else {
                    // Permanent error, report to user
                    (_binding->error_handler)(_binding, err);
                    _binding->tx_msgnum = 0;
                    flounder_support_trigger_chan(&(_binding->register_chanstate));
                    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                }
                break;
            }
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 2:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_move_response__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_move_response__msgnum);
            (msg->data)[0] = (((_binding->tx_union).move_response).tid);
            (msg->data)[1] = (((_binding->tx_union).move_response).error);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 1:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_copy_untrusted_call__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_copy_untrusted_call__msgnum);
            (msg->data)[0] = (((((_binding->tx_union).copy_untrusted_call).poolid).pool_id_machine) | (((uintptr_t )((((_binding->tx_union).copy_untrusted_call).poolid).pool_id_dom)) << 32));
            (msg->data)[1] = (((((_binding->tx_union).copy_untrusted_call).poolid).pool_id_local) | (((uintptr_t )(((_binding->tx_union).copy_untrusted_call).bufferid)) << 32));
            (msg->data)[2] = (((_binding->tx_union).copy_untrusted_call).tid);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        case 1:
            err = flounder_stub_ump_send_buf(&(b->ump_state), bulk_ctrl_copy_untrusted_call__msgnum, ((_binding->tx_union).copy_untrusted_call).meta, ((_binding->tx_union).copy_untrusted_call).metasize, &(_binding->tx_str_pos));
            if (err_is_fail(err)) {
                if (err_no(err) == FLOUNDER_ERR_BUF_SEND_MORE) {
                    tx_notify = true;
                } else {
                    // Permanent error, report to user
                    (_binding->error_handler)(_binding, err);
                    _binding->tx_msgnum = 0;
                    flounder_support_trigger_chan(&(_binding->register_chanstate));
                    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                }
                break;
            }
            (_binding->tx_msg_fragment)++;
            if ((((b->ump_state).capst).tx_capnum) == 2) {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            return;
        case 2:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 1);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_copy_trusted_call__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_copy_trusted_call__msgnum);
            (msg->data)[0] = (((((_binding->tx_union).copy_trusted_call).poolid).pool_id_machine) | (((uintptr_t )((((_binding->tx_union).copy_trusted_call).poolid).pool_id_dom)) << 32));
            (msg->data)[1] = (((((_binding->tx_union).copy_trusted_call).poolid).pool_id_local) | (((uintptr_t )(((_binding->tx_union).copy_trusted_call).bufferid)) << 32));
            (msg->data)[2] = (((_binding->tx_union).copy_trusted_call).tid);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        case 1:
            err = flounder_stub_ump_send_buf(&(b->ump_state), bulk_ctrl_copy_trusted_call__msgnum, ((_binding->tx_union).copy_trusted_call).meta, ((_binding->tx_union).copy_trusted_call).metasize, &(_binding->tx_str_pos));
            if (err_is_fail(err)) {
                if (err_no(err) == FLOUNDER_ERR_BUF_SEND_MORE) {
                    tx_notify = true;
                } else {
                    // Permanent error, report to user
                    (_binding->error_handler)(_binding, err);
                    _binding->tx_msgnum = 0;
                    flounder_support_trigger_chan(&(_binding->register_chanstate));
                    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                }
                break;
            }
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 2:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_copy_response__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_copy_response__msgnum);
            (msg->data)[0] = (((_binding->tx_union).copy_response).tid);
            (msg->data)[1] = (((_binding->tx_union).copy_response).error);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 1:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_pass_untrusted_call__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_pass_untrusted_call__msgnum);
            (msg->data)[0] = (((((_binding->tx_union).pass_untrusted_call).poolid).pool_id_machine) | (((uintptr_t )((((_binding->tx_union).pass_untrusted_call).poolid).pool_id_dom)) << 32));
            (msg->data)[1] = (((((_binding->tx_union).pass_untrusted_call).poolid).pool_id_local) | (((uintptr_t )(((_binding->tx_union).pass_untrusted_call).bufferid)) << 32));
            (msg->data)[2] = (((_binding->tx_union).pass_untrusted_call).tid);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        case 1:
            err = flounder_stub_ump_send_buf(&(b->ump_state), bulk_ctrl_pass_untrusted_call__msgnum, ((_binding->tx_union).pass_untrusted_call).meta, ((_binding->tx_union).pass_untrusted_call).metasize, &(_binding->tx_str_pos));
            if (err_is_fail(err)) {
                if (err_no(err) == FLOUNDER_ERR_BUF_SEND_MORE) {
                    tx_notify = true;
                } else {
                    // Permanent error, report to user
                    (_binding->error_handler)(_binding, err);
                    _binding->tx_msgnum = 0;
                    flounder_support_trigger_chan(&(_binding->register_chanstate));
                    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                }
                break;
            }
            (_binding->tx_msg_fragment)++;
            if ((((b->ump_state).capst).tx_capnum) == 2) {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            return;
        case 2:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 1);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_pass_trusted_call__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_pass_trusted_call__msgnum);
            (msg->data)[0] = (((((_binding->tx_union).pass_trusted_call).poolid).pool_id_machine) | (((uintptr_t )((((_binding->tx_union).pass_trusted_call).poolid).pool_id_dom)) << 32));
            (msg->data)[1] = (((((_binding->tx_union).pass_trusted_call).poolid).pool_id_local) | (((uintptr_t )(((_binding->tx_union).pass_trusted_call).bufferid)) << 32));
            (msg->data)[2] = (((_binding->tx_union).pass_trusted_call).tid);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            // fall through to next fragment
        case 1:
            err = flounder_stub_ump_send_buf(&(b->ump_state), bulk_ctrl_pass_trusted_call__msgnum, ((_binding->tx_union).pass_trusted_call).meta, ((_binding->tx_union).pass_trusted_call).metasize, &(_binding->tx_str_pos));
            if (err_is_fail(err)) {
                if (err_no(err) == FLOUNDER_ERR_BUF_SEND_MORE) {
                    tx_notify = true;
                } else {
                    // Permanent error, report to user
                    (_binding->error_handler)(_binding, err);
                    _binding->tx_msgnum = 0;
                    flounder_support_trigger_chan(&(_binding->register_chanstate));
                    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                }
                break;
            }
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 2:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_pass_response__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_pass_response__msgnum);
            (msg->data)[0] = (((_binding->tx_union).pass_response).tid);
            (msg->data)[1] = (((_binding->tx_union).pass_response).error);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 1:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_release_call__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_release_call__msgnum);
            (msg->data)[0] = (((((_binding->tx_union).release_call).poolid).pool_id_machine) | (((uintptr_t )((((_binding->tx_union).release_call).poolid).pool_id_dom)) << 32));
            (msg->data)[1] = (((((_binding->tx_union).release_call).poolid).pool_id_local) | (((uintptr_t )(((_binding->tx_union).release_call).bufferid)) << 32));
            (msg->data)[2] = (((_binding->tx_union).release_call).tid);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 1:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_release_response__msgnum:
        // Switch on current outgoing message fragment
        switch (_binding->tx_msg_fragment) {
        case 0:
            // check if we can send another message
            if (!flounder_stub_ump_can_send(&(b->ump_state))) {
                tx_notify = true;
                break;
            }
            
            // send the next fragment
            msg = ump_chan_get_next(&((b->ump_state).chan), &ctrl);
            flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl_release_response__msgnum);
            (msg->data)[0] = (((_binding->tx_union).release_response).tid);
            (msg->data)[1] = (((_binding->tx_union).release_response).error);
            flounder_stub_ump_barrier();
            (msg->header).control = ctrl;
            (_binding->tx_msg_fragment)++;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        case 1:
            // we've sent all the fragments, we must just be waiting for caps
            assert((((b->ump_state).capst).tx_capnum) <= 0);
            break;
        default:
            assert(!("invalid fragment"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    default:
        assert(!("invalid msgnum"));
        (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
    }
    
    // Send a notification if necessary
    if (tx_notify) {
    }
}

static  errval_t bulk_ctrl_ump_tx_bind_msg(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_ump_binding *b = arg;
    errval_t err;
    err = SYS_ERR_OK;
    
    volatile struct ump_message *msg;
    struct ump_control ctrl;
    
    // check if we can send another message
    if (!flounder_stub_ump_can_send(&(b->ump_state))) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // send the next fragment
    msg = ump_chan_get_next(&((&(b->ump_state))->chan), &ctrl);
    flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl___bind__msgnum);
    (msg->data)[0] = 0xcafebabe;
    flounder_stub_ump_barrier();
    (msg->header).control = ctrl;
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_ump_tx_bind_reply(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_ump_binding *b = arg;
    errval_t err;
    err = SYS_ERR_OK;
    
    volatile struct ump_message *msg;
    struct ump_control ctrl;
    
    // check if we can send another message
    if (!flounder_stub_ump_can_send(&(b->ump_state))) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // send the next fragment
    msg = ump_chan_get_next(&((&(b->ump_state))->chan), &ctrl);
    flounder_stub_ump_control_fill(&(b->ump_state), &ctrl, bulk_ctrl___bind_reply__msgnum);
    (msg->data)[0] = 0xcafebabe;
    flounder_stub_ump_barrier();
    (msg->header).control = ctrl;
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    return(SYS_ERR_OK);
}


/*
 * Capability sender function
 */
static  void bulk_ctrl_ump_cap_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_ump_binding *b = arg;
    errval_t err;
    err = SYS_ERR_OK;
    
    assert(((b->ump_state).capst).rx_cap_ack);
    assert(((b->ump_state).capst).monitor_mutex_held);
    
    // Switch on current outgoing message
    switch (_binding->tx_msgnum) {
    case bulk_ctrl_assign_pool_call__msgnum:
        // Switch on current outgoing cap
        switch (((b->ump_state).capst).tx_capnum) {
        case 0:
            err = flounder_stub_send_cap(&((b->ump_state).capst), ((b->ump_state).chan).monitor_binding, ((b->ump_state).chan).monitor_id, (((_binding->tx_union).assign_pool_call).pool).cap, false, bulk_ctrl_ump_cap_send_handler);
            if (err_is_fail(err)) {
                (_binding->error_handler)(_binding, err);
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                break;
            }
            break;
        case 1:
            flounder_support_monitor_mutex_unlock(((b->ump_state).chan).monitor_binding);
            if ((_binding->tx_msg_fragment) == 1) {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_move_untrusted_call__msgnum:
        // Switch on current outgoing cap
        switch (((b->ump_state).capst).tx_capnum) {
        case 0:
            err = flounder_stub_send_cap(&((b->ump_state).capst), ((b->ump_state).chan).monitor_binding, ((b->ump_state).chan).monitor_id, ((_binding->tx_union).move_untrusted_call).cap, false, bulk_ctrl_ump_cap_send_handler);
            if (err_is_fail(err)) {
                (_binding->error_handler)(_binding, err);
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                break;
            }
            break;
        case 1:
            flounder_support_monitor_mutex_unlock(((b->ump_state).chan).monitor_binding);
            if ((_binding->tx_msg_fragment) == 2) {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_copy_untrusted_call__msgnum:
        // Switch on current outgoing cap
        switch (((b->ump_state).capst).tx_capnum) {
        case 0:
            err = flounder_stub_send_cap(&((b->ump_state).capst), ((b->ump_state).chan).monitor_binding, ((b->ump_state).chan).monitor_id, ((_binding->tx_union).copy_untrusted_call).cap, false, bulk_ctrl_ump_cap_send_handler);
            if (err_is_fail(err)) {
                (_binding->error_handler)(_binding, err);
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                break;
            }
            break;
        case 1:
            flounder_support_monitor_mutex_unlock(((b->ump_state).chan).monitor_binding);
            if ((_binding->tx_msg_fragment) == 2) {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_pass_untrusted_call__msgnum:
        // Switch on current outgoing cap
        switch (((b->ump_state).capst).tx_capnum) {
        case 0:
            err = flounder_stub_send_cap(&((b->ump_state).capst), ((b->ump_state).chan).monitor_binding, ((b->ump_state).chan).monitor_id, ((_binding->tx_union).pass_untrusted_call).cap, false, bulk_ctrl_ump_cap_send_handler);
            if (err_is_fail(err)) {
                (_binding->error_handler)(_binding, err);
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                break;
            }
            break;
        case 1:
            flounder_support_monitor_mutex_unlock(((b->ump_state).chan).monitor_binding);
            if ((_binding->tx_msg_fragment) == 2) {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    default:
        assert(!("invalid message number"));
        (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
    }
}


/*
 * Receive handler
 */
 void bulk_ctrl_ump_rx_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_ump_binding *b = arg;
    errval_t err;
    err = SYS_ERR_OK;
    
    volatile struct ump_message *msg;
    int msgnum;
    
    while (true) {
        // try to retrieve a message from the channel
        err = ump_chan_recv(&((b->ump_state).chan), &msg);
        // check if we succeeded
        if (err_is_fail(err)) {
            if (err_no(err) == LIB_ERR_NO_UMP_MSG) {
                // no message
                break;
            } else {
                // real error
                (_binding->error_handler)(_binding, err_push(err, LIB_ERR_UMP_CHAN_RECV));
                return;
            }
        }
        
        // process control word
        msgnum = flounder_stub_ump_control_process(&(b->ump_state), (msg->header).control);
        
        // is this a dummy message (ACK)?
        if (msgnum == FL_UMP_ACK) {
            goto loopnext;
        }
        
        // is this a binding message of connect/accept?
        if (msgnum == FL_UMP_BIND) {
            if ((b->is_client) == 1) {
                // Client should not recv bind messages. Ignore.
                goto loopnext;
            }
            // handle bind reply: calling bind callback
            (_binding->bind_cont)(_binding->st, err, _binding);
            bulk_ctrl_ump_tx_bind_reply(b);
            goto loopnext;
        }
        
        // is this a binding reply message of connect/accept?
        if (msgnum == FL_UMP_BIND_REPLY) {
            if ((b->is_client) == 0) {
                // Server should not recv bind messages. Ignore.
                goto loopnext;
            }
            // handle bind: calling connect callback
            (_binding->bind_cont)(_binding->st, err, _binding);
            goto loopnext;
        }
        
        // is this a cap ack for a pending tx message
        if (msgnum == FL_UMP_CAP_ACK) {
            assert(!(((b->ump_state).capst).rx_cap_ack));
            ((b->ump_state).capst).rx_cap_ack = true;
            if (((b->ump_state).capst).monitor_mutex_held) {
                bulk_ctrl_ump_cap_send_handler(b);
            }
            goto loopnext;
        }
        
        // is this the start of a new message?
        if ((_binding->rx_msgnum) == 0) {
            _binding->rx_msgnum = msgnum;
            _binding->rx_msg_fragment = 0;
        }
        
        // switch on message number and fragment number
        switch (_binding->rx_msgnum) {
        case bulk_ctrl_negotiate_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((_binding->rx_union).negotiate_call).role = (((msg->data)[0]) & 0xffffffff);
                ((_binding->rx_union).negotiate_call).trust = ((((msg->data)[0]) >> 32) & 0xffffffff);
                
                FL_DEBUG("ump RX bulk_ctrl.negotiate_call\n");
                assert(((_binding->rx_vtbl).negotiate_call) != NULL);
                ((_binding->rx_vtbl).negotiate_call)(_binding, ((_binding->rx_union).negotiate_call).role, ((_binding->rx_union).negotiate_call).trust);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_negotiate_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((_binding->rx_union).negotiate_response).match_direction = (((msg->data)[0]) & 0xffffffff);
                ((_binding->rx_union).negotiate_response).match_role = ((((msg->data)[0]) >> 32) & 0xffffffff);
                ((_binding->rx_union).negotiate_response).error = ((msg->data)[1]);
                ((_binding->rx_union).negotiate_response).meta_size = ((msg->data)[2]);
                
                FL_DEBUG("ump RX bulk_ctrl.negotiate_response\n");
                assert(((_binding->rx_vtbl).negotiate_response) != NULL);
                ((_binding->rx_vtbl).negotiate_response)(_binding, ((_binding->rx_union).negotiate_response).error, ((_binding->rx_union).negotiate_response).match_direction, ((_binding->rx_union).negotiate_response).match_role, ((_binding->rx_union).negotiate_response).meta_size);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_assign_pool_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((b->ump_state).capst).tx_cap_ack = true;
                ((b->ump_state).capst).rx_capnum = 0;
                (((_binding->rx_union).assign_pool_call).pool).pool_id_machine = (((msg->data)[0]) & 0xffffffff);
                (((_binding->rx_union).assign_pool_call).pool).pool_id_dom = ((((msg->data)[0]) >> 32) & 0xffffffff);
                (((_binding->rx_union).assign_pool_call).pool).pool_id_local = (((msg->data)[1]) & 0xffffffff);
                (((_binding->rx_union).assign_pool_call).pool).trust = ((((msg->data)[1]) >> 32) & 0xffffffff);
                (((_binding->rx_union).assign_pool_call).pool).buffer_size = (((msg->data)[2]) & 0xffffffff);
                (((_binding->rx_union).assign_pool_call).pool).num_buffers = ((((msg->data)[2]) >> 32) & 0xffffffff);
                ((_binding->rx_union).assign_pool_call).id = ((msg->data)[3]);
                
                (_binding->rx_msg_fragment)++;
                if ((((b->ump_state).capst).rx_capnum) == 1) {
                    FL_DEBUG("ump RX bulk_ctrl.assign_pool_call\n");
                    assert(((_binding->rx_vtbl).assign_pool_call) != NULL);
                    ((_binding->rx_vtbl).assign_pool_call)(_binding, ((_binding->rx_union).assign_pool_call).pool, ((_binding->rx_union).assign_pool_call).id);
                    _binding->rx_msgnum = 0;
                } else {
                    // don't process anything else until we're done
                    goto out_no_reregister;
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_assign_pool_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((_binding->rx_union).assign_pool_response).error = ((msg->data)[0]);
                ((_binding->rx_union).assign_pool_response).id = ((msg->data)[1]);
                
                FL_DEBUG("ump RX bulk_ctrl.assign_pool_response\n");
                assert(((_binding->rx_vtbl).assign_pool_response) != NULL);
                ((_binding->rx_vtbl).assign_pool_response)(_binding, ((_binding->rx_union).assign_pool_response).error, ((_binding->rx_union).assign_pool_response).id);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_move_untrusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((b->ump_state).capst).tx_cap_ack = true;
                ((b->ump_state).capst).rx_capnum = 0;
                (((_binding->rx_union).move_untrusted_call).poolid).pool_id_machine = (((msg->data)[0]) & 0xffffffff);
                (((_binding->rx_union).move_untrusted_call).poolid).pool_id_dom = ((((msg->data)[0]) >> 32) & 0xffffffff);
                (((_binding->rx_union).move_untrusted_call).poolid).pool_id_local = (((msg->data)[1]) & 0xffffffff);
                ((_binding->rx_union).move_untrusted_call).bufferid = ((((msg->data)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).move_untrusted_call).tid = (((msg->data)[2]) & 0xffffffff);
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_ump_recv_buf(msg, (void **)(&(((_binding->rx_union).move_untrusted_call).meta)), &(((_binding->rx_union).move_untrusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    (_binding->rx_msg_fragment)++;
                    if ((((b->ump_state).capst).rx_capnum) == 1) {
                        FL_DEBUG("ump RX bulk_ctrl.move_untrusted_call\n");
                        assert(((_binding->rx_vtbl).move_untrusted_call) != NULL);
                        ((_binding->rx_vtbl).move_untrusted_call)(_binding, ((_binding->rx_union).move_untrusted_call).poolid, ((_binding->rx_union).move_untrusted_call).bufferid, ((_binding->rx_union).move_untrusted_call).tid, ((_binding->rx_union).move_untrusted_call).cap, ((_binding->rx_union).move_untrusted_call).meta, ((_binding->rx_union).move_untrusted_call).metasize);
                        _binding->rx_msgnum = 0;
                    } else {
                        // don't process anything else until we're done
                        goto out_no_reregister;
                    }
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_move_trusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                (((_binding->rx_union).move_trusted_call).poolid).pool_id_machine = (((msg->data)[0]) & 0xffffffff);
                (((_binding->rx_union).move_trusted_call).poolid).pool_id_dom = ((((msg->data)[0]) >> 32) & 0xffffffff);
                (((_binding->rx_union).move_trusted_call).poolid).pool_id_local = (((msg->data)[1]) & 0xffffffff);
                ((_binding->rx_union).move_trusted_call).bufferid = ((((msg->data)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).move_trusted_call).tid = (((msg->data)[2]) & 0xffffffff);
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_ump_recv_buf(msg, (void **)(&(((_binding->rx_union).move_trusted_call).meta)), &(((_binding->rx_union).move_trusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    FL_DEBUG("ump RX bulk_ctrl.move_trusted_call\n");
                    assert(((_binding->rx_vtbl).move_trusted_call) != NULL);
                    ((_binding->rx_vtbl).move_trusted_call)(_binding, ((_binding->rx_union).move_trusted_call).poolid, ((_binding->rx_union).move_trusted_call).bufferid, ((_binding->rx_union).move_trusted_call).tid, ((_binding->rx_union).move_trusted_call).meta, ((_binding->rx_union).move_trusted_call).metasize);
                    _binding->rx_msgnum = 0;
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_move_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((_binding->rx_union).move_response).tid = (((msg->data)[0]) & 0xffffffff);
                ((_binding->rx_union).move_response).error = ((msg->data)[1]);
                
                FL_DEBUG("ump RX bulk_ctrl.move_response\n");
                assert(((_binding->rx_vtbl).move_response) != NULL);
                ((_binding->rx_vtbl).move_response)(_binding, ((_binding->rx_union).move_response).error, ((_binding->rx_union).move_response).tid);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_copy_untrusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((b->ump_state).capst).tx_cap_ack = true;
                ((b->ump_state).capst).rx_capnum = 0;
                (((_binding->rx_union).copy_untrusted_call).poolid).pool_id_machine = (((msg->data)[0]) & 0xffffffff);
                (((_binding->rx_union).copy_untrusted_call).poolid).pool_id_dom = ((((msg->data)[0]) >> 32) & 0xffffffff);
                (((_binding->rx_union).copy_untrusted_call).poolid).pool_id_local = (((msg->data)[1]) & 0xffffffff);
                ((_binding->rx_union).copy_untrusted_call).bufferid = ((((msg->data)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).copy_untrusted_call).tid = (((msg->data)[2]) & 0xffffffff);
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_ump_recv_buf(msg, (void **)(&(((_binding->rx_union).copy_untrusted_call).meta)), &(((_binding->rx_union).copy_untrusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    (_binding->rx_msg_fragment)++;
                    if ((((b->ump_state).capst).rx_capnum) == 1) {
                        FL_DEBUG("ump RX bulk_ctrl.copy_untrusted_call\n");
                        assert(((_binding->rx_vtbl).copy_untrusted_call) != NULL);
                        ((_binding->rx_vtbl).copy_untrusted_call)(_binding, ((_binding->rx_union).copy_untrusted_call).poolid, ((_binding->rx_union).copy_untrusted_call).bufferid, ((_binding->rx_union).copy_untrusted_call).tid, ((_binding->rx_union).copy_untrusted_call).cap, ((_binding->rx_union).copy_untrusted_call).meta, ((_binding->rx_union).copy_untrusted_call).metasize);
                        _binding->rx_msgnum = 0;
                    } else {
                        // don't process anything else until we're done
                        goto out_no_reregister;
                    }
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_copy_trusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                (((_binding->rx_union).copy_trusted_call).poolid).pool_id_machine = (((msg->data)[0]) & 0xffffffff);
                (((_binding->rx_union).copy_trusted_call).poolid).pool_id_dom = ((((msg->data)[0]) >> 32) & 0xffffffff);
                (((_binding->rx_union).copy_trusted_call).poolid).pool_id_local = (((msg->data)[1]) & 0xffffffff);
                ((_binding->rx_union).copy_trusted_call).bufferid = ((((msg->data)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).copy_trusted_call).tid = (((msg->data)[2]) & 0xffffffff);
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_ump_recv_buf(msg, (void **)(&(((_binding->rx_union).copy_trusted_call).meta)), &(((_binding->rx_union).copy_trusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    FL_DEBUG("ump RX bulk_ctrl.copy_trusted_call\n");
                    assert(((_binding->rx_vtbl).copy_trusted_call) != NULL);
                    ((_binding->rx_vtbl).copy_trusted_call)(_binding, ((_binding->rx_union).copy_trusted_call).poolid, ((_binding->rx_union).copy_trusted_call).bufferid, ((_binding->rx_union).copy_trusted_call).tid, ((_binding->rx_union).copy_trusted_call).meta, ((_binding->rx_union).copy_trusted_call).metasize);
                    _binding->rx_msgnum = 0;
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_copy_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((_binding->rx_union).copy_response).tid = (((msg->data)[0]) & 0xffffffff);
                ((_binding->rx_union).copy_response).error = ((msg->data)[1]);
                
                FL_DEBUG("ump RX bulk_ctrl.copy_response\n");
                assert(((_binding->rx_vtbl).copy_response) != NULL);
                ((_binding->rx_vtbl).copy_response)(_binding, ((_binding->rx_union).copy_response).error, ((_binding->rx_union).copy_response).tid);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_pass_untrusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((b->ump_state).capst).tx_cap_ack = true;
                ((b->ump_state).capst).rx_capnum = 0;
                (((_binding->rx_union).pass_untrusted_call).poolid).pool_id_machine = (((msg->data)[0]) & 0xffffffff);
                (((_binding->rx_union).pass_untrusted_call).poolid).pool_id_dom = ((((msg->data)[0]) >> 32) & 0xffffffff);
                (((_binding->rx_union).pass_untrusted_call).poolid).pool_id_local = (((msg->data)[1]) & 0xffffffff);
                ((_binding->rx_union).pass_untrusted_call).bufferid = ((((msg->data)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).pass_untrusted_call).tid = (((msg->data)[2]) & 0xffffffff);
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_ump_recv_buf(msg, (void **)(&(((_binding->rx_union).pass_untrusted_call).meta)), &(((_binding->rx_union).pass_untrusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    (_binding->rx_msg_fragment)++;
                    if ((((b->ump_state).capst).rx_capnum) == 1) {
                        FL_DEBUG("ump RX bulk_ctrl.pass_untrusted_call\n");
                        assert(((_binding->rx_vtbl).pass_untrusted_call) != NULL);
                        ((_binding->rx_vtbl).pass_untrusted_call)(_binding, ((_binding->rx_union).pass_untrusted_call).poolid, ((_binding->rx_union).pass_untrusted_call).bufferid, ((_binding->rx_union).pass_untrusted_call).tid, ((_binding->rx_union).pass_untrusted_call).cap, ((_binding->rx_union).pass_untrusted_call).meta, ((_binding->rx_union).pass_untrusted_call).metasize);
                        _binding->rx_msgnum = 0;
                    } else {
                        // don't process anything else until we're done
                        goto out_no_reregister;
                    }
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_pass_trusted_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                (((_binding->rx_union).pass_trusted_call).poolid).pool_id_machine = (((msg->data)[0]) & 0xffffffff);
                (((_binding->rx_union).pass_trusted_call).poolid).pool_id_dom = ((((msg->data)[0]) >> 32) & 0xffffffff);
                (((_binding->rx_union).pass_trusted_call).poolid).pool_id_local = (((msg->data)[1]) & 0xffffffff);
                ((_binding->rx_union).pass_trusted_call).bufferid = ((((msg->data)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).pass_trusted_call).tid = (((msg->data)[2]) & 0xffffffff);
                
                (_binding->rx_msg_fragment)++;
                break;
            case 1:
                err = flounder_stub_ump_recv_buf(msg, (void **)(&(((_binding->rx_union).pass_trusted_call).meta)), &(((_binding->rx_union).pass_trusted_call).metasize), &(_binding->rx_str_pos));
                if (err_is_ok(err)) {
                    FL_DEBUG("ump RX bulk_ctrl.pass_trusted_call\n");
                    assert(((_binding->rx_vtbl).pass_trusted_call) != NULL);
                    ((_binding->rx_vtbl).pass_trusted_call)(_binding, ((_binding->rx_union).pass_trusted_call).poolid, ((_binding->rx_union).pass_trusted_call).bufferid, ((_binding->rx_union).pass_trusted_call).tid, ((_binding->rx_union).pass_trusted_call).meta, ((_binding->rx_union).pass_trusted_call).metasize);
                    _binding->rx_msgnum = 0;
                } else {
                    if (err_no(err) != FLOUNDER_ERR_BUF_RECV_MORE) {
                        (_binding->error_handler)(_binding, err);
                    }
                }
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_pass_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((_binding->rx_union).pass_response).tid = (((msg->data)[0]) & 0xffffffff);
                ((_binding->rx_union).pass_response).error = ((msg->data)[1]);
                
                FL_DEBUG("ump RX bulk_ctrl.pass_response\n");
                assert(((_binding->rx_vtbl).pass_response) != NULL);
                ((_binding->rx_vtbl).pass_response)(_binding, ((_binding->rx_union).pass_response).error, ((_binding->rx_union).pass_response).tid);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_release_call__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                (((_binding->rx_union).release_call).poolid).pool_id_machine = (((msg->data)[0]) & 0xffffffff);
                (((_binding->rx_union).release_call).poolid).pool_id_dom = ((((msg->data)[0]) >> 32) & 0xffffffff);
                (((_binding->rx_union).release_call).poolid).pool_id_local = (((msg->data)[1]) & 0xffffffff);
                ((_binding->rx_union).release_call).bufferid = ((((msg->data)[1]) >> 32) & 0xffffffff);
                ((_binding->rx_union).release_call).tid = (((msg->data)[2]) & 0xffffffff);
                
                FL_DEBUG("ump RX bulk_ctrl.release_call\n");
                assert(((_binding->rx_vtbl).release_call) != NULL);
                ((_binding->rx_vtbl).release_call)(_binding, ((_binding->rx_union).release_call).poolid, ((_binding->rx_union).release_call).bufferid, ((_binding->rx_union).release_call).tid);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        case bulk_ctrl_release_response__msgnum:
            switch (_binding->rx_msg_fragment) {
            case 0:
                ((_binding->rx_union).release_response).tid = (((msg->data)[0]) & 0xffffffff);
                ((_binding->rx_union).release_response).error = ((msg->data)[1]);
                
                FL_DEBUG("ump RX bulk_ctrl.release_response\n");
                assert(((_binding->rx_vtbl).release_response) != NULL);
                ((_binding->rx_vtbl).release_response)(_binding, ((_binding->rx_union).release_response).error, ((_binding->rx_union).release_response).tid);
                _binding->rx_msgnum = 0;
                break;
            default:
                (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
                goto out;
            }
            break;
        default:
            (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_MSGNUM);
            goto out;
        }
        
        loopnext:
        // send an ack if the channel is now full
        if (flounder_stub_ump_needs_ack(&(b->ump_state))) {
            // run our send process if we need to
            if ((((b->ump_state).capst).tx_cap_ack) || ((_binding->tx_msgnum) != 0)) {
                bulk_ctrl_ump_send_handler(b);
            } else {
                flounder_stub_ump_send_ack(&(b->ump_state));
            }
        }
    }
    
    out:
    // register for receive notification
    err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
    if (err_is_fail(err)) {
        (_binding->error_handler)(_binding, err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
    }
    
    out_no_reregister:
    __attribute__((unused));
    // run our send process, if we need to
    if ((((b->ump_state).capst).tx_cap_ack) || ((_binding->tx_msgnum) != 0)) {
        bulk_ctrl_ump_send_handler(b);
    } else {
        // otherwise send a forced ack if the channel is now full
        if (flounder_stub_ump_needs_ack(&(b->ump_state))) {
            flounder_stub_ump_send_ack(&(b->ump_state));
        }
    }
}


/*
 * Cap send/receive handlers
 */
static  void bulk_ctrl_ump_cap_rx_handler(void *arg, errval_t success, struct capref cap, uint32_t capid)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_ump_binding *b = arg;
    errval_t err;
    err = SYS_ERR_OK;
    
    assert(capid == (((b->ump_state).capst).rx_capnum));
    
    // Check if there's an associated error
    // FIXME: how should we report this to the user? at present we just deliver a NULL capref
    if (err_is_fail(success)) {
        DEBUG_ERR(success, "error in cap transfer");
    }
    
    // Switch on current incoming message
    switch (_binding->rx_msgnum) {
    case bulk_ctrl_assign_pool_call__msgnum:
        // Switch on current incoming cap
        switch ((((b->ump_state).capst).rx_capnum)++) {
        case 0:
            (((_binding->rx_union).assign_pool_call).pool).cap = cap;
            if ((_binding->rx_msg_fragment) == 1) {
                FL_DEBUG("ump RX bulk_ctrl.assign_pool_call\n");
                assert(((_binding->rx_vtbl).assign_pool_call) != NULL);
                ((_binding->rx_vtbl).assign_pool_call)(_binding, ((_binding->rx_union).assign_pool_call).pool, ((_binding->rx_union).assign_pool_call).id);
                _binding->rx_msgnum = 0;
                // register for receive notification
                err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
                if (err_is_fail(err)) {
                    (_binding->error_handler)(_binding, err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
                }
            }
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_move_untrusted_call__msgnum:
        // Switch on current incoming cap
        switch ((((b->ump_state).capst).rx_capnum)++) {
        case 0:
            ((_binding->rx_union).move_untrusted_call).cap = cap;
            if ((_binding->rx_msg_fragment) == 2) {
                FL_DEBUG("ump RX bulk_ctrl.move_untrusted_call\n");
                assert(((_binding->rx_vtbl).move_untrusted_call) != NULL);
                ((_binding->rx_vtbl).move_untrusted_call)(_binding, ((_binding->rx_union).move_untrusted_call).poolid, ((_binding->rx_union).move_untrusted_call).bufferid, ((_binding->rx_union).move_untrusted_call).tid, ((_binding->rx_union).move_untrusted_call).cap, ((_binding->rx_union).move_untrusted_call).meta, ((_binding->rx_union).move_untrusted_call).metasize);
                _binding->rx_msgnum = 0;
                // register for receive notification
                err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
                if (err_is_fail(err)) {
                    (_binding->error_handler)(_binding, err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
                }
            }
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_copy_untrusted_call__msgnum:
        // Switch on current incoming cap
        switch ((((b->ump_state).capst).rx_capnum)++) {
        case 0:
            ((_binding->rx_union).copy_untrusted_call).cap = cap;
            if ((_binding->rx_msg_fragment) == 2) {
                FL_DEBUG("ump RX bulk_ctrl.copy_untrusted_call\n");
                assert(((_binding->rx_vtbl).copy_untrusted_call) != NULL);
                ((_binding->rx_vtbl).copy_untrusted_call)(_binding, ((_binding->rx_union).copy_untrusted_call).poolid, ((_binding->rx_union).copy_untrusted_call).bufferid, ((_binding->rx_union).copy_untrusted_call).tid, ((_binding->rx_union).copy_untrusted_call).cap, ((_binding->rx_union).copy_untrusted_call).meta, ((_binding->rx_union).copy_untrusted_call).metasize);
                _binding->rx_msgnum = 0;
                // register for receive notification
                err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
                if (err_is_fail(err)) {
                    (_binding->error_handler)(_binding, err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
                }
            }
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_pass_untrusted_call__msgnum:
        // Switch on current incoming cap
        switch ((((b->ump_state).capst).rx_capnum)++) {
        case 0:
            ((_binding->rx_union).pass_untrusted_call).cap = cap;
            if ((_binding->rx_msg_fragment) == 2) {
                FL_DEBUG("ump RX bulk_ctrl.pass_untrusted_call\n");
                assert(((_binding->rx_vtbl).pass_untrusted_call) != NULL);
                ((_binding->rx_vtbl).pass_untrusted_call)(_binding, ((_binding->rx_union).pass_untrusted_call).poolid, ((_binding->rx_union).pass_untrusted_call).bufferid, ((_binding->rx_union).pass_untrusted_call).tid, ((_binding->rx_union).pass_untrusted_call).cap, ((_binding->rx_union).pass_untrusted_call).meta, ((_binding->rx_union).pass_untrusted_call).metasize);
                _binding->rx_msgnum = 0;
                // register for receive notification
                err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
                if (err_is_fail(err)) {
                    (_binding->error_handler)(_binding, err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
                }
            }
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    default:
        assert(!("invalid message number"));
        (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
    }
}


/*
 * Monitor mutex acquire continuation
 */
static  void bulk_ctrl_ump_monitor_mutex_cont(void *arg)
{
    struct bulk_ctrl_ump_binding *b = arg;
    assert(!(((b->ump_state).capst).monitor_mutex_held));
    ((b->ump_state).capst).monitor_mutex_held = true;
    if (((b->ump_state).capst).rx_cap_ack) {
        bulk_ctrl_ump_cap_send_handler(b);
    }
}


/*
 * Message sender functions
 */
static  errval_t bulk_ctrl_negotiate_call__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_role_t role, bulk_ctrl_trust_t trust)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_negotiate_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).negotiate_call).role = role;
    ((_binding->tx_union).negotiate_call).trust = trust;
    FL_DEBUG("ump TX bulk_ctrl.negotiate_call\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_negotiate_response__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, bulk_ctrl_direction_t match_direction, bulk_ctrl_role_t match_role, uint64_t meta_size)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_negotiate_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).negotiate_response).error = error;
    ((_binding->tx_union).negotiate_response).match_direction = match_direction;
    ((_binding->tx_union).negotiate_response).match_role = match_role;
    ((_binding->tx_union).negotiate_response).meta_size = meta_size;
    FL_DEBUG("ump TX bulk_ctrl.negotiate_response\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_assign_pool_call__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_pool_t pool, uint64_t id)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_assign_pool_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).assign_pool_call).pool = pool;
    ((_binding->tx_union).assign_pool_call).id = id;
    FL_DEBUG("ump TX bulk_ctrl.assign_pool_call\n");
    
    // init cap send state
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).tx_capnum = 0;
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).rx_cap_ack = false;
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).monitor_mutex_held = false;
    
    // wait to acquire the monitor binding mutex
    flounder_support_monitor_mutex_enqueue(((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).chan).monitor_binding, &(_binding->event_qnode), (struct event_closure){  .handler = bulk_ctrl_ump_monitor_mutex_cont,  .arg = _binding });
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_assign_pool_response__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint64_t id)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_assign_pool_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).assign_pool_response).error = error;
    ((_binding->tx_union).assign_pool_response).id = id;
    FL_DEBUG("ump TX bulk_ctrl.assign_pool_response\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_move_untrusted_call__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, struct capref cap, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_move_untrusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).move_untrusted_call).poolid = poolid;
    ((_binding->tx_union).move_untrusted_call).bufferid = bufferid;
    ((_binding->tx_union).move_untrusted_call).tid = tid;
    ((_binding->tx_union).move_untrusted_call).cap = cap;
    ((_binding->tx_union).move_untrusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).move_untrusted_call).metasize = metasize;
    FL_DEBUG("ump TX bulk_ctrl.move_untrusted_call\n");
    
    // init cap send state
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).tx_capnum = 0;
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).rx_cap_ack = false;
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).monitor_mutex_held = false;
    
    // wait to acquire the monitor binding mutex
    flounder_support_monitor_mutex_enqueue(((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).chan).monitor_binding, &(_binding->event_qnode), (struct event_closure){  .handler = bulk_ctrl_ump_monitor_mutex_cont,  .arg = _binding });
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_move_trusted_call__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_move_trusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).move_trusted_call).poolid = poolid;
    ((_binding->tx_union).move_trusted_call).bufferid = bufferid;
    ((_binding->tx_union).move_trusted_call).tid = tid;
    ((_binding->tx_union).move_trusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).move_trusted_call).metasize = metasize;
    FL_DEBUG("ump TX bulk_ctrl.move_trusted_call\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_move_response__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_move_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).move_response).error = error;
    ((_binding->tx_union).move_response).tid = tid;
    FL_DEBUG("ump TX bulk_ctrl.move_response\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_copy_untrusted_call__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, struct capref cap, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_copy_untrusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).copy_untrusted_call).poolid = poolid;
    ((_binding->tx_union).copy_untrusted_call).bufferid = bufferid;
    ((_binding->tx_union).copy_untrusted_call).tid = tid;
    ((_binding->tx_union).copy_untrusted_call).cap = cap;
    ((_binding->tx_union).copy_untrusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).copy_untrusted_call).metasize = metasize;
    FL_DEBUG("ump TX bulk_ctrl.copy_untrusted_call\n");
    
    // init cap send state
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).tx_capnum = 0;
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).rx_cap_ack = false;
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).monitor_mutex_held = false;
    
    // wait to acquire the monitor binding mutex
    flounder_support_monitor_mutex_enqueue(((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).chan).monitor_binding, &(_binding->event_qnode), (struct event_closure){  .handler = bulk_ctrl_ump_monitor_mutex_cont,  .arg = _binding });
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_copy_trusted_call__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_copy_trusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).copy_trusted_call).poolid = poolid;
    ((_binding->tx_union).copy_trusted_call).bufferid = bufferid;
    ((_binding->tx_union).copy_trusted_call).tid = tid;
    ((_binding->tx_union).copy_trusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).copy_trusted_call).metasize = metasize;
    FL_DEBUG("ump TX bulk_ctrl.copy_trusted_call\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_copy_response__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_copy_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).copy_response).error = error;
    ((_binding->tx_union).copy_response).tid = tid;
    FL_DEBUG("ump TX bulk_ctrl.copy_response\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_pass_untrusted_call__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, struct capref cap, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_pass_untrusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).pass_untrusted_call).poolid = poolid;
    ((_binding->tx_union).pass_untrusted_call).bufferid = bufferid;
    ((_binding->tx_union).pass_untrusted_call).tid = tid;
    ((_binding->tx_union).pass_untrusted_call).cap = cap;
    ((_binding->tx_union).pass_untrusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).pass_untrusted_call).metasize = metasize;
    FL_DEBUG("ump TX bulk_ctrl.pass_untrusted_call\n");
    
    // init cap send state
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).tx_capnum = 0;
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).rx_cap_ack = false;
    ((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).capst).monitor_mutex_held = false;
    
    // wait to acquire the monitor binding mutex
    flounder_support_monitor_mutex_enqueue(((((struct bulk_ctrl_ump_binding *)(_binding))->ump_state).chan).monitor_binding, &(_binding->event_qnode), (struct event_closure){  .handler = bulk_ctrl_ump_monitor_mutex_cont,  .arg = _binding });
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_pass_trusted_call__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_pass_trusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).pass_trusted_call).poolid = poolid;
    ((_binding->tx_union).pass_trusted_call).bufferid = bufferid;
    ((_binding->tx_union).pass_trusted_call).tid = tid;
    ((_binding->tx_union).pass_trusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).pass_trusted_call).metasize = metasize;
    FL_DEBUG("ump TX bulk_ctrl.pass_trusted_call\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_pass_response__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_pass_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).pass_response).error = error;
    ((_binding->tx_union).pass_response).tid = tid;
    FL_DEBUG("ump TX bulk_ctrl.pass_response\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_release_call__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_release_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).release_call).poolid = poolid;
    ((_binding->tx_union).release_call).bufferid = bufferid;
    ((_binding->tx_union).release_call).tid = tid;
    FL_DEBUG("ump TX bulk_ctrl.release_call\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_release_response__ump_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and arguments
    _binding->tx_msgnum = bulk_ctrl_release_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).release_response).error = error;
    ((_binding->tx_union).release_response).tid = tid;
    FL_DEBUG("ump TX bulk_ctrl.release_response\n");
    
    // try to send!
    bulk_ctrl_ump_send_handler(_binding);
    
    return(SYS_ERR_OK);
}


/*
 * Send vtable
 */
static  struct bulk_ctrl_tx_vtbl bulk_ctrl_ump_tx_vtbl = {
    .negotiate_call = bulk_ctrl_negotiate_call__ump_send,
    .negotiate_response = bulk_ctrl_negotiate_response__ump_send,
    .assign_pool_call = bulk_ctrl_assign_pool_call__ump_send,
    .assign_pool_response = bulk_ctrl_assign_pool_response__ump_send,
    .move_untrusted_call = bulk_ctrl_move_untrusted_call__ump_send,
    .move_trusted_call = bulk_ctrl_move_trusted_call__ump_send,
    .move_response = bulk_ctrl_move_response__ump_send,
    .copy_untrusted_call = bulk_ctrl_copy_untrusted_call__ump_send,
    .copy_trusted_call = bulk_ctrl_copy_trusted_call__ump_send,
    .copy_response = bulk_ctrl_copy_response__ump_send,
    .pass_untrusted_call = bulk_ctrl_pass_untrusted_call__ump_send,
    .pass_trusted_call = bulk_ctrl_pass_trusted_call__ump_send,
    .pass_response = bulk_ctrl_pass_response__ump_send,
    .release_call = bulk_ctrl_release_call__ump_send,
    .release_response = bulk_ctrl_release_response__ump_send,
};
/*
 * Control functions
 */
static  bool bulk_ctrl_ump_can_send(struct bulk_ctrl_binding *b)
{
    return((b->tx_msgnum) == 0);
}

static  errval_t bulk_ctrl_ump_register_send(struct bulk_ctrl_binding *b, struct waitset *ws, struct event_closure _continuation)
{
    return(flounder_support_register(ws, &(b->register_chanstate), _continuation, bulk_ctrl_ump_can_send(b)));
}

static  void bulk_ctrl_ump_default_error_handler(struct bulk_ctrl_binding *b, errval_t err)
{
    DEBUG_ERR(err, "asynchronous error in Flounder-generated bulk_ctrl ump binding (default handler)");
    abort();
}

static  errval_t bulk_ctrl_ump_change_waitset(struct bulk_ctrl_binding *_binding, struct waitset *ws)
{
    struct bulk_ctrl_ump_binding *b = (void *)(_binding);
    errval_t err;
    
    // change waitset on private monitor binding if we have one
    if ((((b->ump_state).chan).monitor_binding) != get_monitor_binding()) {
        err = flounder_support_change_monitor_waitset(((b->ump_state).chan).monitor_binding, ws);
        if (err_is_fail(err)) {
            return(err_push(err, FLOUNDER_ERR_CHANGE_MONITOR_WAITSET));
        }
    }
    
    // change waitset on binding
    _binding->waitset = ws;
    
    // re-register for receive (if previously registered)
    err = ump_chan_deregister_recv(&((b->ump_state).chan));
    if (err_is_fail(err) && (err_no(err) != LIB_ERR_CHAN_NOT_REGISTERED)) {
        return(err_push(err, LIB_ERR_CHAN_DEREGISTER_RECV));
    }
    if (err_is_ok(err)) {
        err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
        if (err_is_fail(err)) {
            return(err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
        }
    }
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_ump_control(struct bulk_ctrl_binding *_binding, idc_control_t control)
{
    // no control flags are supported
    return(SYS_ERR_OK);
}


/*
 * Function to destroy the binding state
 */
 void bulk_ctrl_ump_destroy(struct bulk_ctrl_ump_binding *b)
{
    flounder_support_waitset_chanstate_destroy(&((b->b).register_chanstate));
    flounder_support_waitset_chanstate_destroy(&((b->b).tx_cont_chanstate));
    ump_chan_destroy(&((b->ump_state).chan));
}


/*
 * Bind function
 */
static  void bulk_ctrl_ump_bind_continuation(void *st, errval_t err, struct ump_chan *chan, struct capref notify_cap)
{
    struct bulk_ctrl_binding *_binding = st;
    struct bulk_ctrl_ump_binding *b = st;
    
    if (err_is_ok(err)) {
        // notify cap ignored
        // setup cap handlers
        (((b->ump_state).chan).cap_handlers).st = b;
        (((b->ump_state).chan).cap_handlers).cap_receive_handler = bulk_ctrl_ump_cap_rx_handler;
        // register for receive notification
        err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
        if (err_is_fail(err)) {
            (_binding->error_handler)(_binding, err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
        }
    } else {
        bulk_ctrl_ump_destroy(b);
    }
    
    (_binding->bind_cont)(_binding->st, err, _binding);
}

 errval_t bulk_ctrl_ump_init(struct bulk_ctrl_ump_binding *b, struct waitset *waitset, volatile void *inbuf, size_t inbufsize, volatile void *outbuf, size_t outbufsize)
{
    errval_t err;
    struct bulk_ctrl_binding *_binding = &(b->b);
    (b->b).st = NULL;
    (b->b).waitset = waitset;
    event_mutex_init(&((b->b).mutex), waitset);
    (b->b).can_send = bulk_ctrl_ump_can_send;
    (b->b).register_send = bulk_ctrl_ump_register_send;
    (b->b).error_handler = bulk_ctrl_ump_default_error_handler;
    (b->b).tx_vtbl = bulk_ctrl_ump_tx_vtbl;
    memset(&((b->b).rx_vtbl), 0, sizeof((b->b).rx_vtbl));
    flounder_support_waitset_chanstate_init(&((b->b).register_chanstate));
    flounder_support_waitset_chanstate_init(&((b->b).tx_cont_chanstate));
    (b->b).tx_msgnum = 0;
    (b->b).rx_msgnum = 0;
    (b->b).tx_msg_fragment = 0;
    (b->b).rx_msg_fragment = 0;
    (b->b).tx_str_pos = 0;
    (b->b).rx_str_pos = 0;
    (b->b).tx_str_len = 0;
    (b->b).rx_str_len = 0;
    (b->b).bind_cont = NULL;
    flounder_stub_ump_state_init(&(b->ump_state), b);
    err = ump_chan_init(&((b->ump_state).chan), inbuf, inbufsize, outbuf, outbufsize);
    if (err_is_fail(err)) {
        bulk_ctrl_ump_destroy(b);
        return(err_push(err, LIB_ERR_UMP_CHAN_INIT));
    }
    
    (b->b).change_waitset = bulk_ctrl_ump_change_waitset;
    (b->b).control = bulk_ctrl_ump_control;
    // register for receive notification
    err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
    if (err_is_fail(err)) {
        (_binding->error_handler)(_binding, err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
    }
    
    return(err);
}

static  void bulk_ctrl_ump_new_monitor_binding_continuation(void *st, errval_t err, struct monitor_binding *monitor_binding)
{
    struct bulk_ctrl_binding *_binding = st;
    struct bulk_ctrl_ump_binding *b = st;
    
    if (err_is_fail(err)) {
        err = err_push(err, LIB_ERR_MONITOR_CLIENT_BIND);
        goto out;
    }
    
    ((b->ump_state).chan).monitor_binding = monitor_binding;
    // start the bind on the new monitor binding
    err = ump_chan_bind(&((b->ump_state).chan), (struct ump_bind_continuation){  .handler = bulk_ctrl_ump_bind_continuation,  .st = b }, &(_binding->event_qnode), b->iref, monitor_binding, b->inchanlen, b->outchanlen, NULL_CAP);
    
    out:
    if (err_is_fail(err)) {
        (_binding->bind_cont)(_binding->st, err, _binding);
        bulk_ctrl_ump_destroy(b);
    }
}

 errval_t bulk_ctrl_ump_bind(struct bulk_ctrl_ump_binding *b, iref_t iref, bulk_ctrl_bind_continuation_fn *_continuation, void *st, struct waitset *waitset, idc_bind_flags_t flags, size_t inchanlen, size_t outchanlen)
{
    errval_t err;
    (b->b).st = NULL;
    (b->b).waitset = waitset;
    event_mutex_init(&((b->b).mutex), waitset);
    (b->b).can_send = bulk_ctrl_ump_can_send;
    (b->b).register_send = bulk_ctrl_ump_register_send;
    (b->b).error_handler = bulk_ctrl_ump_default_error_handler;
    (b->b).tx_vtbl = bulk_ctrl_ump_tx_vtbl;
    memset(&((b->b).rx_vtbl), 0, sizeof((b->b).rx_vtbl));
    flounder_support_waitset_chanstate_init(&((b->b).register_chanstate));
    flounder_support_waitset_chanstate_init(&((b->b).tx_cont_chanstate));
    (b->b).tx_msgnum = 0;
    (b->b).rx_msgnum = 0;
    (b->b).tx_msg_fragment = 0;
    (b->b).rx_msg_fragment = 0;
    (b->b).tx_str_pos = 0;
    (b->b).rx_str_pos = 0;
    (b->b).tx_str_len = 0;
    (b->b).rx_str_len = 0;
    (b->b).bind_cont = NULL;
    flounder_stub_ump_state_init(&(b->ump_state), b);
    (b->b).change_waitset = bulk_ctrl_ump_change_waitset;
    (b->b).control = bulk_ctrl_ump_control;
    (b->b).st = st;
    (b->b).bind_cont = _continuation;
    b->iref = iref;
    b->inchanlen = inchanlen;
    b->outchanlen = outchanlen;
    b->no_cap_transfer = 0;
    
    // do we need a new monitor binding?
    if (flags & IDC_BIND_FLAG_RPC_CAP_TRANSFER) {
        err = monitor_client_new_binding(bulk_ctrl_ump_new_monitor_binding_continuation, b, waitset, DEFAULT_LMP_BUF_WORDS);
    } else {
        err = ump_chan_bind(&((b->ump_state).chan), (struct ump_bind_continuation){  .handler = bulk_ctrl_ump_bind_continuation,  .st = b }, &((b->b).event_qnode), iref, get_monitor_binding(), inchanlen, outchanlen, NULL_CAP);
    }
    
    if (err_is_fail(err)) {
        bulk_ctrl_ump_destroy(b);
    }
    return(err);
}


/*
 * Connect callback for export
 */
 errval_t bulk_ctrl_ump_connect_handler(void *st, struct monitor_binding *mb, uintptr_t mon_id, struct capref frame, size_t inchanlen, size_t outchanlen, struct capref notify_cap)
{
    struct bulk_ctrl_export *e = st;
    errval_t err;
    
    // allocate storage for binding
    struct bulk_ctrl_ump_binding *b = malloc(sizeof(struct bulk_ctrl_ump_binding ));
    if (b == NULL) {
        return(LIB_ERR_MALLOC_FAIL);
    }
    
    struct bulk_ctrl_binding *_binding = &(b->b);
    (b->b).st = NULL;
    (b->b).waitset = (e->waitset);
    event_mutex_init(&((b->b).mutex), e->waitset);
    (b->b).can_send = bulk_ctrl_ump_can_send;
    (b->b).register_send = bulk_ctrl_ump_register_send;
    (b->b).error_handler = bulk_ctrl_ump_default_error_handler;
    (b->b).tx_vtbl = bulk_ctrl_ump_tx_vtbl;
    memset(&((b->b).rx_vtbl), 0, sizeof((b->b).rx_vtbl));
    flounder_support_waitset_chanstate_init(&((b->b).register_chanstate));
    flounder_support_waitset_chanstate_init(&((b->b).tx_cont_chanstate));
    (b->b).tx_msgnum = 0;
    (b->b).rx_msgnum = 0;
    (b->b).tx_msg_fragment = 0;
    (b->b).rx_msg_fragment = 0;
    (b->b).tx_str_pos = 0;
    (b->b).rx_str_pos = 0;
    (b->b).tx_str_len = 0;
    (b->b).rx_str_len = 0;
    (b->b).bind_cont = NULL;
    flounder_stub_ump_state_init(&(b->ump_state), b);
    (b->b).change_waitset = bulk_ctrl_ump_change_waitset;
    (b->b).control = bulk_ctrl_ump_control;
    b->no_cap_transfer = 0;
    
    // run user's connect handler
    err = ((e->connect_cb)(e->st, _binding));
    if (err_is_fail(err)) {
        // connection refused
        bulk_ctrl_ump_destroy(b);
        return(err);
    }
    
    // accept the connection and setup the channel
    err = ump_chan_accept(&((b->ump_state).chan), mon_id, frame, inchanlen, outchanlen);
    if (err_is_fail(err)) {
        err = err_push(err, LIB_ERR_UMP_CHAN_ACCEPT);
        (_binding->error_handler)(_binding, err);
        return(err);
    }
    
    // notify cap ignored
    // setup cap handlers
    (((b->ump_state).chan).cap_handlers).st = b;
    (((b->ump_state).chan).cap_handlers).cap_receive_handler = bulk_ctrl_ump_cap_rx_handler;
    
    // register for receive notification
    err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
    if (err_is_fail(err)) {
        (_binding->error_handler)(_binding, err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
    }
    
    // send back bind reply
    ump_chan_send_bind_reply(mb, &((b->ump_state).chan), SYS_ERR_OK, mon_id, NULL_CAP);
    
    return(SYS_ERR_OK);
}


/*
 * Functions to accept/connect over a already shared frame
 */
 errval_t bulk_ctrl_ump_accept(struct bulk_ctrl_frameinfo *_frameinfo, void *st, bulk_ctrl_bind_continuation_fn *_continuation, struct waitset *ws, idc_export_flags_t flags)
{
    errval_t err;
    
    // allocate storage for binding
    struct bulk_ctrl_ump_binding *b = malloc(sizeof(struct bulk_ctrl_ump_binding ));
    if (b == NULL) {
        return(LIB_ERR_MALLOC_FAIL);
    }
    
    struct bulk_ctrl_binding *_binding = &(b->b);
    (b->b).st = NULL;
    (b->b).waitset = ws;
    event_mutex_init(&((b->b).mutex), ws);
    (b->b).can_send = bulk_ctrl_ump_can_send;
    (b->b).register_send = bulk_ctrl_ump_register_send;
    (b->b).error_handler = bulk_ctrl_ump_default_error_handler;
    (b->b).tx_vtbl = bulk_ctrl_ump_tx_vtbl;
    memset(&((b->b).rx_vtbl), 0, sizeof((b->b).rx_vtbl));
    flounder_support_waitset_chanstate_init(&((b->b).register_chanstate));
    flounder_support_waitset_chanstate_init(&((b->b).tx_cont_chanstate));
    (b->b).tx_msgnum = 0;
    (b->b).rx_msgnum = 0;
    (b->b).tx_msg_fragment = 0;
    (b->b).rx_msg_fragment = 0;
    (b->b).tx_str_pos = 0;
    (b->b).rx_str_pos = 0;
    (b->b).tx_str_len = 0;
    (b->b).rx_str_len = 0;
    (b->b).bind_cont = NULL;
    flounder_stub_ump_state_init(&(b->ump_state), b);
    err = ump_chan_init(&((b->ump_state).chan), _frameinfo->inbuf, _frameinfo->inbufsize, _frameinfo->outbuf, _frameinfo->outbufsize);
    if (err_is_fail(err)) {
        bulk_ctrl_ump_destroy(b);
        return(err_push(err, LIB_ERR_UMP_CHAN_INIT));
    }
    
    ((b->ump_state).chan).sendid = (_frameinfo->sendbase);
    (b->b).change_waitset = bulk_ctrl_ump_change_waitset;
    (b->b).control = bulk_ctrl_ump_control;
    (b->b).st = st;
    (b->b).bind_cont = _continuation;
    b->inchanlen = (_frameinfo->inbufsize);
    b->outchanlen = (_frameinfo->outbufsize);
    b->no_cap_transfer = 1;
    b->is_client = 0;
    // register for receive notification
    err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
    if (err_is_fail(err)) {
        (_binding->error_handler)(_binding, err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
    }
    
    // notify cap ignored
    // setup cap handlers
    (((b->ump_state).chan).cap_handlers).st = b;
    (((b->ump_state).chan).cap_handlers).cap_receive_handler = bulk_ctrl_ump_cap_rx_handler;
    
    return(SYS_ERR_OK);
}

 errval_t bulk_ctrl_ump_connect(struct bulk_ctrl_frameinfo *_frameinfo, bulk_ctrl_bind_continuation_fn *_continuation, void *st, struct waitset *ws, idc_bind_flags_t flags)
{
    errval_t err;
    // allocate storage for binding
    struct bulk_ctrl_ump_binding *b = malloc(sizeof(struct bulk_ctrl_ump_binding ));
    if (b == NULL) {
        return(LIB_ERR_MALLOC_FAIL);
    }
    
    struct bulk_ctrl_binding *_binding = &(b->b);
    (b->b).st = NULL;
    (b->b).waitset = ws;
    event_mutex_init(&((b->b).mutex), ws);
    (b->b).can_send = bulk_ctrl_ump_can_send;
    (b->b).register_send = bulk_ctrl_ump_register_send;
    (b->b).error_handler = bulk_ctrl_ump_default_error_handler;
    (b->b).tx_vtbl = bulk_ctrl_ump_tx_vtbl;
    memset(&((b->b).rx_vtbl), 0, sizeof((b->b).rx_vtbl));
    flounder_support_waitset_chanstate_init(&((b->b).register_chanstate));
    flounder_support_waitset_chanstate_init(&((b->b).tx_cont_chanstate));
    (b->b).tx_msgnum = 0;
    (b->b).rx_msgnum = 0;
    (b->b).tx_msg_fragment = 0;
    (b->b).rx_msg_fragment = 0;
    (b->b).tx_str_pos = 0;
    (b->b).rx_str_pos = 0;
    (b->b).tx_str_len = 0;
    (b->b).rx_str_len = 0;
    (b->b).bind_cont = NULL;
    flounder_stub_ump_state_init(&(b->ump_state), b);
    (b->b).change_waitset = bulk_ctrl_ump_change_waitset;
    (b->b).control = bulk_ctrl_ump_control;
    (b->b).st = st;
    (b->b).bind_cont = _continuation;
    err = ump_chan_init(&((b->ump_state).chan), _frameinfo->inbuf, _frameinfo->inbufsize, _frameinfo->outbuf, _frameinfo->outbufsize);
    if (err_is_fail(err)) {
        bulk_ctrl_ump_destroy(b);
        return(err_push(err, LIB_ERR_UMP_CHAN_INIT));
    }
    
    ((b->ump_state).chan).sendid = (_frameinfo->sendbase);
    b->inchanlen = (_frameinfo->inbufsize);
    b->outchanlen = (_frameinfo->outbufsize);
    b->no_cap_transfer = 1;
    b->is_client = 1;
    
    // notify cap ignored
    // setup cap handlers
    (((b->ump_state).chan).cap_handlers).st = b;
    (((b->ump_state).chan).cap_handlers).cap_receive_handler = bulk_ctrl_ump_cap_rx_handler;
    
    // register for receive notification
    err = ump_chan_register_recv(&((b->ump_state).chan), _binding->waitset, (struct event_closure){  .handler = bulk_ctrl_ump_rx_handler,  .arg = _binding });
    if (err_is_fail(err)) {
        (_binding->error_handler)(_binding, err_push(err, LIB_ERR_CHAN_REGISTER_RECV));
    }
    
    return(bulk_ctrl_ump_tx_bind_msg(b));
}

#endif // CONFIG_FLOUNDER_BACKEND_UMP
/*
 * Copyright (c) 2010, ETH Zurich.
 * All rights reserved.
 * 
 * INTERFACE NAME: bulk_ctrl
 * INTEFACE FILE: ../if/bulk_ctrl.if
 * INTERFACE DESCRIPTION: bulk control channel interface
 * 
 * This file is distributed under the terms in the attached LICENSE
 * file. If you do not find this file, copies can be found by
 * writing to:
 * ETH Zurich D-INFK, Universitaetstr.6, CH-8092 Zurich.
 * Attn: Systems Group.
 * 
 * THIS FILE IS AUTOMATICALLY GENERATED BY FLOUNDER: DO NOT EDIT!
 */

#ifdef CONFIG_FLOUNDER_BACKEND_MULTIHOP
/*
 * Generated Stub for Multihop on x86_64
 */

#include <string.h>
#include <barrelfish/barrelfish.h>
#include <flounder/flounder_support.h>
#include <if/bulk_ctrl_defs.h>

/*
 * Capability sender function
 */
static  void bulk_ctrl_multihop_cap_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    
    // Switch on current outgoing message
    switch (_binding->tx_msgnum) {
    case bulk_ctrl_assign_pool_call__msgnum:
        // Switch on current outgoing cap
        switch ((mb->capst).tx_capnum) {
        case 0:
            err = multihop_send_capability(&(mb->chan), MKCONT(bulk_ctrl_multihop_cap_send_handler, _binding), &(mb->capst), (((_binding->tx_union).assign_pool_call).pool).cap);
            if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
                err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_multihop_cap_send_handler, _binding));
                assert(err_is_ok(err));
            }
            if (err_is_fail(err)) {
                (_binding->error_handler)(_binding, err);
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                break;
            }
            break;
        case 1:
            if (multihop_chan_is_window_full(&(mb->chan))) {
                mb->trigger_chan = true;
                break;
            } else {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                break;
            }
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_move_untrusted_call__msgnum:
        // Switch on current outgoing cap
        switch ((mb->capst).tx_capnum) {
        case 0:
            err = multihop_send_capability(&(mb->chan), MKCONT(bulk_ctrl_multihop_cap_send_handler, _binding), &(mb->capst), ((_binding->tx_union).move_untrusted_call).cap);
            if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
                err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_multihop_cap_send_handler, _binding));
                assert(err_is_ok(err));
            }
            if (err_is_fail(err)) {
                (_binding->error_handler)(_binding, err);
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                break;
            }
            break;
        case 1:
            if (multihop_chan_is_window_full(&(mb->chan))) {
                mb->trigger_chan = true;
                break;
            } else {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                break;
            }
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_copy_untrusted_call__msgnum:
        // Switch on current outgoing cap
        switch ((mb->capst).tx_capnum) {
        case 0:
            err = multihop_send_capability(&(mb->chan), MKCONT(bulk_ctrl_multihop_cap_send_handler, _binding), &(mb->capst), ((_binding->tx_union).copy_untrusted_call).cap);
            if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
                err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_multihop_cap_send_handler, _binding));
                assert(err_is_ok(err));
            }
            if (err_is_fail(err)) {
                (_binding->error_handler)(_binding, err);
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                break;
            }
            break;
        case 1:
            if (multihop_chan_is_window_full(&(mb->chan))) {
                mb->trigger_chan = true;
                break;
            } else {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                break;
            }
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_pass_untrusted_call__msgnum:
        // Switch on current outgoing cap
        switch ((mb->capst).tx_capnum) {
        case 0:
            err = multihop_send_capability(&(mb->chan), MKCONT(bulk_ctrl_multihop_cap_send_handler, _binding), &(mb->capst), ((_binding->tx_union).pass_untrusted_call).cap);
            if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
                err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_multihop_cap_send_handler, _binding));
                assert(err_is_ok(err));
            }
            if (err_is_fail(err)) {
                (_binding->error_handler)(_binding, err);
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
                break;
            }
            break;
        case 1:
            if (multihop_chan_is_window_full(&(mb->chan))) {
                mb->trigger_chan = true;
                break;
            } else {
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
                break;
            }
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    default:
        assert(!("invalid message number"));
        (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
    }
}

/*
 * Send handler functions
 */
static  void bulk_ctrl_negotiate_call__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 16;
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment int32 [NamedField "role"] 0],[ArgFieldFragment int32 [NamedField "trust"] 0]]
        msg[0] = (bulk_ctrl_negotiate_call__msgnum | (((uint64_t )(((_binding->tx_union).negotiate_call).role)) << 16));
        msg[1] = (((_binding->tx_union).negotiate_call).trust);
        
        
        // copy strings
        
        // copy buffers
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_negotiate_call__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_negotiate_call__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_negotiate_response__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 32;
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment int32 [NamedField "match_direction"] 0],[ArgFieldFragment int32 [NamedField "match_role"] 0],[ArgFieldFragment uint64 [NamedField "error"] 0],[ArgFieldFragment uint64 [NamedField "meta_size"] 0]]
        msg[0] = (bulk_ctrl_negotiate_response__msgnum | (((uint64_t )(((_binding->tx_union).negotiate_response).match_direction)) << 16));
        msg[1] = (((_binding->tx_union).negotiate_response).match_role);
        msg[2] = (((_binding->tx_union).negotiate_response).error);
        msg[3] = (((_binding->tx_union).negotiate_response).meta_size);
        
        
        // copy strings
        
        // copy buffers
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_negotiate_response__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_negotiate_response__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_assign_pool_call__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 40;
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "pool_id_machine",NamedField "pool"] 0],[ArgFieldFragment uint32 [NamedField "pool_id_dom",NamedField "pool"] 0,ArgFieldFragment uint32 [NamedField "pool_id_local",NamedField "pool"] 0],[ArgFieldFragment int32 [NamedField "trust",NamedField "pool"] 0,ArgFieldFragment uint32 [NamedField "buffer_size",NamedField "pool"] 0],[ArgFieldFragment uint32 [NamedField "num_buffers",NamedField "pool"] 0],[ArgFieldFragment uint64 [NamedField "id"] 0]]
        msg[0] = (bulk_ctrl_assign_pool_call__msgnum | (((uint64_t )((((_binding->tx_union).assign_pool_call).pool).pool_id_machine)) << 16));
        msg[1] = (((((_binding->tx_union).assign_pool_call).pool).pool_id_dom) | (((uint64_t )((((_binding->tx_union).assign_pool_call).pool).pool_id_local)) << 32));
        msg[2] = (((((_binding->tx_union).assign_pool_call).pool).trust) | (((uint64_t )((((_binding->tx_union).assign_pool_call).pool).buffer_size)) << 32));
        msg[3] = ((((_binding->tx_union).assign_pool_call).pool).num_buffers);
        msg[4] = (((_binding->tx_union).assign_pool_call).id);
        
        
        // copy strings
        
        // copy buffers
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_assign_pool_call__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_assign_pool_call__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        free(mb->message);
        // send caps
        bulk_ctrl_multihop_cap_send_handler(mb);
        return;
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_assign_pool_response__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 24;
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode],[ArgFieldFragment uint64 [NamedField "error"] 0],[ArgFieldFragment uint64 [NamedField "id"] 0]]
        msg[0] = bulk_ctrl_assign_pool_response__msgnum;
        msg[1] = (((_binding->tx_union).assign_pool_response).error);
        msg[2] = (((_binding->tx_union).assign_pool_response).id);
        
        
        // copy strings
        
        // copy buffers
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_assign_pool_response__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_assign_pool_response__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_move_untrusted_call__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    uint8_t *msg2;
    uint64_t o_frag_size;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 24;
        msg_size = (msg_size + ((((_binding->tx_union).move_untrusted_call).metasize) + 8));
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "pool_id_machine",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "pool_id_dom",NamedField "poolid"] 0,ArgFieldFragment uint32 [NamedField "pool_id_local",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "bufferid"] 0,ArgFieldFragment uint32 [NamedField "tid"] 0]]
        msg[0] = (bulk_ctrl_move_untrusted_call__msgnum | (((uint64_t )((((_binding->tx_union).move_untrusted_call).poolid).pool_id_machine)) << 16));
        msg[1] = (((((_binding->tx_union).move_untrusted_call).poolid).pool_id_dom) | (((uint64_t )((((_binding->tx_union).move_untrusted_call).poolid).pool_id_local)) << 32));
        msg[2] = ((((_binding->tx_union).move_untrusted_call).bufferid) | (((uint64_t )(((_binding->tx_union).move_untrusted_call).tid)) << 32));
        msg2 = (((uint8_t *)(msg)) + 24);
        
        // copy strings
        
        // copy buffers
        o_frag_size = ((uint64_t )(((_binding->tx_union).move_untrusted_call).metasize));
        memcpy(msg2, &o_frag_size, 8);
        memcpy(msg2 + 8, ((_binding->tx_union).move_untrusted_call).meta, o_frag_size);
        msg2 = ((msg2 + o_frag_size) + 8);
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_move_untrusted_call__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_move_untrusted_call__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        free(mb->message);
        // send caps
        bulk_ctrl_multihop_cap_send_handler(mb);
        return;
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_move_trusted_call__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    uint8_t *msg2;
    uint64_t o_frag_size;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 24;
        msg_size = (msg_size + ((((_binding->tx_union).move_trusted_call).metasize) + 8));
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "pool_id_machine",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "pool_id_dom",NamedField "poolid"] 0,ArgFieldFragment uint32 [NamedField "pool_id_local",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "bufferid"] 0,ArgFieldFragment uint32 [NamedField "tid"] 0]]
        msg[0] = (bulk_ctrl_move_trusted_call__msgnum | (((uint64_t )((((_binding->tx_union).move_trusted_call).poolid).pool_id_machine)) << 16));
        msg[1] = (((((_binding->tx_union).move_trusted_call).poolid).pool_id_dom) | (((uint64_t )((((_binding->tx_union).move_trusted_call).poolid).pool_id_local)) << 32));
        msg[2] = ((((_binding->tx_union).move_trusted_call).bufferid) | (((uint64_t )(((_binding->tx_union).move_trusted_call).tid)) << 32));
        msg2 = (((uint8_t *)(msg)) + 24);
        
        // copy strings
        
        // copy buffers
        o_frag_size = ((uint64_t )(((_binding->tx_union).move_trusted_call).metasize));
        memcpy(msg2, &o_frag_size, 8);
        memcpy(msg2 + 8, ((_binding->tx_union).move_trusted_call).meta, o_frag_size);
        msg2 = ((msg2 + o_frag_size) + 8);
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_move_trusted_call__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_move_trusted_call__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_move_response__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 16;
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "tid"] 0],[ArgFieldFragment uint64 [NamedField "error"] 0]]
        msg[0] = (bulk_ctrl_move_response__msgnum | (((uint64_t )(((_binding->tx_union).move_response).tid)) << 16));
        msg[1] = (((_binding->tx_union).move_response).error);
        
        
        // copy strings
        
        // copy buffers
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_move_response__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_move_response__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_copy_untrusted_call__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    uint8_t *msg2;
    uint64_t o_frag_size;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 24;
        msg_size = (msg_size + ((((_binding->tx_union).copy_untrusted_call).metasize) + 8));
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "pool_id_machine",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "pool_id_dom",NamedField "poolid"] 0,ArgFieldFragment uint32 [NamedField "pool_id_local",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "bufferid"] 0,ArgFieldFragment uint32 [NamedField "tid"] 0]]
        msg[0] = (bulk_ctrl_copy_untrusted_call__msgnum | (((uint64_t )((((_binding->tx_union).copy_untrusted_call).poolid).pool_id_machine)) << 16));
        msg[1] = (((((_binding->tx_union).copy_untrusted_call).poolid).pool_id_dom) | (((uint64_t )((((_binding->tx_union).copy_untrusted_call).poolid).pool_id_local)) << 32));
        msg[2] = ((((_binding->tx_union).copy_untrusted_call).bufferid) | (((uint64_t )(((_binding->tx_union).copy_untrusted_call).tid)) << 32));
        msg2 = (((uint8_t *)(msg)) + 24);
        
        // copy strings
        
        // copy buffers
        o_frag_size = ((uint64_t )(((_binding->tx_union).copy_untrusted_call).metasize));
        memcpy(msg2, &o_frag_size, 8);
        memcpy(msg2 + 8, ((_binding->tx_union).copy_untrusted_call).meta, o_frag_size);
        msg2 = ((msg2 + o_frag_size) + 8);
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_copy_untrusted_call__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_copy_untrusted_call__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        free(mb->message);
        // send caps
        bulk_ctrl_multihop_cap_send_handler(mb);
        return;
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_copy_trusted_call__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    uint8_t *msg2;
    uint64_t o_frag_size;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 24;
        msg_size = (msg_size + ((((_binding->tx_union).copy_trusted_call).metasize) + 8));
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "pool_id_machine",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "pool_id_dom",NamedField "poolid"] 0,ArgFieldFragment uint32 [NamedField "pool_id_local",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "bufferid"] 0,ArgFieldFragment uint32 [NamedField "tid"] 0]]
        msg[0] = (bulk_ctrl_copy_trusted_call__msgnum | (((uint64_t )((((_binding->tx_union).copy_trusted_call).poolid).pool_id_machine)) << 16));
        msg[1] = (((((_binding->tx_union).copy_trusted_call).poolid).pool_id_dom) | (((uint64_t )((((_binding->tx_union).copy_trusted_call).poolid).pool_id_local)) << 32));
        msg[2] = ((((_binding->tx_union).copy_trusted_call).bufferid) | (((uint64_t )(((_binding->tx_union).copy_trusted_call).tid)) << 32));
        msg2 = (((uint8_t *)(msg)) + 24);
        
        // copy strings
        
        // copy buffers
        o_frag_size = ((uint64_t )(((_binding->tx_union).copy_trusted_call).metasize));
        memcpy(msg2, &o_frag_size, 8);
        memcpy(msg2 + 8, ((_binding->tx_union).copy_trusted_call).meta, o_frag_size);
        msg2 = ((msg2 + o_frag_size) + 8);
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_copy_trusted_call__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_copy_trusted_call__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_copy_response__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 16;
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "tid"] 0],[ArgFieldFragment uint64 [NamedField "error"] 0]]
        msg[0] = (bulk_ctrl_copy_response__msgnum | (((uint64_t )(((_binding->tx_union).copy_response).tid)) << 16));
        msg[1] = (((_binding->tx_union).copy_response).error);
        
        
        // copy strings
        
        // copy buffers
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_copy_response__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_copy_response__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_pass_untrusted_call__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    uint8_t *msg2;
    uint64_t o_frag_size;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 24;
        msg_size = (msg_size + ((((_binding->tx_union).pass_untrusted_call).metasize) + 8));
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "pool_id_machine",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "pool_id_dom",NamedField "poolid"] 0,ArgFieldFragment uint32 [NamedField "pool_id_local",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "bufferid"] 0,ArgFieldFragment uint32 [NamedField "tid"] 0]]
        msg[0] = (bulk_ctrl_pass_untrusted_call__msgnum | (((uint64_t )((((_binding->tx_union).pass_untrusted_call).poolid).pool_id_machine)) << 16));
        msg[1] = (((((_binding->tx_union).pass_untrusted_call).poolid).pool_id_dom) | (((uint64_t )((((_binding->tx_union).pass_untrusted_call).poolid).pool_id_local)) << 32));
        msg[2] = ((((_binding->tx_union).pass_untrusted_call).bufferid) | (((uint64_t )(((_binding->tx_union).pass_untrusted_call).tid)) << 32));
        msg2 = (((uint8_t *)(msg)) + 24);
        
        // copy strings
        
        // copy buffers
        o_frag_size = ((uint64_t )(((_binding->tx_union).pass_untrusted_call).metasize));
        memcpy(msg2, &o_frag_size, 8);
        memcpy(msg2 + 8, ((_binding->tx_union).pass_untrusted_call).meta, o_frag_size);
        msg2 = ((msg2 + o_frag_size) + 8);
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_pass_untrusted_call__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_pass_untrusted_call__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        free(mb->message);
        // send caps
        bulk_ctrl_multihop_cap_send_handler(mb);
        return;
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_pass_trusted_call__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    uint8_t *msg2;
    uint64_t o_frag_size;
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 24;
        msg_size = (msg_size + ((((_binding->tx_union).pass_trusted_call).metasize) + 8));
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "pool_id_machine",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "pool_id_dom",NamedField "poolid"] 0,ArgFieldFragment uint32 [NamedField "pool_id_local",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "bufferid"] 0,ArgFieldFragment uint32 [NamedField "tid"] 0]]
        msg[0] = (bulk_ctrl_pass_trusted_call__msgnum | (((uint64_t )((((_binding->tx_union).pass_trusted_call).poolid).pool_id_machine)) << 16));
        msg[1] = (((((_binding->tx_union).pass_trusted_call).poolid).pool_id_dom) | (((uint64_t )((((_binding->tx_union).pass_trusted_call).poolid).pool_id_local)) << 32));
        msg[2] = ((((_binding->tx_union).pass_trusted_call).bufferid) | (((uint64_t )(((_binding->tx_union).pass_trusted_call).tid)) << 32));
        msg2 = (((uint8_t *)(msg)) + 24);
        
        // copy strings
        
        // copy buffers
        o_frag_size = ((uint64_t )(((_binding->tx_union).pass_trusted_call).metasize));
        memcpy(msg2, &o_frag_size, 8);
        memcpy(msg2 + 8, ((_binding->tx_union).pass_trusted_call).meta, o_frag_size);
        msg2 = ((msg2 + o_frag_size) + 8);
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_pass_trusted_call__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_pass_trusted_call__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_pass_response__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 16;
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "tid"] 0],[ArgFieldFragment uint64 [NamedField "error"] 0]]
        msg[0] = (bulk_ctrl_pass_response__msgnum | (((uint64_t )(((_binding->tx_union).pass_response).tid)) << 16));
        msg[1] = (((_binding->tx_union).pass_response).error);
        
        
        // copy strings
        
        // copy buffers
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_pass_response__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_pass_response__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_release_call__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 24;
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "pool_id_machine",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "pool_id_dom",NamedField "poolid"] 0,ArgFieldFragment uint32 [NamedField "pool_id_local",NamedField "poolid"] 0],[ArgFieldFragment uint32 [NamedField "bufferid"] 0,ArgFieldFragment uint32 [NamedField "tid"] 0]]
        msg[0] = (bulk_ctrl_release_call__msgnum | (((uint64_t )((((_binding->tx_union).release_call).poolid).pool_id_machine)) << 16));
        msg[1] = (((((_binding->tx_union).release_call).poolid).pool_id_dom) | (((uint64_t )((((_binding->tx_union).release_call).poolid).pool_id_local)) << 32));
        msg[2] = ((((_binding->tx_union).release_call).bufferid) | (((uint64_t )(((_binding->tx_union).release_call).tid)) << 32));
        
        
        // copy strings
        
        // copy buffers
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_release_call__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_release_call__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}

static  void bulk_ctrl_release_response__multihop_send_handler(void *arg)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    errval_t err = SYS_ERR_OK;
    uint64_t *msg;
    uint64_t msg_size;
    
    
    // Switch on current outgoing message fragment
    switch (_binding->tx_msg_fragment) {
    case 0:
        // Calculate size of message & allocate it
        msg_size = 16;
        assert(msg_size != 0);
        msg = malloc(msg_size);
        
        // copy words from fixed size fragments
        // [[MsgCode,ArgFieldFragment uint32 [NamedField "tid"] 0],[ArgFieldFragment uint64 [NamedField "error"] 0]]
        msg[0] = (bulk_ctrl_release_response__msgnum | (((uint64_t )(((_binding->tx_union).release_response).tid)) << 16));
        msg[1] = (((_binding->tx_union).release_response).error);
        
        
        // copy strings
        
        // copy buffers
        
        // try to send!
        (_binding->tx_msg_fragment)++;
        mb->message = msg;
        err = multihop_send_message(&(mb->chan), MKCONT(bulk_ctrl_release_response__multihop_send_handler, _binding), msg, msg_size);
        if (err_no(err) == FLOUNDER_ERR_TX_BUSY) {
            (_binding->tx_msg_fragment)--;
            err = multihop_chan_register_send(&(mb->chan), _binding->waitset, MKCONT(bulk_ctrl_release_response__multihop_send_handler, _binding));
            assert(err_is_ok(err));
        }
        if (err_is_fail(err)) {
            break;
        } else {
            return;
        }
    case 1:
        // all fragments are sent
        free(mb->message);
        if (multihop_chan_is_window_full(&(mb->chan))) {
            mb->trigger_chan = true;
            return;
        } else {
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
            return;
        }
    default:
        assert(!("invalid fragment"));
        err = FLOUNDER_ERR_INVALID_STATE;
    }
    
    
    // Report error to user
    (_binding->error_handler)(_binding, err);
    _binding->tx_msgnum = 0;
    flounder_support_trigger_chan(&(_binding->register_chanstate));
    flounder_support_deregister_chan(&(_binding->tx_cont_chanstate));
}


/*
 * Cap receive handlers
 */
 void bulk_ctrl_multihop_caps_rx_handler(void *arg, errval_t success, struct capref cap, uint32_t capid)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    
    assert(capid == ((mb->capst).rx_capnum));
    
    // Check if there's an associated error
    // FIXME: how should we report this to the user? at present we just deliver a NULL capref
    if (err_is_fail(success)) {
        DEBUG_ERR(success, "could not send cap over multihop channel");
    }
    
    // Switch on current incoming message
    switch (_binding->rx_msgnum) {
    case bulk_ctrl_assign_pool_call__msgnum:
        // Switch on current incoming cap
        switch (((mb->capst).rx_capnum)++) {
        case 0:
            (((_binding->rx_union).assign_pool_call).pool).cap = cap;
            if (mb->trigger_chan) {
                mb->trigger_chan = false;
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            FL_DEBUG("multihop RX bulk_ctrl.assign_pool_call\n");
            assert(((_binding->rx_vtbl).assign_pool_call) != NULL);
            ((_binding->rx_vtbl).assign_pool_call)(_binding, ((_binding->rx_union).assign_pool_call).pool, ((_binding->rx_union).assign_pool_call).id);
            _binding->rx_msgnum = 0;
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_move_untrusted_call__msgnum:
        // Switch on current incoming cap
        switch (((mb->capst).rx_capnum)++) {
        case 0:
            ((_binding->rx_union).move_untrusted_call).cap = cap;
            if (mb->trigger_chan) {
                mb->trigger_chan = false;
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            FL_DEBUG("multihop RX bulk_ctrl.move_untrusted_call\n");
            assert(((_binding->rx_vtbl).move_untrusted_call) != NULL);
            ((_binding->rx_vtbl).move_untrusted_call)(_binding, ((_binding->rx_union).move_untrusted_call).poolid, ((_binding->rx_union).move_untrusted_call).bufferid, ((_binding->rx_union).move_untrusted_call).tid, ((_binding->rx_union).move_untrusted_call).cap, ((_binding->rx_union).move_untrusted_call).meta, ((_binding->rx_union).move_untrusted_call).metasize);
            _binding->rx_msgnum = 0;
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_copy_untrusted_call__msgnum:
        // Switch on current incoming cap
        switch (((mb->capst).rx_capnum)++) {
        case 0:
            ((_binding->rx_union).copy_untrusted_call).cap = cap;
            if (mb->trigger_chan) {
                mb->trigger_chan = false;
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            FL_DEBUG("multihop RX bulk_ctrl.copy_untrusted_call\n");
            assert(((_binding->rx_vtbl).copy_untrusted_call) != NULL);
            ((_binding->rx_vtbl).copy_untrusted_call)(_binding, ((_binding->rx_union).copy_untrusted_call).poolid, ((_binding->rx_union).copy_untrusted_call).bufferid, ((_binding->rx_union).copy_untrusted_call).tid, ((_binding->rx_union).copy_untrusted_call).cap, ((_binding->rx_union).copy_untrusted_call).meta, ((_binding->rx_union).copy_untrusted_call).metasize);
            _binding->rx_msgnum = 0;
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    case bulk_ctrl_pass_untrusted_call__msgnum:
        // Switch on current incoming cap
        switch (((mb->capst).rx_capnum)++) {
        case 0:
            ((_binding->rx_union).pass_untrusted_call).cap = cap;
            if (mb->trigger_chan) {
                mb->trigger_chan = false;
                _binding->tx_msgnum = 0;
                flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
                flounder_support_trigger_chan(&(_binding->register_chanstate));
            }
            FL_DEBUG("multihop RX bulk_ctrl.pass_untrusted_call\n");
            assert(((_binding->rx_vtbl).pass_untrusted_call) != NULL);
            ((_binding->rx_vtbl).pass_untrusted_call)(_binding, ((_binding->rx_union).pass_untrusted_call).poolid, ((_binding->rx_union).pass_untrusted_call).bufferid, ((_binding->rx_union).pass_untrusted_call).tid, ((_binding->rx_union).pass_untrusted_call).cap, ((_binding->rx_union).pass_untrusted_call).meta, ((_binding->rx_union).pass_untrusted_call).metasize);
            _binding->rx_msgnum = 0;
            break;
        default:
            assert(!("invalid cap number"));
            (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
        }
        break;
    default:
        assert(!("invalid message number"));
        (_binding->error_handler)(_binding, FLOUNDER_ERR_INVALID_STATE);
    }
}


/*
 * Message sender functions
 */
static  errval_t bulk_ctrl_negotiate_call__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_role_t role, bulk_ctrl_trust_t trust)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_negotiate_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).negotiate_call).role = role;
    ((_binding->tx_union).negotiate_call).trust = trust;
    FL_DEBUG("multihop TX bulk_ctrl.negotiate_call\n");
    
    // try to send!
    bulk_ctrl_negotiate_call__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_negotiate_response__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, bulk_ctrl_direction_t match_direction, bulk_ctrl_role_t match_role, uint64_t meta_size)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_negotiate_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).negotiate_response).error = error;
    ((_binding->tx_union).negotiate_response).match_direction = match_direction;
    ((_binding->tx_union).negotiate_response).match_role = match_role;
    ((_binding->tx_union).negotiate_response).meta_size = meta_size;
    FL_DEBUG("multihop TX bulk_ctrl.negotiate_response\n");
    
    // try to send!
    bulk_ctrl_negotiate_response__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_assign_pool_call__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_pool_t pool, uint64_t id)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_assign_pool_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).assign_pool_call).pool = pool;
    ((_binding->tx_union).assign_pool_call).id = id;
    FL_DEBUG("multihop TX bulk_ctrl.assign_pool_call\n");
    
    // try to send!
    bulk_ctrl_assign_pool_call__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_assign_pool_response__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint64_t id)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_assign_pool_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).assign_pool_response).error = error;
    ((_binding->tx_union).assign_pool_response).id = id;
    FL_DEBUG("multihop TX bulk_ctrl.assign_pool_response\n");
    
    // try to send!
    bulk_ctrl_assign_pool_response__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_move_untrusted_call__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, struct capref cap, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_move_untrusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).move_untrusted_call).poolid = poolid;
    ((_binding->tx_union).move_untrusted_call).bufferid = bufferid;
    ((_binding->tx_union).move_untrusted_call).tid = tid;
    ((_binding->tx_union).move_untrusted_call).cap = cap;
    ((_binding->tx_union).move_untrusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).move_untrusted_call).metasize = metasize;
    FL_DEBUG("multihop TX bulk_ctrl.move_untrusted_call\n");
    
    // try to send!
    bulk_ctrl_move_untrusted_call__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_move_trusted_call__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_move_trusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).move_trusted_call).poolid = poolid;
    ((_binding->tx_union).move_trusted_call).bufferid = bufferid;
    ((_binding->tx_union).move_trusted_call).tid = tid;
    ((_binding->tx_union).move_trusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).move_trusted_call).metasize = metasize;
    FL_DEBUG("multihop TX bulk_ctrl.move_trusted_call\n");
    
    // try to send!
    bulk_ctrl_move_trusted_call__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_move_response__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_move_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).move_response).error = error;
    ((_binding->tx_union).move_response).tid = tid;
    FL_DEBUG("multihop TX bulk_ctrl.move_response\n");
    
    // try to send!
    bulk_ctrl_move_response__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_copy_untrusted_call__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, struct capref cap, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_copy_untrusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).copy_untrusted_call).poolid = poolid;
    ((_binding->tx_union).copy_untrusted_call).bufferid = bufferid;
    ((_binding->tx_union).copy_untrusted_call).tid = tid;
    ((_binding->tx_union).copy_untrusted_call).cap = cap;
    ((_binding->tx_union).copy_untrusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).copy_untrusted_call).metasize = metasize;
    FL_DEBUG("multihop TX bulk_ctrl.copy_untrusted_call\n");
    
    // try to send!
    bulk_ctrl_copy_untrusted_call__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_copy_trusted_call__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_copy_trusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).copy_trusted_call).poolid = poolid;
    ((_binding->tx_union).copy_trusted_call).bufferid = bufferid;
    ((_binding->tx_union).copy_trusted_call).tid = tid;
    ((_binding->tx_union).copy_trusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).copy_trusted_call).metasize = metasize;
    FL_DEBUG("multihop TX bulk_ctrl.copy_trusted_call\n");
    
    // try to send!
    bulk_ctrl_copy_trusted_call__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_copy_response__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_copy_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).copy_response).error = error;
    ((_binding->tx_union).copy_response).tid = tid;
    FL_DEBUG("multihop TX bulk_ctrl.copy_response\n");
    
    // try to send!
    bulk_ctrl_copy_response__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_pass_untrusted_call__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, struct capref cap, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_pass_untrusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).pass_untrusted_call).poolid = poolid;
    ((_binding->tx_union).pass_untrusted_call).bufferid = bufferid;
    ((_binding->tx_union).pass_untrusted_call).tid = tid;
    ((_binding->tx_union).pass_untrusted_call).cap = cap;
    ((_binding->tx_union).pass_untrusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).pass_untrusted_call).metasize = metasize;
    FL_DEBUG("multihop TX bulk_ctrl.pass_untrusted_call\n");
    
    // try to send!
    bulk_ctrl_pass_untrusted_call__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_pass_trusted_call__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid, const uint8_t *meta, size_t metasize)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_pass_trusted_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).pass_trusted_call).poolid = poolid;
    ((_binding->tx_union).pass_trusted_call).bufferid = bufferid;
    ((_binding->tx_union).pass_trusted_call).tid = tid;
    ((_binding->tx_union).pass_trusted_call).meta = ((uint8_t *)(meta));
    ((_binding->tx_union).pass_trusted_call).metasize = metasize;
    FL_DEBUG("multihop TX bulk_ctrl.pass_trusted_call\n");
    
    // try to send!
    bulk_ctrl_pass_trusted_call__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_pass_response__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_pass_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).pass_response).error = error;
    ((_binding->tx_union).pass_response).tid = tid;
    FL_DEBUG("multihop TX bulk_ctrl.pass_response\n");
    
    // try to send!
    bulk_ctrl_pass_response__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_release_call__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_poolid_t poolid, uint32_t bufferid, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_release_call__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).release_call).poolid = poolid;
    ((_binding->tx_union).release_call).bufferid = bufferid;
    ((_binding->tx_union).release_call).tid = tid;
    FL_DEBUG("multihop TX bulk_ctrl.release_call\n");
    
    // try to send!
    bulk_ctrl_release_call__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}

static  errval_t bulk_ctrl_release_response__multihop_send(struct bulk_ctrl_binding *_binding, struct event_closure _continuation, bulk_ctrl_error_t error, uint32_t tid)
{
    // check that we can accept an outgoing message
    if ((_binding->tx_msgnum) != 0) {
        return(FLOUNDER_ERR_TX_BUSY);
    }
    
    // register send continuation
    if ((_continuation.handler) != NULL) {
        errval_t _err;
        _err = flounder_support_register(_binding->waitset, &(_binding->tx_cont_chanstate), _continuation, false);
        // may fail if previous continuation hasn't fired yet
        if (err_is_fail(_err)) {
            if (err_no(_err) == LIB_ERR_CHAN_ALREADY_REGISTERED) {
                return(FLOUNDER_ERR_TX_BUSY);
            } else {
                assert(!("shouldn't happen"));
                return(_err);
            }
        }
    }
    
    // store message number and the arguments
    _binding->tx_msgnum = bulk_ctrl_release_response__msgnum;
    _binding->tx_msg_fragment = 0;
    ((_binding->tx_union).release_response).error = error;
    ((_binding->tx_union).release_response).tid = tid;
    FL_DEBUG("multihop TX bulk_ctrl.release_response\n");
    
    // try to send!
    bulk_ctrl_release_response__multihop_send_handler(_binding);
    
    return(SYS_ERR_OK);
}


/*
 * Send vtable
 */
static  struct bulk_ctrl_tx_vtbl bulk_ctrl_multihop_tx_vtbl = {
    .negotiate_call = bulk_ctrl_negotiate_call__multihop_send,
    .negotiate_response = bulk_ctrl_negotiate_response__multihop_send,
    .assign_pool_call = bulk_ctrl_assign_pool_call__multihop_send,
    .assign_pool_response = bulk_ctrl_assign_pool_response__multihop_send,
    .move_untrusted_call = bulk_ctrl_move_untrusted_call__multihop_send,
    .move_trusted_call = bulk_ctrl_move_trusted_call__multihop_send,
    .move_response = bulk_ctrl_move_response__multihop_send,
    .copy_untrusted_call = bulk_ctrl_copy_untrusted_call__multihop_send,
    .copy_trusted_call = bulk_ctrl_copy_trusted_call__multihop_send,
    .copy_response = bulk_ctrl_copy_response__multihop_send,
    .pass_untrusted_call = bulk_ctrl_pass_untrusted_call__multihop_send,
    .pass_trusted_call = bulk_ctrl_pass_trusted_call__multihop_send,
    .pass_response = bulk_ctrl_pass_response__multihop_send,
    .release_call = bulk_ctrl_release_call__multihop_send,
    .release_response = bulk_ctrl_release_response__multihop_send,
};
/*
 * Receive handler
 */
 void bulk_ctrl_multihop_rx_handler(void *arg, uint8_t *message, size_t message_len)
{
    // Get the binding state from our argument pointer
    struct bulk_ctrl_binding *_binding = arg;
    struct bulk_ctrl_multihop_binding *mb = arg;
    
    uint64_t o_frag_size;
    uint8_t *msg;
    
    // if this a dummy message?
    if (message_len == 0) {
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        return;
    }
    // is this the start of a new message?
    if ((_binding->rx_msgnum) == 0) {
        // unmarshall message number from first word, set fragment to 0
        _binding->rx_msgnum = ((message[0]) & 0xffff);
        _binding->rx_msg_fragment = 0;
        (mb->capst).rx_capnum = 0;
    } else {
        assert(!"should not happen");
    }
    
    // switch on message number
    switch (_binding->rx_msgnum) {
    case bulk_ctrl_negotiate_call__msgnum:
        // store fixed size fragments
        ((_binding->rx_union).negotiate_call).role = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        ((_binding->rx_union).negotiate_call).trust = ((((uint64_t *)(message))[1]) & 0xffffffff);
        msg = (message + 16);
        
        // receive strings
        
        // receive buffers
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.negotiate_call\n");
        assert(((_binding->rx_vtbl).negotiate_call) != NULL);
        ((_binding->rx_vtbl).negotiate_call)(_binding, ((_binding->rx_union).negotiate_call).role, ((_binding->rx_union).negotiate_call).trust);
        _binding->rx_msgnum = 0;
        break;
    case bulk_ctrl_negotiate_response__msgnum:
        // store fixed size fragments
        ((_binding->rx_union).negotiate_response).match_direction = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        ((_binding->rx_union).negotiate_response).match_role = ((((uint64_t *)(message))[1]) & 0xffffffff);
        ((_binding->rx_union).negotiate_response).error = (((uint64_t *)(message))[2]);
        ((_binding->rx_union).negotiate_response).meta_size = (((uint64_t *)(message))[3]);
        msg = (message + 32);
        
        // receive strings
        
        // receive buffers
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.negotiate_response\n");
        assert(((_binding->rx_vtbl).negotiate_response) != NULL);
        ((_binding->rx_vtbl).negotiate_response)(_binding, ((_binding->rx_union).negotiate_response).error, ((_binding->rx_union).negotiate_response).match_direction, ((_binding->rx_union).negotiate_response).match_role, ((_binding->rx_union).negotiate_response).meta_size);
        _binding->rx_msgnum = 0;
        break;
    case bulk_ctrl_assign_pool_call__msgnum:
        // store fixed size fragments
        (((_binding->rx_union).assign_pool_call).pool).pool_id_machine = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        (((_binding->rx_union).assign_pool_call).pool).pool_id_dom = ((((uint64_t *)(message))[1]) & 0xffffffff);
        (((_binding->rx_union).assign_pool_call).pool).pool_id_local = (((((uint64_t *)(message))[1]) >> 32) & 0xffffffff);
        (((_binding->rx_union).assign_pool_call).pool).trust = ((((uint64_t *)(message))[2]) & 0xffffffff);
        (((_binding->rx_union).assign_pool_call).pool).buffer_size = (((((uint64_t *)(message))[2]) >> 32) & 0xffffffff);
        (((_binding->rx_union).assign_pool_call).pool).num_buffers = ((((uint64_t *)(message))[3]) & 0xffffffff);
        ((_binding->rx_union).assign_pool_call).id = (((uint64_t *)(message))[4]);
        msg = (message + 40);
        
        // receive strings
        
        // receive buffers
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        (_binding->rx_msg_fragment)++;
        break;
    case bulk_ctrl_assign_pool_response__msgnum:
        // store fixed size fragments
        ((_binding->rx_union).assign_pool_response).error = (((uint64_t *)(message))[1]);
        ((_binding->rx_union).assign_pool_response).id = (((uint64_t *)(message))[2]);
        msg = (message + 24);
        
        // receive strings
        
        // receive buffers
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.assign_pool_response\n");
        assert(((_binding->rx_vtbl).assign_pool_response) != NULL);
        ((_binding->rx_vtbl).assign_pool_response)(_binding, ((_binding->rx_union).assign_pool_response).error, ((_binding->rx_union).assign_pool_response).id);
        _binding->rx_msgnum = 0;
        break;
    case bulk_ctrl_move_untrusted_call__msgnum:
        // store fixed size fragments
        (((_binding->rx_union).move_untrusted_call).poolid).pool_id_machine = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        (((_binding->rx_union).move_untrusted_call).poolid).pool_id_dom = ((((uint64_t *)(message))[1]) & 0xffffffff);
        (((_binding->rx_union).move_untrusted_call).poolid).pool_id_local = (((((uint64_t *)(message))[1]) >> 32) & 0xffffffff);
        ((_binding->rx_union).move_untrusted_call).bufferid = ((((uint64_t *)(message))[2]) & 0xffffffff);
        ((_binding->rx_union).move_untrusted_call).tid = (((((uint64_t *)(message))[2]) >> 32) & 0xffffffff);
        msg = (message + 24);
        
        // receive strings
        
        // receive buffers
        o_frag_size = 0;
        memcpy(&o_frag_size, msg, 8);
        ((_binding->rx_union).move_untrusted_call).meta = malloc(o_frag_size);
        memcpy(((_binding->rx_union).move_untrusted_call).meta, msg + 8, o_frag_size);
        ((_binding->rx_union).move_untrusted_call).metasize = ((size_t )(o_frag_size));
        msg = ((msg + o_frag_size) + 8);
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        (_binding->rx_msg_fragment)++;
        break;
    case bulk_ctrl_move_trusted_call__msgnum:
        // store fixed size fragments
        (((_binding->rx_union).move_trusted_call).poolid).pool_id_machine = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        (((_binding->rx_union).move_trusted_call).poolid).pool_id_dom = ((((uint64_t *)(message))[1]) & 0xffffffff);
        (((_binding->rx_union).move_trusted_call).poolid).pool_id_local = (((((uint64_t *)(message))[1]) >> 32) & 0xffffffff);
        ((_binding->rx_union).move_trusted_call).bufferid = ((((uint64_t *)(message))[2]) & 0xffffffff);
        ((_binding->rx_union).move_trusted_call).tid = (((((uint64_t *)(message))[2]) >> 32) & 0xffffffff);
        msg = (message + 24);
        
        // receive strings
        
        // receive buffers
        o_frag_size = 0;
        memcpy(&o_frag_size, msg, 8);
        ((_binding->rx_union).move_trusted_call).meta = malloc(o_frag_size);
        memcpy(((_binding->rx_union).move_trusted_call).meta, msg + 8, o_frag_size);
        ((_binding->rx_union).move_trusted_call).metasize = ((size_t )(o_frag_size));
        msg = ((msg + o_frag_size) + 8);
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.move_trusted_call\n");
        assert(((_binding->rx_vtbl).move_trusted_call) != NULL);
        ((_binding->rx_vtbl).move_trusted_call)(_binding, ((_binding->rx_union).move_trusted_call).poolid, ((_binding->rx_union).move_trusted_call).bufferid, ((_binding->rx_union).move_trusted_call).tid, ((_binding->rx_union).move_trusted_call).meta, ((_binding->rx_union).move_trusted_call).metasize);
        _binding->rx_msgnum = 0;
        break;
    case bulk_ctrl_move_response__msgnum:
        // store fixed size fragments
        ((_binding->rx_union).move_response).tid = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        ((_binding->rx_union).move_response).error = (((uint64_t *)(message))[1]);
        msg = (message + 16);
        
        // receive strings
        
        // receive buffers
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.move_response\n");
        assert(((_binding->rx_vtbl).move_response) != NULL);
        ((_binding->rx_vtbl).move_response)(_binding, ((_binding->rx_union).move_response).error, ((_binding->rx_union).move_response).tid);
        _binding->rx_msgnum = 0;
        break;
    case bulk_ctrl_copy_untrusted_call__msgnum:
        // store fixed size fragments
        (((_binding->rx_union).copy_untrusted_call).poolid).pool_id_machine = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        (((_binding->rx_union).copy_untrusted_call).poolid).pool_id_dom = ((((uint64_t *)(message))[1]) & 0xffffffff);
        (((_binding->rx_union).copy_untrusted_call).poolid).pool_id_local = (((((uint64_t *)(message))[1]) >> 32) & 0xffffffff);
        ((_binding->rx_union).copy_untrusted_call).bufferid = ((((uint64_t *)(message))[2]) & 0xffffffff);
        ((_binding->rx_union).copy_untrusted_call).tid = (((((uint64_t *)(message))[2]) >> 32) & 0xffffffff);
        msg = (message + 24);
        
        // receive strings
        
        // receive buffers
        o_frag_size = 0;
        memcpy(&o_frag_size, msg, 8);
        ((_binding->rx_union).copy_untrusted_call).meta = malloc(o_frag_size);
        memcpy(((_binding->rx_union).copy_untrusted_call).meta, msg + 8, o_frag_size);
        ((_binding->rx_union).copy_untrusted_call).metasize = ((size_t )(o_frag_size));
        msg = ((msg + o_frag_size) + 8);
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        (_binding->rx_msg_fragment)++;
        break;
    case bulk_ctrl_copy_trusted_call__msgnum:
        // store fixed size fragments
        (((_binding->rx_union).copy_trusted_call).poolid).pool_id_machine = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        (((_binding->rx_union).copy_trusted_call).poolid).pool_id_dom = ((((uint64_t *)(message))[1]) & 0xffffffff);
        (((_binding->rx_union).copy_trusted_call).poolid).pool_id_local = (((((uint64_t *)(message))[1]) >> 32) & 0xffffffff);
        ((_binding->rx_union).copy_trusted_call).bufferid = ((((uint64_t *)(message))[2]) & 0xffffffff);
        ((_binding->rx_union).copy_trusted_call).tid = (((((uint64_t *)(message))[2]) >> 32) & 0xffffffff);
        msg = (message + 24);
        
        // receive strings
        
        // receive buffers
        o_frag_size = 0;
        memcpy(&o_frag_size, msg, 8);
        ((_binding->rx_union).copy_trusted_call).meta = malloc(o_frag_size);
        memcpy(((_binding->rx_union).copy_trusted_call).meta, msg + 8, o_frag_size);
        ((_binding->rx_union).copy_trusted_call).metasize = ((size_t )(o_frag_size));
        msg = ((msg + o_frag_size) + 8);
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.copy_trusted_call\n");
        assert(((_binding->rx_vtbl).copy_trusted_call) != NULL);
        ((_binding->rx_vtbl).copy_trusted_call)(_binding, ((_binding->rx_union).copy_trusted_call).poolid, ((_binding->rx_union).copy_trusted_call).bufferid, ((_binding->rx_union).copy_trusted_call).tid, ((_binding->rx_union).copy_trusted_call).meta, ((_binding->rx_union).copy_trusted_call).metasize);
        _binding->rx_msgnum = 0;
        break;
    case bulk_ctrl_copy_response__msgnum:
        // store fixed size fragments
        ((_binding->rx_union).copy_response).tid = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        ((_binding->rx_union).copy_response).error = (((uint64_t *)(message))[1]);
        msg = (message + 16);
        
        // receive strings
        
        // receive buffers
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.copy_response\n");
        assert(((_binding->rx_vtbl).copy_response) != NULL);
        ((_binding->rx_vtbl).copy_response)(_binding, ((_binding->rx_union).copy_response).error, ((_binding->rx_union).copy_response).tid);
        _binding->rx_msgnum = 0;
        break;
    case bulk_ctrl_pass_untrusted_call__msgnum:
        // store fixed size fragments
        (((_binding->rx_union).pass_untrusted_call).poolid).pool_id_machine = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        (((_binding->rx_union).pass_untrusted_call).poolid).pool_id_dom = ((((uint64_t *)(message))[1]) & 0xffffffff);
        (((_binding->rx_union).pass_untrusted_call).poolid).pool_id_local = (((((uint64_t *)(message))[1]) >> 32) & 0xffffffff);
        ((_binding->rx_union).pass_untrusted_call).bufferid = ((((uint64_t *)(message))[2]) & 0xffffffff);
        ((_binding->rx_union).pass_untrusted_call).tid = (((((uint64_t *)(message))[2]) >> 32) & 0xffffffff);
        msg = (message + 24);
        
        // receive strings
        
        // receive buffers
        o_frag_size = 0;
        memcpy(&o_frag_size, msg, 8);
        ((_binding->rx_union).pass_untrusted_call).meta = malloc(o_frag_size);
        memcpy(((_binding->rx_union).pass_untrusted_call).meta, msg + 8, o_frag_size);
        ((_binding->rx_union).pass_untrusted_call).metasize = ((size_t )(o_frag_size));
        msg = ((msg + o_frag_size) + 8);
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        (_binding->rx_msg_fragment)++;
        break;
    case bulk_ctrl_pass_trusted_call__msgnum:
        // store fixed size fragments
        (((_binding->rx_union).pass_trusted_call).poolid).pool_id_machine = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        (((_binding->rx_union).pass_trusted_call).poolid).pool_id_dom = ((((uint64_t *)(message))[1]) & 0xffffffff);
        (((_binding->rx_union).pass_trusted_call).poolid).pool_id_local = (((((uint64_t *)(message))[1]) >> 32) & 0xffffffff);
        ((_binding->rx_union).pass_trusted_call).bufferid = ((((uint64_t *)(message))[2]) & 0xffffffff);
        ((_binding->rx_union).pass_trusted_call).tid = (((((uint64_t *)(message))[2]) >> 32) & 0xffffffff);
        msg = (message + 24);
        
        // receive strings
        
        // receive buffers
        o_frag_size = 0;
        memcpy(&o_frag_size, msg, 8);
        ((_binding->rx_union).pass_trusted_call).meta = malloc(o_frag_size);
        memcpy(((_binding->rx_union).pass_trusted_call).meta, msg + 8, o_frag_size);
        ((_binding->rx_union).pass_trusted_call).metasize = ((size_t )(o_frag_size));
        msg = ((msg + o_frag_size) + 8);
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.pass_trusted_call\n");
        assert(((_binding->rx_vtbl).pass_trusted_call) != NULL);
        ((_binding->rx_vtbl).pass_trusted_call)(_binding, ((_binding->rx_union).pass_trusted_call).poolid, ((_binding->rx_union).pass_trusted_call).bufferid, ((_binding->rx_union).pass_trusted_call).tid, ((_binding->rx_union).pass_trusted_call).meta, ((_binding->rx_union).pass_trusted_call).metasize);
        _binding->rx_msgnum = 0;
        break;
    case bulk_ctrl_pass_response__msgnum:
        // store fixed size fragments
        ((_binding->rx_union).pass_response).tid = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        ((_binding->rx_union).pass_response).error = (((uint64_t *)(message))[1]);
        msg = (message + 16);
        
        // receive strings
        
        // receive buffers
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.pass_response\n");
        assert(((_binding->rx_vtbl).pass_response) != NULL);
        ((_binding->rx_vtbl).pass_response)(_binding, ((_binding->rx_union).pass_response).error, ((_binding->rx_union).pass_response).tid);
        _binding->rx_msgnum = 0;
        break;
    case bulk_ctrl_release_call__msgnum:
        // store fixed size fragments
        (((_binding->rx_union).release_call).poolid).pool_id_machine = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        (((_binding->rx_union).release_call).poolid).pool_id_dom = ((((uint64_t *)(message))[1]) & 0xffffffff);
        (((_binding->rx_union).release_call).poolid).pool_id_local = (((((uint64_t *)(message))[1]) >> 32) & 0xffffffff);
        ((_binding->rx_union).release_call).bufferid = ((((uint64_t *)(message))[2]) & 0xffffffff);
        ((_binding->rx_union).release_call).tid = (((((uint64_t *)(message))[2]) >> 32) & 0xffffffff);
        msg = (message + 24);
        
        // receive strings
        
        // receive buffers
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.release_call\n");
        assert(((_binding->rx_vtbl).release_call) != NULL);
        ((_binding->rx_vtbl).release_call)(_binding, ((_binding->rx_union).release_call).poolid, ((_binding->rx_union).release_call).bufferid, ((_binding->rx_union).release_call).tid);
        _binding->rx_msgnum = 0;
        break;
    case bulk_ctrl_release_response__msgnum:
        // store fixed size fragments
        ((_binding->rx_union).release_response).tid = (((((uint64_t *)(message))[0]) >> 16) & 0xffffffff);
        ((_binding->rx_union).release_response).error = (((uint64_t *)(message))[1]);
        msg = (message + 16);
        
        // receive strings
        
        // receive buffers
        
        free(message);
        if (mb->trigger_chan) {
            mb->trigger_chan = false;
            _binding->tx_msgnum = 0;
            flounder_support_trigger_chan(&(_binding->tx_cont_chanstate));
            flounder_support_trigger_chan(&(_binding->register_chanstate));
        }
        FL_DEBUG("multihop RX bulk_ctrl.release_response\n");
        assert(((_binding->rx_vtbl).release_response) != NULL);
        ((_binding->rx_vtbl).release_response)(_binding, ((_binding->rx_union).release_response).error, ((_binding->rx_union).release_response).tid);
        _binding->rx_msgnum = 0;
        break;
    default:
        (_binding->error_handler)(_binding, FLOUNDER_ERR_RX_INVALID_MSGNUM);
        return;
    }
}


/*
 * Control functions
 */
static  bool bulk_ctrl_multihop_can_send(struct bulk_ctrl_binding *b)
{
    struct bulk_ctrl_multihop_binding *mb = (struct bulk_ctrl_multihop_binding *)(b);
    return(((b->tx_msgnum) == 0) && (!multihop_chan_is_window_full(&(mb->chan))));
}

static  errval_t bulk_ctrl_multihop_register_send(struct bulk_ctrl_binding *b, struct waitset *ws, struct event_closure _continuation)
{
    return(flounder_support_register(ws, &(b->register_chanstate), _continuation, bulk_ctrl_multihop_can_send(b)));
}

static  void bulk_ctrl_multihop_default_error_handler(struct bulk_ctrl_binding *b, errval_t err)
{
    DEBUG_ERR(err, "asynchronous error in Flounder-generated bulk_ctrl multihop binding (default handler)");
    abort();
}

static  errval_t bulk_ctrl_multihop_change_waitset(struct bulk_ctrl_binding *_binding, struct waitset *ws)
{
    struct bulk_ctrl_multihop_binding *mb = (void *)(_binding);
    
    // change waitset on binding
    _binding->waitset = ws;
    
    // change waitset on multi-hop channel
    return(multihop_chan_change_waitset(&(mb->chan), ws));
}

static  errval_t bulk_ctrl_multihop_control(struct bulk_ctrl_binding *_binding, idc_control_t control)
{
    // No control flags supported
    return(SYS_ERR_OK);
}

/*
 * Functions to initialise/destroy the binding state
 */
 void bulk_ctrl_multihop_init(struct bulk_ctrl_multihop_binding *mb, struct waitset *waitset)
{
    (mb->b).st = NULL;
    (mb->b).waitset = waitset;
    event_mutex_init(&((mb->b).mutex), waitset);
    (mb->b).can_send = bulk_ctrl_multihop_can_send;
    (mb->b).register_send = bulk_ctrl_multihop_register_send;
    (mb->b).error_handler = bulk_ctrl_multihop_default_error_handler;
    (mb->b).tx_vtbl = bulk_ctrl_multihop_tx_vtbl;
    memset(&((mb->b).rx_vtbl), 0, sizeof((mb->b).rx_vtbl));
    flounder_support_waitset_chanstate_init(&((mb->b).register_chanstate));
    flounder_support_waitset_chanstate_init(&((mb->b).tx_cont_chanstate));
    (mb->b).tx_msgnum = 0;
    (mb->b).rx_msgnum = 0;
    (mb->b).tx_msg_fragment = 0;
    (mb->b).rx_msg_fragment = 0;
    (mb->b).tx_str_pos = 0;
    (mb->b).rx_str_pos = 0;
    (mb->b).tx_str_len = 0;
    (mb->b).rx_str_len = 0;
    (mb->b).bind_cont = NULL;
    (mb->b).change_waitset = bulk_ctrl_multihop_change_waitset;
    (mb->b).control = bulk_ctrl_multihop_control;
    mb->trigger_chan = false;
}

 void bulk_ctrl_multihop_destroy(struct bulk_ctrl_multihop_binding *mb)
{
    flounder_support_waitset_chanstate_destroy(&((mb->b).register_chanstate));
    flounder_support_waitset_chanstate_destroy(&((mb->b).tx_cont_chanstate));
    assert(! "NYI!");
}


/*
 * Bind function
 */
static  void bulk_ctrl_multihop_bind_continuation(void *st, errval_t err, struct multihop_chan *chan)
{
    struct bulk_ctrl_multihop_binding *mb = st;
    
    if (err_is_ok(err)) {
        // set receive handlers
        multihop_chan_set_receive_handler(&(mb->chan), (struct multihop_receive_handler){  .handler = bulk_ctrl_multihop_rx_handler,  .arg = st });
        multihop_chan_set_caps_receive_handlers(&(mb->chan), (struct monitor_cap_handlers){  .st = st,  .cap_receive_handler = bulk_ctrl_multihop_caps_rx_handler });
    } else {
        bulk_ctrl_multihop_destroy(mb);
    }
    
    ((mb->b).bind_cont)((mb->b).st, err, &(mb->b));
}

 errval_t bulk_ctrl_multihop_bind(struct bulk_ctrl_multihop_binding *mb, iref_t iref, bulk_ctrl_bind_continuation_fn *_continuation, void *st, struct waitset *waitset, idc_bind_flags_t flags)
{
    errval_t err;
    bulk_ctrl_multihop_init(mb, waitset);
    (mb->b).st = st;
    (mb->b).bind_cont = _continuation;
    err = multihop_chan_bind(&(mb->chan), (struct multihop_bind_continuation){  .handler = bulk_ctrl_multihop_bind_continuation,  .st = mb }, iref, waitset);
    if (err_is_fail(err)) {
        bulk_ctrl_multihop_destroy(mb);
    }
    return(err);
}


/*
 * Connect callback for export
 */
 errval_t bulk_ctrl_multihop_connect_handler(void *st, multihop_vci_t vci)
{
    struct bulk_ctrl_export *e = st;
    errval_t err;
    
    // allocate storage for binding
    struct bulk_ctrl_multihop_binding *mb = malloc(sizeof(struct bulk_ctrl_multihop_binding ));
    if (mb == NULL) {
        return(LIB_ERR_MALLOC_FAIL);
    }
    
    // initialize binding
    struct bulk_ctrl_binding *_binding = &(mb->b);
    bulk_ctrl_multihop_init(mb, e->waitset);
    (mb->chan).vci = vci;
    
    // run user's connect handler
    err = ((e->connect_cb)(e->st, _binding));
    if (err_is_fail(err)) {
        return(err);
    }
    
    // set receive handlers
    multihop_chan_set_receive_handler(&(mb->chan), (struct multihop_receive_handler){  .handler = bulk_ctrl_multihop_rx_handler,  .arg = mb });
    multihop_chan_set_caps_receive_handlers(&(mb->chan), (struct monitor_cap_handlers){  .st = mb,  .cap_receive_handler = bulk_ctrl_multihop_caps_rx_handler });
    
    // send back bind reply
    multihop_chan_send_bind_reply(&(mb->chan), SYS_ERR_OK, (mb->chan).vci, (mb->b).waitset);
    
    return(err);
}

#endif // CONFIG_FLOUNDER_BACKEND_MULTIHOP
