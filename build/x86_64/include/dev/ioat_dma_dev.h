#ifndef __ioat_dma_DEV_H
#define __ioat_dma_DEV_H 1
/*
 * DEVICE DEFINITION: IOAT DMA (Crystal Beach) registers
 * 
 * Copyright (c) 2010, ETH Zurich.
 * All rights reserved.
 * 
 * This file is distributed under the terms in the attached LICENSE
 * file. If you do not find this file, copies can be found by
 * writing to:
 * ETH Zurich D-INFK, Universitaetstr. 6, CH-8092 Zurich.
 * Attn: Systems Group.
 * 
 * THIS FILE IS AUTOMATICALLY GENERATED BY MACKEREL: DO NOT EDIT!
 */
#include <mackerel/mackerel.h>
#include <inttypes.h>
#undef __DN
#define __DN(x) ioat_dma ## _ ## x
/*
 * Constants defn: ioat_dma.device_ids (Crystal Beach DMA device IDs)
 *  - no width specified
 */
typedef uint16_t ioat_dma_device_ids_t;
#define ioat_dma_pci_vendorid ((ioat_dma_device_ids_t)0x8086)
#define ioat_dma_pci_deviceid_0 ((ioat_dma_device_ids_t)0xe20)
#define ioat_dma_pci_deviceid_1 ((ioat_dma_device_ids_t)0xe21)
#define ioat_dma_pci_deviceid_2 ((ioat_dma_device_ids_t)0xe22)
#define ioat_dma_pci_deviceid_3 ((ioat_dma_device_ids_t)0xe23)
#define ioat_dma_pci_deviceid_4 ((ioat_dma_device_ids_t)0xe24)
#define ioat_dma_pci_deviceid_5 ((ioat_dma_device_ids_t)0xe25)
#define ioat_dma_pci_deviceid_6 ((ioat_dma_device_ids_t)0xe26)
#define ioat_dma_pci_deviceid_7 ((ioat_dma_device_ids_t)0xe27)

static inline char *ioat_dma_device_ids_describe(ioat_dma_device_ids_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_device_ids_describe(ioat_dma_device_ids_t _e)
{
    switch (_e) {
    case ioat_dma_pci_vendorid:
        return("pci_vendorid: Intel Corporation");
    case ioat_dma_pci_deviceid_0:
        return("pci_deviceid_0: DMA Channel 0");
    case ioat_dma_pci_deviceid_1:
        return("pci_deviceid_1: DMA Channel 1");
    case ioat_dma_pci_deviceid_2:
        return("pci_deviceid_2: DMA Channel 2");
    case ioat_dma_pci_deviceid_3:
        return("pci_deviceid_3: DMA Channel 3");
    case ioat_dma_pci_deviceid_4:
        return("pci_deviceid_4: DMA Channel 4");
    case ioat_dma_pci_deviceid_5:
        return("pci_deviceid_5: DMA Channel 5");
    case ioat_dma_pci_deviceid_6:
        return("pci_deviceid_6: DMA Channel 6");
    case ioat_dma_pci_deviceid_7:
        return("pci_deviceid_7: DMA Channel 7");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_device_ids_prtval(char *_s, size_t _size, ioat_dma_device_ids_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_device_ids_prtval(char *_s, size_t _size, ioat_dma_device_ids_t _e)
{
    char *d = ioat_dma_device_ids_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_device_ids_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.shifts (Crystal Beach Shift Values)
 *  - no width specified
 */
typedef uint8_t ioat_dma_shifts_t;
#define ioat_dma_shift_baraddr ((ioat_dma_shifts_t)0xe)
#define ioat_dma_shift_descaddr ((ioat_dma_shifts_t)0x6)

static inline char *ioat_dma_shifts_describe(ioat_dma_shifts_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_shifts_describe(ioat_dma_shifts_t _e)
{
    switch (_e) {
    case ioat_dma_shift_baraddr:
        return("shift_baraddr: Base Address shift amount");
    case ioat_dma_shift_descaddr:
        return("shift_descaddr: Descriptor addres shift value");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_shifts_prtval(char *_s, size_t _size, ioat_dma_shifts_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_shifts_prtval(char *_s, size_t _size, ioat_dma_shifts_t _e)
{
    char *d = ioat_dma_shifts_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_shifts_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.msixctrl (MSI-X Control values)
 *  - no width specified
 */
typedef uint8_t ioat_dma_msixctrl_t;
#define ioat_dma_msix_use_intx ((ioat_dma_msixctrl_t)0x0)
#define ioat_dma_msix_use_msix ((ioat_dma_msixctrl_t)0x1)

static inline char *ioat_dma_msixctrl_describe(ioat_dma_msixctrl_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_msixctrl_describe(ioat_dma_msixctrl_t _e)
{
    switch (_e) {
    case ioat_dma_msix_use_intx:
        return("msix_use_intx: INTx method is used");
    case ioat_dma_msix_use_msix:
        return("msix_use_msix: MSI-X method is used");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_msixctrl_prtval(char *_s, size_t _size, ioat_dma_msixctrl_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_msixctrl_prtval(char *_s, size_t _size, ioat_dma_msixctrl_t _e)
{
    char *d = ioat_dma_msixctrl_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_msixctrl_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.power_st (Power States)
 *  - no width specified
 */
typedef uint8_t ioat_dma_power_st_t;
#define ioat_dma_pwr_st_d0 ((ioat_dma_power_st_t)0x0)
#define ioat_dma_pwr_st_d1 ((ioat_dma_power_st_t)0x1)
#define ioat_dma_pwr_st_d2 ((ioat_dma_power_st_t)0x2)
#define ioat_dma_pwr_st_d3 ((ioat_dma_power_st_t)0x3)

static inline char *ioat_dma_power_st_describe(ioat_dma_power_st_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_power_st_describe(ioat_dma_power_st_t _e)
{
    switch (_e) {
    case ioat_dma_pwr_st_d0:
        return("pwr_st_d0: ");
    case ioat_dma_pwr_st_d1:
        return("pwr_st_d1: ");
    case ioat_dma_pwr_st_d2:
        return("pwr_st_d2: ");
    case ioat_dma_pwr_st_d3:
        return("pwr_st_d3: ");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_power_st_prtval(char *_s, size_t _size, ioat_dma_power_st_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_power_st_prtval(char *_s, size_t _size, ioat_dma_power_st_t _e)
{
    char *d = ioat_dma_power_st_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_power_st_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.chanerr_int_val (Values for enabling/disabling the error intr)
 *  - no width specified
 */
typedef uint8_t ioat_dma_chanerr_int_val_t;
#define ioat_dma_chanerr_int_disabled ((ioat_dma_chanerr_int_val_t)0x1)
#define ioat_dma_chanerr_int_enabled ((ioat_dma_chanerr_int_val_t)0x0)

static inline char *ioat_dma_chanerr_int_val_describe(ioat_dma_chanerr_int_val_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_chanerr_int_val_describe(ioat_dma_chanerr_int_val_t _e)
{
    switch (_e) {
    case ioat_dma_chanerr_int_disabled:
        return("chanerr_int_disabled: Disable the interrupt");
    case ioat_dma_chanerr_int_enabled:
        return("chanerr_int_enabled: Enable the interrupt");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_chanerr_int_val_prtval(char *_s, size_t _size, ioat_dma_chanerr_int_val_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_chanerr_int_val_prtval(char *_s, size_t _size, ioat_dma_chanerr_int_val_t _e)
{
    char *d = ioat_dma_chanerr_int_val_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_chanerr_int_val_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.cbversions (Crystal Beach Major Versions)
 *  - no width specified
 */
typedef uint8_t ioat_dma_cbversions_t;
#define ioat_dma_cbver_1x ((ioat_dma_cbversions_t)0x1)
#define ioat_dma_cbver_2x ((ioat_dma_cbversions_t)0x2)
#define ioat_dma_cbver_3x ((ioat_dma_cbversions_t)0x3)

static inline char *ioat_dma_cbversions_describe(ioat_dma_cbversions_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_cbversions_describe(ioat_dma_cbversions_t _e)
{
    switch (_e) {
    case ioat_dma_cbver_1x:
        return("cbver_1x: Crystal Beach Version 1.xx");
    case ioat_dma_cbver_2x:
        return("cbver_2x: Crystal Beach Version 2.xx");
    case ioat_dma_cbver_3x:
        return("cbver_3x: Crystal Beach Version 3.xx");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_cbversions_prtval(char *_s, size_t _size, ioat_dma_cbversions_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_cbversions_prtval(char *_s, size_t _size, ioat_dma_cbversions_t _e)
{
    char *d = ioat_dma_cbversions_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_cbversions_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.chanctrl_snoop (Field values for Snoop Control)
 *  - no width specified
 */
typedef uint8_t ioat_dma_chanctrl_snoop_t;
#define ioat_dma_chanctrl_snoop_disabled ((ioat_dma_chanctrl_snoop_t)0x1)
#define ioat_dma_chanctrl_snoop_enabled ((ioat_dma_chanctrl_snoop_t)0x0)

static inline char *ioat_dma_chanctrl_snoop_describe(ioat_dma_chanctrl_snoop_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_chanctrl_snoop_describe(ioat_dma_chanctrl_snoop_t _e)
{
    switch (_e) {
    case ioat_dma_chanctrl_snoop_disabled:
        return("chanctrl_snoop_disabled: Disabled snooping");
    case ioat_dma_chanctrl_snoop_enabled:
        return("chanctrl_snoop_enabled: Enable snooping");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_chanctrl_snoop_prtval(char *_s, size_t _size, ioat_dma_chanctrl_snoop_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_chanctrl_snoop_prtval(char *_s, size_t _size, ioat_dma_chanctrl_snoop_t _e)
{
    char *d = ioat_dma_chanctrl_snoop_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_chanctrl_snoop_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.chanctrl_features (Field values for Channel Features)
 *  - no width specified
 */
typedef uint8_t ioat_dma_chanctrl_features_t;
#define ioat_dma_chanctrl_f_enable ((ioat_dma_chanctrl_features_t)0x1)
#define ioat_dma_chanctrl_f_disable ((ioat_dma_chanctrl_features_t)0x0)

static inline char *ioat_dma_chanctrl_features_describe(ioat_dma_chanctrl_features_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_chanctrl_features_describe(ioat_dma_chanctrl_features_t _e)
{
    switch (_e) {
    case ioat_dma_chanctrl_f_enable:
        return("chanctrl_f_enable: Feature field is enabled");
    case ioat_dma_chanctrl_f_disable:
        return("chanctrl_f_disable: Feature field is disabled");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_chanctrl_features_prtval(char *_s, size_t _size, ioat_dma_chanctrl_features_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_chanctrl_features_prtval(char *_s, size_t _size, ioat_dma_chanctrl_features_t _e)
{
    char *d = ioat_dma_chanctrl_features_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_chanctrl_features_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.trans_state (DMA Transfer States)
 *  - no width specified
 */
typedef uint8_t ioat_dma_trans_state_t;
#define ioat_dma_trans_state_idle ((ioat_dma_trans_state_t)0x1)
#define ioat_dma_trans_state_susp ((ioat_dma_trans_state_t)0x2)
#define ioat_dma_trans_state_halt ((ioat_dma_trans_state_t)0x3)
#define ioat_dma_trans_state_armed ((ioat_dma_trans_state_t)0x4)

static inline char *ioat_dma_trans_state_describe(ioat_dma_trans_state_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_trans_state_describe(ioat_dma_trans_state_t _e)
{
    switch (_e) {
    case ioat_dma_trans_state_idle:
        return("trans_state_idle: Idle, All DMA transfers done");
    case ioat_dma_trans_state_susp:
        return("trans_state_susp: Suspended");
    case ioat_dma_trans_state_halt:
        return("trans_state_halt: Halted, operation aborted (error)");
    case ioat_dma_trans_state_armed:
        return("trans_state_armed: Armed State");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_trans_state_prtval(char *_s, size_t _size, ioat_dma_trans_state_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_trans_state_prtval(char *_s, size_t _size, ioat_dma_trans_state_t _e)
{
    char *d = ioat_dma_trans_state_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_trans_state_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.tag_maps (APICID to Tag Map Values)
 *  - no width specified
 */
typedef uint8_t ioat_dma_tag_maps_t;
#define ioat_dma_tag_map_0 ((ioat_dma_tag_maps_t)0x0)
#define ioat_dma_tag_map_apic ((ioat_dma_tag_maps_t)0x1)
#define ioat_dma_tag_map_apicneg ((ioat_dma_tag_maps_t)0x2)
#define ioat_dma_tag_map_res ((ioat_dma_tag_maps_t)0x3)

static inline char *ioat_dma_tag_maps_describe(ioat_dma_tag_maps_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_tag_maps_describe(ioat_dma_tag_maps_t _e)
{
    switch (_e) {
    case ioat_dma_tag_map_0:
        return("tag_map_0: Tag_Map[0]");
    case ioat_dma_tag_map_apic:
        return("tag_map_apic: APICID[ Tag_Map[3:0] ]");
    case ioat_dma_tag_map_apicneg:
        return("tag_map_apicneg: NOT( APICID [Tag_Map_4[3:0] ] )");
    case ioat_dma_tag_map_res:
        return("tag_map_res: reserved");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_tag_maps_prtval(char *_s, size_t _size, ioat_dma_tag_maps_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_tag_maps_prtval(char *_s, size_t _size, ioat_dma_tag_maps_t _e)
{
    char *d = ioat_dma_tag_maps_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_tag_maps_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.desc_sizes (IOAT DMA Descriptor Sizes)
 *  - no width specified
 */
typedef uint8_t ioat_dma_desc_sizes_t;
#define ioat_dma_descriptor_size ((ioat_dma_desc_sizes_t)0x40)

static inline char *ioat_dma_desc_sizes_describe(ioat_dma_desc_sizes_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_desc_sizes_describe(ioat_dma_desc_sizes_t _e)
{
    switch (_e) {
    case ioat_dma_descriptor_size:
        return("descriptor_size: Size of the DMA descriptor");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_desc_sizes_prtval(char *_s, size_t _size, ioat_dma_desc_sizes_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_desc_sizes_prtval(char *_s, size_t _size, ioat_dma_desc_sizes_t _e)
{
    char *d = ioat_dma_desc_sizes_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_desc_sizes_t", (uint64_t )(_e)));
    }
}

/*
 * Constants defn: ioat_dma.desc_opcodes (IOAT DMA Descriptor OP Codes)
 *  - no width specified
 */
typedef uint8_t ioat_dma_desc_opcodes_t;
#define ioat_dma_desc_op_copy ((ioat_dma_desc_opcodes_t)0x0)
#define ioat_dma_desc_op_memset ((ioat_dma_desc_opcodes_t)0x1)
#define ioat_dma_desc_op_xor ((ioat_dma_desc_opcodes_t)0x87)
#define ioat_dma_desc_op_xor_val ((ioat_dma_desc_opcodes_t)0x88)

static inline char *ioat_dma_desc_opcodes_describe(ioat_dma_desc_opcodes_t _e) __attribute__ ((always_inline));
static inline char *ioat_dma_desc_opcodes_describe(ioat_dma_desc_opcodes_t _e)
{
    switch (_e) {
    case ioat_dma_desc_op_copy:
        return("desc_op_copy: Copy Operation");
    case ioat_dma_desc_op_memset:
        return("desc_op_memset: Memset Operation");
    case ioat_dma_desc_op_xor:
        return("desc_op_xor: For Xor Descriptor");
    case ioat_dma_desc_op_xor_val:
        return("desc_op_xor_val: For Xor descriptor");
    default:
        return(NULL);
    }
}

static inline int ioat_dma_desc_opcodes_prtval(char *_s, size_t _size, ioat_dma_desc_opcodes_t _e) __attribute__ ((always_inline));
static inline int ioat_dma_desc_opcodes_prtval(char *_s, size_t _size, ioat_dma_desc_opcodes_t _e)
{
    char *d = ioat_dma_desc_opcodes_describe(_e);
    if (d) {
        return(snprintf(_s, _size, "%s", d));
    } else {
        return(snprintf(_s, _size, "Unknown constant %s value 0x%" PRIx64, "ioat_dma_desc_opcodes_t", (uint64_t )(_e)));
    }
}

/*
 * Register type: ioat_dma_did_t
 * Description: Implicit type of Device Identification Number register
 * Fields:
 *   function	(size 8, offset 0, init 0):	RO	Function number: 0-7
 *   devid	(size 8, offset 8, init 0):	RO	Device ID always 0x0E
 */
typedef uint16_t ioat_dma_did_t;
#define ioat_dma_did_default 0x0
static inline uint8_t ioat_dma_did_function_extract(ioat_dma_did_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_did_function_extract(ioat_dma_did_t _regval)
{
    return((uint8_t )((_regval & 0xff) >> 0));
}

static inline ioat_dma_did_t ioat_dma_did_function_insert(ioat_dma_did_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_did_t ioat_dma_did_function_insert(ioat_dma_did_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xff00) | (0xff & (((ioat_dma_did_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_did_devid_extract(ioat_dma_did_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_did_devid_extract(ioat_dma_did_t _regval)
{
    return((uint8_t )((_regval & 0xff00) >> 8));
}

static inline ioat_dma_did_t ioat_dma_did_devid_insert(ioat_dma_did_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_did_t ioat_dma_did_devid_insert(ioat_dma_did_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xff) | (0xff00 & (((ioat_dma_did_t )(_fieldval)) << 8)));
}

static inline int ioat_dma_did_prtval(char *_s, size_t _size, ioat_dma_did_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_did_prtval(char *_s, size_t _size, ioat_dma_did_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " function =\t%" PRIx8 "\t(Function number: 0-7)\n", ioat_dma_did_function_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " devid =\t%" PRIx8 "\t(Device ID always 0x0E)\n", ioat_dma_did_devid_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_pcicmd_t
 * Description: Implicit type of PCI Command Register register
 * Fields:
 *   iose	(size 1, offset 0, init 0):	RO	
 *   mse	(size 1, offset 1, init 0):	RW	
 *   bme	(size 1, offset 2, init 0):	RW	
 *   sce	(size 1, offset 3, init 0):	RO	
 *   mwie	(size 1, offset 4, init 0):	RO	
 *   _anon5	(size 1, offset 5, init 0):	RSVD	_
 *   perre	(size 1, offset 6, init 0):	RO	
 *   _anon7	(size 1, offset 7, init 0):	RSVD	_
 *   serre	(size 1, offset 8, init 0):	RO	
 *   _anon9	(size 1, offset 9, init 0):	RSVD	_
 *   intx_disable	(size 1, offset 10, init 0):	RW	
 *   _anon11	(size 5, offset 11, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_pcicmd_t;
#define ioat_dma_pcicmd_default 0x0
static inline uint8_t ioat_dma_pcicmd_iose_extract(ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_iose_extract(ioat_dma_pcicmd_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_iose_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_iose_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((ioat_dma_pcicmd_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_pcicmd_mse_extract(ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_mse_extract(ioat_dma_pcicmd_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_mse_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_mse_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffd) | (0x2 & (((ioat_dma_pcicmd_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_pcicmd_bme_extract(ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_bme_extract(ioat_dma_pcicmd_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_bme_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_bme_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffb) | (0x4 & (((ioat_dma_pcicmd_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_pcicmd_sce_extract(ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_sce_extract(ioat_dma_pcicmd_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_sce_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_sce_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff7) | (0x8 & (((ioat_dma_pcicmd_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_pcicmd_mwie_extract(ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_mwie_extract(ioat_dma_pcicmd_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_mwie_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_mwie_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffef) | (0x10 & (((ioat_dma_pcicmd_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_pcicmd_perre_extract(ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_perre_extract(ioat_dma_pcicmd_t _regval)
{
    return((uint8_t )((_regval & 0x40) >> 6));
}

static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_perre_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_perre_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffbf) | (0x40 & (((ioat_dma_pcicmd_t )(_fieldval)) << 6)));
}

static inline uint8_t ioat_dma_pcicmd_serre_extract(ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_serre_extract(ioat_dma_pcicmd_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_serre_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_serre_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfeff) | (0x100 & (((ioat_dma_pcicmd_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_pcicmd_intx_disable_extract(ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_intx_disable_extract(ioat_dma_pcicmd_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_intx_disable_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_intx_disable_insert(ioat_dma_pcicmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfbff) | (0x400 & (((ioat_dma_pcicmd_t )(_fieldval)) << 10)));
}

static inline int ioat_dma_pcicmd_prtval(char *_s, size_t _size, ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_pcicmd_prtval(char *_s, size_t _size, ioat_dma_pcicmd_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " iose =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_iose_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mse =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_mse_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bme =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_bme_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " sce =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_sce_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mwie =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_mwie_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " perre =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_perre_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " serre =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_serre_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intx_disable =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_intx_disable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_pcists_t
 * Description: Implicit type of PCI Status Register register
 * Fields:
 *   _anon0	(size 3, offset 0, init 0):	RSVD	_
 *   intxsts	(size 1, offset 3, init 0):	RO	
 *   caplist	(size 1, offset 4, init 0):	RO	indicates the presence of a capabilities list structure
 *   _anon5	(size 3, offset 5, init 0):	RSVD	_
 *   mdpe	(size 1, offset 8, init 0):	RWC	
 *   _anon9	(size 2, offset 9, init 0):	RSVD	_
 *   sta	(size 1, offset 11, init 0):	RWC	
 *   rta	(size 1, offset 12, init 0):	RO	
 *   rma	(size 1, offset 13, init 0):	RO	
 *   sse	(size 1, offset 14, init 0):	RO	
 *   dpe	(size 1, offset 15, init 0):	RWC	
 */
typedef uint16_t ioat_dma_pcists_t;
#define ioat_dma_pcists_default 0x0
static inline uint8_t ioat_dma_pcists_intxsts_extract(ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_intxsts_extract(ioat_dma_pcists_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_pcists_t ioat_dma_pcists_intxsts_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcists_t ioat_dma_pcists_intxsts_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff7) | (0x8 & (((ioat_dma_pcists_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_pcists_caplist_extract(ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_caplist_extract(ioat_dma_pcists_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_pcists_t ioat_dma_pcists_caplist_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcists_t ioat_dma_pcists_caplist_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffef) | (0x10 & (((ioat_dma_pcists_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_pcists_mdpe_extract(ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_mdpe_extract(ioat_dma_pcists_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_pcists_t ioat_dma_pcists_mdpe_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcists_t ioat_dma_pcists_mdpe_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfeff) | (0x100 & (((ioat_dma_pcists_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_pcists_sta_extract(ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_sta_extract(ioat_dma_pcists_t _regval)
{
    return((uint8_t )((_regval & 0x800) >> 11));
}

static inline ioat_dma_pcists_t ioat_dma_pcists_sta_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcists_t ioat_dma_pcists_sta_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf7ff) | (0x800 & (((ioat_dma_pcists_t )(_fieldval)) << 11)));
}

static inline uint8_t ioat_dma_pcists_rta_extract(ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_rta_extract(ioat_dma_pcists_t _regval)
{
    return((uint8_t )((_regval & 0x1000) >> 12));
}

static inline ioat_dma_pcists_t ioat_dma_pcists_rta_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcists_t ioat_dma_pcists_rta_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xefff) | (0x1000 & (((ioat_dma_pcists_t )(_fieldval)) << 12)));
}

static inline uint8_t ioat_dma_pcists_rma_extract(ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_rma_extract(ioat_dma_pcists_t _regval)
{
    return((uint8_t )((_regval & 0x2000) >> 13));
}

static inline ioat_dma_pcists_t ioat_dma_pcists_rma_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcists_t ioat_dma_pcists_rma_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xdfff) | (0x2000 & (((ioat_dma_pcists_t )(_fieldval)) << 13)));
}

static inline uint8_t ioat_dma_pcists_sse_extract(ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_sse_extract(ioat_dma_pcists_t _regval)
{
    return((uint8_t )((_regval & 0x4000) >> 14));
}

static inline ioat_dma_pcists_t ioat_dma_pcists_sse_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcists_t ioat_dma_pcists_sse_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xbfff) | (0x4000 & (((ioat_dma_pcists_t )(_fieldval)) << 14)));
}

static inline uint8_t ioat_dma_pcists_dpe_extract(ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_dpe_extract(ioat_dma_pcists_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_pcists_t ioat_dma_pcists_dpe_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcists_t ioat_dma_pcists_dpe_insert(ioat_dma_pcists_t _regval, uint8_t _fieldval)
{
    return((_regval & 0x7fff) | (0x8000 & (((ioat_dma_pcists_t )(_fieldval)) << 15)));
}

static inline int ioat_dma_pcists_prtval(char *_s, size_t _size, ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_pcists_prtval(char *_s, size_t _size, ioat_dma_pcists_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intxsts =\t%" PRIx8 "\t()\n", ioat_dma_pcists_intxsts_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " caplist =\t%" PRIx8 "\t(indicates the presence of a capabilities list structure)\n", ioat_dma_pcists_caplist_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mdpe =\t%" PRIx8 "\t()\n", ioat_dma_pcists_mdpe_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " sta =\t%" PRIx8 "\t()\n", ioat_dma_pcists_sta_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rta =\t%" PRIx8 "\t()\n", ioat_dma_pcists_rta_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rma =\t%" PRIx8 "\t()\n", ioat_dma_pcists_rma_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " sse =\t%" PRIx8 "\t()\n", ioat_dma_pcists_sse_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dpe =\t%" PRIx8 "\t()\n", ioat_dma_pcists_dpe_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_rid_ccr_t
 * Description: Implicit type of Revision ID and PCI Class register
 * Fields:
 *   rid	(size 8, offset 0, init 0):	RO	Revision ID
 *   rlpi	(size 8, offset 8, init 0):	RO	Register level programming interface (set to 00)
 *   subclass	(size 8, offset 16, init 0):	RO	Sub class: Generic device
 *   class	(size 8, offset 24, init 0):	RO	Base class: Generic device
 */
typedef uint32_t ioat_dma_rid_ccr_t;
#define ioat_dma_rid_ccr_default 0x0
static inline uint8_t ioat_dma_rid_ccr_rid_extract(ioat_dma_rid_ccr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_rid_ccr_rid_extract(ioat_dma_rid_ccr_t _regval)
{
    return((uint8_t )((_regval & 0xff) >> 0));
}

static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_rid_insert(ioat_dma_rid_ccr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_rid_insert(ioat_dma_rid_ccr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff00) | (0xff & (((ioat_dma_rid_ccr_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_rid_ccr_rlpi_extract(ioat_dma_rid_ccr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_rid_ccr_rlpi_extract(ioat_dma_rid_ccr_t _regval)
{
    return((uint8_t )((_regval & 0xff00) >> 8));
}

static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_rlpi_insert(ioat_dma_rid_ccr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_rlpi_insert(ioat_dma_rid_ccr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff00ff) | (0xff00 & (((ioat_dma_rid_ccr_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_rid_ccr_subclass_extract(ioat_dma_rid_ccr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_rid_ccr_subclass_extract(ioat_dma_rid_ccr_t _regval)
{
    return((uint8_t )((_regval & 0xff0000) >> 16));
}

static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_subclass_insert(ioat_dma_rid_ccr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_subclass_insert(ioat_dma_rid_ccr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xff00ffff) | (0xff0000 & (((ioat_dma_rid_ccr_t )(_fieldval)) << 16)));
}

static inline uint8_t ioat_dma_rid_ccr_class_extract(ioat_dma_rid_ccr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_rid_ccr_class_extract(ioat_dma_rid_ccr_t _regval)
{
    return((uint8_t )((_regval & 0xff000000) >> 24));
}

static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_class_insert(ioat_dma_rid_ccr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_class_insert(ioat_dma_rid_ccr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff) | (0xff000000 & (((ioat_dma_rid_ccr_t )(_fieldval)) << 24)));
}

static inline int ioat_dma_rid_ccr_prtval(char *_s, size_t _size, ioat_dma_rid_ccr_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_rid_ccr_prtval(char *_s, size_t _size, ioat_dma_rid_ccr_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rid =\t%" PRIx8 "\t(Revision ID)\n", ioat_dma_rid_ccr_rid_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rlpi =\t%" PRIx8 "\t(Register level programming interface (set to 00))\n", ioat_dma_rid_ccr_rlpi_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " subclass =\t%" PRIx8 "\t(Sub class: Generic device)\n", ioat_dma_rid_ccr_subclass_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " class =\t%" PRIx8 "\t(Base class: Generic device)\n", ioat_dma_rid_ccr_class_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_hdr_t
 * Description: Implicit type of PCI Header Register register
 * Fields:
 *   _anon0	(size 6, offset 0, init 0):	RSVD	_
 *   cfglayout	(size 1, offset 6, init 0):	RO	Configuration layout (always 0, endpoint)
 *   mfd	(size 1, offset 7, init 0):	RO	Multifunction device (always 1)
 */
typedef uint8_t ioat_dma_hdr_t;
#define ioat_dma_hdr_default 0x0
static inline uint8_t ioat_dma_hdr_cfglayout_extract(ioat_dma_hdr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_hdr_cfglayout_extract(ioat_dma_hdr_t _regval)
{
    return((uint8_t )((_regval & 0x40) >> 6));
}

static inline ioat_dma_hdr_t ioat_dma_hdr_cfglayout_insert(ioat_dma_hdr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_hdr_t ioat_dma_hdr_cfglayout_insert(ioat_dma_hdr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xbf) | (0x40 & (((ioat_dma_hdr_t )(_fieldval)) << 6)));
}

static inline uint8_t ioat_dma_hdr_mfd_extract(ioat_dma_hdr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_hdr_mfd_extract(ioat_dma_hdr_t _regval)
{
    return((uint8_t )((_regval & 0x80) >> 7));
}

static inline ioat_dma_hdr_t ioat_dma_hdr_mfd_insert(ioat_dma_hdr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_hdr_t ioat_dma_hdr_mfd_insert(ioat_dma_hdr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0x7f) | (0x80 & (((ioat_dma_hdr_t )(_fieldval)) << 7)));
}

static inline int ioat_dma_hdr_prtval(char *_s, size_t _size, ioat_dma_hdr_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_hdr_prtval(char *_s, size_t _size, ioat_dma_hdr_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cfglayout =\t%" PRIx8 "\t(Configuration layout (always 0, endpoint))\n", ioat_dma_hdr_cfglayout_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mfd =\t%" PRIx8 "\t(Multifunction device (always 1))\n", ioat_dma_hdr_mfd_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_cb_bar_t
 * Description: Implicit type of Crystal Beach Base Address Register register
 * Fields:
 *   memspace	(size 1, offset 0, init 0):	RO	This Base Address Register indicates memory space.
 *   bartype	(size 2, offset 1, init 0):	RO	The DMA registers is 64-bit address space
 *   prefetch	(size 1, offset 3, init 0):	RO	DMA registers are non-prefetchable (always 0)
 *   _anon4	(size 10, offset 4, init 0):	RSVD	_
 *   bar	(size 50, offset 14, init 0):	RW	16 KB aligned 64-bit base address for MMIO regs
 */
typedef uint64_t ioat_dma_cb_bar_t;
#define ioat_dma_cb_bar_default 0x0
static inline uint8_t ioat_dma_cb_bar_memspace_extract(ioat_dma_cb_bar_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cb_bar_memspace_extract(ioat_dma_cb_bar_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_memspace_insert(ioat_dma_cb_bar_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_memspace_insert(ioat_dma_cb_bar_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffffffffffe) | (0x1 & (((ioat_dma_cb_bar_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_cb_bar_bartype_extract(ioat_dma_cb_bar_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cb_bar_bartype_extract(ioat_dma_cb_bar_t _regval)
{
    return((uint8_t )((_regval & 0x6) >> 1));
}

static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_bartype_insert(ioat_dma_cb_bar_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_bartype_insert(ioat_dma_cb_bar_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffffffffff9) | (0x6 & (((ioat_dma_cb_bar_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_cb_bar_prefetch_extract(ioat_dma_cb_bar_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cb_bar_prefetch_extract(ioat_dma_cb_bar_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_prefetch_insert(ioat_dma_cb_bar_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_prefetch_insert(ioat_dma_cb_bar_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffffffffff7) | (0x8 & (((ioat_dma_cb_bar_t )(_fieldval)) << 3)));
}

static inline uint64_t ioat_dma_cb_bar_bar_extract(ioat_dma_cb_bar_t _regval) __attribute__ ((always_inline));
static inline uint64_t ioat_dma_cb_bar_bar_extract(ioat_dma_cb_bar_t _regval)
{
    return((uint64_t )((_regval & 0xffffffffffffc000) >> 14));
}

static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_bar_insert(ioat_dma_cb_bar_t _regval, uint64_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_bar_insert(ioat_dma_cb_bar_t _regval, uint64_t _fieldval)
{
    return((_regval & 0x3fff) | (0xffffffffffffc000 & (((ioat_dma_cb_bar_t )(_fieldval)) << 14)));
}

static inline int ioat_dma_cb_bar_prtval(char *_s, size_t _size, ioat_dma_cb_bar_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_cb_bar_prtval(char *_s, size_t _size, ioat_dma_cb_bar_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " memspace =\t%" PRIx8 "\t(This Base Address Register indicates memory space.)\n", ioat_dma_cb_bar_memspace_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bartype =\t%" PRIx8 "\t(The DMA registers is 64-bit address space)\n", ioat_dma_cb_bar_bartype_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " prefetch =\t%" PRIx8 "\t(DMA registers are non-prefetchable (always 0))\n", ioat_dma_cb_bar_prefetch_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bar =\t%" PRIx64 "\t(16 KB aligned 64-bit base address for MMIO regs)\n", ioat_dma_cb_bar_bar_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_devcfg_t
 * Description: Implicit type of Device Configuration Register register
 * Fields:
 *   numrfo	(size 4, offset 0, init 0):	RW	Number of outstanding RFOs
 *   numrd	(size 4, offset 4, init 0):	RW	Number of outstanding requests
 *   _anon8	(size 1, offset 8, init 0):	RSVD	_
 *   no_snoop	(size 1, offset 9, init 0):	RW	Disable snooping (not recommendend)
 *   f0extop	(size 1, offset 10, init 0):	RW	switches in the Function 0 Device ID
 *   f1extop	(size 1, offset 11, init 0):	RW	switches in the Function 1 Device ID
 *   numrd_xor	(size 4, offset 12, init 0):	RW	Number of outstanding requests (set to 0 for max)
 */
typedef uint16_t ioat_dma_devcfg_t;
#define ioat_dma_devcfg_default 0x0
static inline uint8_t ioat_dma_devcfg_numrfo_extract(ioat_dma_devcfg_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_numrfo_extract(ioat_dma_devcfg_t _regval)
{
    return((uint8_t )((_regval & 0xf) >> 0));
}

static inline ioat_dma_devcfg_t ioat_dma_devcfg_numrfo_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcfg_t ioat_dma_devcfg_numrfo_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff0) | (0xf & (((ioat_dma_devcfg_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_devcfg_numrd_extract(ioat_dma_devcfg_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_numrd_extract(ioat_dma_devcfg_t _regval)
{
    return((uint8_t )((_regval & 0xf0) >> 4));
}

static inline ioat_dma_devcfg_t ioat_dma_devcfg_numrd_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcfg_t ioat_dma_devcfg_numrd_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xff0f) | (0xf0 & (((ioat_dma_devcfg_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_devcfg_no_snoop_extract(ioat_dma_devcfg_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_no_snoop_extract(ioat_dma_devcfg_t _regval)
{
    return((uint8_t )((_regval & 0x200) >> 9));
}

static inline ioat_dma_devcfg_t ioat_dma_devcfg_no_snoop_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcfg_t ioat_dma_devcfg_no_snoop_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfdff) | (0x200 & (((ioat_dma_devcfg_t )(_fieldval)) << 9)));
}

static inline uint8_t ioat_dma_devcfg_f0extop_extract(ioat_dma_devcfg_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_f0extop_extract(ioat_dma_devcfg_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_devcfg_t ioat_dma_devcfg_f0extop_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcfg_t ioat_dma_devcfg_f0extop_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfbff) | (0x400 & (((ioat_dma_devcfg_t )(_fieldval)) << 10)));
}

static inline uint8_t ioat_dma_devcfg_f1extop_extract(ioat_dma_devcfg_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_f1extop_extract(ioat_dma_devcfg_t _regval)
{
    return((uint8_t )((_regval & 0x800) >> 11));
}

static inline ioat_dma_devcfg_t ioat_dma_devcfg_f1extop_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcfg_t ioat_dma_devcfg_f1extop_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf7ff) | (0x800 & (((ioat_dma_devcfg_t )(_fieldval)) << 11)));
}

static inline uint8_t ioat_dma_devcfg_numrd_xor_extract(ioat_dma_devcfg_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_numrd_xor_extract(ioat_dma_devcfg_t _regval)
{
    return((uint8_t )((_regval & 0xf000) >> 12));
}

static inline ioat_dma_devcfg_t ioat_dma_devcfg_numrd_xor_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcfg_t ioat_dma_devcfg_numrd_xor_insert(ioat_dma_devcfg_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff) | (0xf000 & (((ioat_dma_devcfg_t )(_fieldval)) << 12)));
}

static inline int ioat_dma_devcfg_prtval(char *_s, size_t _size, ioat_dma_devcfg_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_devcfg_prtval(char *_s, size_t _size, ioat_dma_devcfg_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " numrfo =\t%" PRIx8 "\t(Number of outstanding RFOs)\n", ioat_dma_devcfg_numrfo_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " numrd =\t%" PRIx8 "\t(Number of outstanding requests)\n", ioat_dma_devcfg_numrd_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " no_snoop =\t%" PRIx8 "\t(Disable snooping (not recommendend))\n", ioat_dma_devcfg_no_snoop_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " f0extop =\t%" PRIx8 "\t(switches in the Function 0 Device ID)\n", ioat_dma_devcfg_f0extop_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " f1extop =\t%" PRIx8 "\t(switches in the Function 1 Device ID)\n", ioat_dma_devcfg_f1extop_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " numrd_xor =\t%" PRIx8 "\t(Number of outstanding requests (set to 0 for max))\n", ioat_dma_devcfg_numrd_xor_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_msixmsgctl_t
 * Description: Implicit type of MSI-X Message Control register
 * Fields:
 *   table_size	(size 11, offset 0, init 0):	RO	Table size of MSI-X
 *   _anon11	(size 3, offset 11, init 0):	RSVD	_
 *   function_mask	(size 1, offset 14, init 0):	RW	Vector mask control
 *   msi_x_en	(size 1, offset 15, init 0):	RW	Select MSI-X instead of INTx method
 */
typedef uint16_t ioat_dma_msixmsgctl_t;
#define ioat_dma_msixmsgctl_default 0x0
static inline uint16_t ioat_dma_msixmsgctl_table_size_extract(ioat_dma_msixmsgctl_t _regval) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_msixmsgctl_table_size_extract(ioat_dma_msixmsgctl_t _regval)
{
    return((uint16_t )((_regval & 0x7ff) >> 0));
}

static inline ioat_dma_msixmsgctl_t ioat_dma_msixmsgctl_table_size_insert(ioat_dma_msixmsgctl_t _regval, uint16_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_msixmsgctl_t ioat_dma_msixmsgctl_table_size_insert(ioat_dma_msixmsgctl_t _regval, uint16_t _fieldval)
{
    return((_regval & 0xf800) | (0x7ff & (((ioat_dma_msixmsgctl_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_msixmsgctl_function_mask_extract(ioat_dma_msixmsgctl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_msixmsgctl_function_mask_extract(ioat_dma_msixmsgctl_t _regval)
{
    return((uint8_t )((_regval & 0x4000) >> 14));
}

static inline ioat_dma_msixmsgctl_t ioat_dma_msixmsgctl_function_mask_insert(ioat_dma_msixmsgctl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_msixmsgctl_t ioat_dma_msixmsgctl_function_mask_insert(ioat_dma_msixmsgctl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xbfff) | (0x4000 & (((ioat_dma_msixmsgctl_t )(_fieldval)) << 14)));
}

static inline uint8_t ioat_dma_msixmsgctl_msi_x_en_extract(ioat_dma_msixmsgctl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_msixmsgctl_msi_x_en_extract(ioat_dma_msixmsgctl_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_msixmsgctl_t ioat_dma_msixmsgctl_msi_x_en_insert(ioat_dma_msixmsgctl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_msixmsgctl_t ioat_dma_msixmsgctl_msi_x_en_insert(ioat_dma_msixmsgctl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0x7fff) | (0x8000 & (((ioat_dma_msixmsgctl_t )(_fieldval)) << 15)));
}

static inline int ioat_dma_msixmsgctl_prtval(char *_s, size_t _size, ioat_dma_msixmsgctl_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_msixmsgctl_prtval(char *_s, size_t _size, ioat_dma_msixmsgctl_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " table_size =\t%" PRIx16 "\t(Table size of MSI-X)\n", ioat_dma_msixmsgctl_table_size_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " function_mask =\t%" PRIx8 "\t(Vector mask control)\n", ioat_dma_msixmsgctl_function_mask_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " msi_x_en =\t%" PRIx8 "\t(Select MSI-X instead of INTx method)\n", ioat_dma_msixmsgctl_msi_x_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_tableoff_bir_t
 * Description: Implicit type of MSI-X Table Offset and BAR Indicator register
 * Fields:
 *   bir	(size 3, offset 0, init 0):	RO	Offset of the CB BAR in the Config Space
 *   offset	(size 29, offset 3, init 0):	RO	Offset of the MSI-X structure from the CB_BAR base
 */
typedef uint32_t ioat_dma_tableoff_bir_t;
#define ioat_dma_tableoff_bir_default 0x0
static inline uint8_t ioat_dma_tableoff_bir_bir_extract(ioat_dma_tableoff_bir_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_tableoff_bir_bir_extract(ioat_dma_tableoff_bir_t _regval)
{
    return((uint8_t )((_regval & 0x7) >> 0));
}

static inline ioat_dma_tableoff_bir_t ioat_dma_tableoff_bir_bir_insert(ioat_dma_tableoff_bir_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_tableoff_bir_t ioat_dma_tableoff_bir_bir_insert(ioat_dma_tableoff_bir_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff8) | (0x7 & (((ioat_dma_tableoff_bir_t )(_fieldval)) << 0)));
}

static inline uint32_t ioat_dma_tableoff_bir_offset_extract(ioat_dma_tableoff_bir_t _regval) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_tableoff_bir_offset_extract(ioat_dma_tableoff_bir_t _regval)
{
    return((uint32_t )((_regval & 0xfffffff8) >> 3));
}

static inline ioat_dma_tableoff_bir_t ioat_dma_tableoff_bir_offset_insert(ioat_dma_tableoff_bir_t _regval, uint32_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_tableoff_bir_t ioat_dma_tableoff_bir_offset_insert(ioat_dma_tableoff_bir_t _regval, uint32_t _fieldval)
{
    return((_regval & 0x7) | (0xfffffff8 & (((ioat_dma_tableoff_bir_t )(_fieldval)) << 3)));
}

static inline int ioat_dma_tableoff_bir_prtval(char *_s, size_t _size, ioat_dma_tableoff_bir_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_tableoff_bir_prtval(char *_s, size_t _size, ioat_dma_tableoff_bir_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bir =\t%" PRIx8 "\t(Offset of the CB BAR in the Config Space)\n", ioat_dma_tableoff_bir_bir_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " offset =\t%" PRIx32 "\t(Offset of the MSI-X structure from the CB_BAR base)\n", ioat_dma_tableoff_bir_offset_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_pbaoff_bir_t
 * Description: Implicit type of MSI-X PBA Offset register
 * Fields:
 *   bir	(size 3, offset 0, init 0):	RO	Offset of the CB BAR in the Config Space
 *   offset	(size 29, offset 3, init 0):	RO	Offset of the MSI-X PBA structure from the CB_BAR base
 */
typedef uint32_t ioat_dma_pbaoff_bir_t;
#define ioat_dma_pbaoff_bir_default 0x0
static inline uint8_t ioat_dma_pbaoff_bir_bir_extract(ioat_dma_pbaoff_bir_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pbaoff_bir_bir_extract(ioat_dma_pbaoff_bir_t _regval)
{
    return((uint8_t )((_regval & 0x7) >> 0));
}

static inline ioat_dma_pbaoff_bir_t ioat_dma_pbaoff_bir_bir_insert(ioat_dma_pbaoff_bir_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pbaoff_bir_t ioat_dma_pbaoff_bir_bir_insert(ioat_dma_pbaoff_bir_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff8) | (0x7 & (((ioat_dma_pbaoff_bir_t )(_fieldval)) << 0)));
}

static inline uint32_t ioat_dma_pbaoff_bir_offset_extract(ioat_dma_pbaoff_bir_t _regval) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_pbaoff_bir_offset_extract(ioat_dma_pbaoff_bir_t _regval)
{
    return((uint32_t )((_regval & 0xfffffff8) >> 3));
}

static inline ioat_dma_pbaoff_bir_t ioat_dma_pbaoff_bir_offset_insert(ioat_dma_pbaoff_bir_t _regval, uint32_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pbaoff_bir_t ioat_dma_pbaoff_bir_offset_insert(ioat_dma_pbaoff_bir_t _regval, uint32_t _fieldval)
{
    return((_regval & 0x7) | (0xfffffff8 & (((ioat_dma_pbaoff_bir_t )(_fieldval)) << 3)));
}

static inline int ioat_dma_pbaoff_bir_prtval(char *_s, size_t _size, ioat_dma_pbaoff_bir_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_pbaoff_bir_prtval(char *_s, size_t _size, ioat_dma_pbaoff_bir_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bir =\t%" PRIx8 "\t(Offset of the CB BAR in the Config Space)\n", ioat_dma_pbaoff_bir_bir_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " offset =\t%" PRIx32 "\t(Offset of the MSI-X PBA structure from the CB_BAR base)\n", ioat_dma_pbaoff_bir_offset_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_expcap_t
 * Description: Implicit type of PCI Express Device Type register
 * Fields:
 *   version	(size 4, offset 0, init 0):	RO	Version of the PCI Express capability structure
 *   port_type	(size 4, offset 4, init 0):	RO	Type of the Device
 *   slot_impl	(size 1, offset 8, init 0):	RO	N/A
 *   irq_msg_num	(size 5, offset 9, init 0):	RO	N/A
 *   _anon14	(size 2, offset 14, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_expcap_t;
#define ioat_dma_expcap_default 0x0
static inline uint8_t ioat_dma_expcap_version_extract(ioat_dma_expcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_expcap_version_extract(ioat_dma_expcap_t _regval)
{
    return((uint8_t )((_regval & 0xf) >> 0));
}

static inline ioat_dma_expcap_t ioat_dma_expcap_version_insert(ioat_dma_expcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_expcap_t ioat_dma_expcap_version_insert(ioat_dma_expcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff0) | (0xf & (((ioat_dma_expcap_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_expcap_port_type_extract(ioat_dma_expcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_expcap_port_type_extract(ioat_dma_expcap_t _regval)
{
    return((uint8_t )((_regval & 0xf0) >> 4));
}

static inline ioat_dma_expcap_t ioat_dma_expcap_port_type_insert(ioat_dma_expcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_expcap_t ioat_dma_expcap_port_type_insert(ioat_dma_expcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xff0f) | (0xf0 & (((ioat_dma_expcap_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_expcap_slot_impl_extract(ioat_dma_expcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_expcap_slot_impl_extract(ioat_dma_expcap_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_expcap_t ioat_dma_expcap_slot_impl_insert(ioat_dma_expcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_expcap_t ioat_dma_expcap_slot_impl_insert(ioat_dma_expcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfeff) | (0x100 & (((ioat_dma_expcap_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_expcap_irq_msg_num_extract(ioat_dma_expcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_expcap_irq_msg_num_extract(ioat_dma_expcap_t _regval)
{
    return((uint8_t )((_regval & 0x3e00) >> 9));
}

static inline ioat_dma_expcap_t ioat_dma_expcap_irq_msg_num_insert(ioat_dma_expcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_expcap_t ioat_dma_expcap_irq_msg_num_insert(ioat_dma_expcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xc1ff) | (0x3e00 & (((ioat_dma_expcap_t )(_fieldval)) << 9)));
}

static inline int ioat_dma_expcap_prtval(char *_s, size_t _size, ioat_dma_expcap_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_expcap_prtval(char *_s, size_t _size, ioat_dma_expcap_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " version =\t%" PRIx8 "\t(Version of the PCI Express capability structure)\n", ioat_dma_expcap_version_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " port_type =\t%" PRIx8 "\t(Type of the Device)\n", ioat_dma_expcap_port_type_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " slot_impl =\t%" PRIx8 "\t(N/A)\n", ioat_dma_expcap_slot_impl_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " irq_msg_num =\t%" PRIx8 "\t(N/A)\n", ioat_dma_expcap_irq_msg_num_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_devcap_t
 * Description: Implicit type of PCI Express Device Capability Register register
 * Fields:
 *   max_payload	(size 3, offset 0, init 0):	RO	Maximum PCIe payload size
 *   phantom	(size 2, offset 3, init 0):	RO	Phantom functions supported
 *   ext_tag	(size 1, offset 5, init 0):	RO	Extended tag supported
 *   ep_latency_0	(size 3, offset 6, init 0):	RO	Endpoint L0 acceptable latency
 *   ep_latency_1	(size 3, offset 9, init 0):	RO	Endpoint L1 acceptable latency
 *   att_btn	(size 1, offset 12, init 0):	RO	Attention button present on device
 *   att_ind	(size 1, offset 13, init 0):	RO	Attention indicator present on device
 *   pwr_ind	(size 1, offset 14, init 0):	RO	Power indicator present on device
 *   err_rep	(size 1, offset 15, init 0):	RO	Role based error reporting
 *   _anon16	(size 2, offset 16, init 0):	RSVD	_
 *   pwr_limit	(size 8, offset 18, init 0):	RO	Captured slot power limit value
 *   pwr_scale	(size 2, offset 26, init 0):	RO	Captured slot power limit scale
 *   flr	(size 1, offset 28, init 0):	RO	FLR supported
 *   _anon29	(size 3, offset 29, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_devcap_t;
#define ioat_dma_devcap_default 0x0
static inline uint8_t ioat_dma_devcap_max_payload_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_max_payload_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0x7) >> 0));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_max_payload_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_max_payload_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff8) | (0x7 & (((ioat_dma_devcap_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_devcap_phantom_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_phantom_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0x18) >> 3));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_phantom_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_phantom_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffe7) | (0x18 & (((ioat_dma_devcap_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_devcap_ext_tag_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_ext_tag_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0x20) >> 5));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_ext_tag_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_ext_tag_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffdf) | (0x20 & (((ioat_dma_devcap_t )(_fieldval)) << 5)));
}

static inline uint8_t ioat_dma_devcap_ep_latency_0_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_ep_latency_0_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0x1c0) >> 6));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_ep_latency_0_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_ep_latency_0_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffe3f) | (0x1c0 & (((ioat_dma_devcap_t )(_fieldval)) << 6)));
}

static inline uint8_t ioat_dma_devcap_ep_latency_1_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_ep_latency_1_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0xe00) >> 9));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_ep_latency_1_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_ep_latency_1_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffff1ff) | (0xe00 & (((ioat_dma_devcap_t )(_fieldval)) << 9)));
}

static inline uint8_t ioat_dma_devcap_att_btn_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_att_btn_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0x1000) >> 12));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_att_btn_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_att_btn_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffefff) | (0x1000 & (((ioat_dma_devcap_t )(_fieldval)) << 12)));
}

static inline uint8_t ioat_dma_devcap_att_ind_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_att_ind_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0x2000) >> 13));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_att_ind_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_att_ind_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffdfff) | (0x2000 & (((ioat_dma_devcap_t )(_fieldval)) << 13)));
}

static inline uint8_t ioat_dma_devcap_pwr_ind_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_pwr_ind_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0x4000) >> 14));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_pwr_ind_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_pwr_ind_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffbfff) | (0x4000 & (((ioat_dma_devcap_t )(_fieldval)) << 14)));
}

static inline uint8_t ioat_dma_devcap_err_rep_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_err_rep_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_err_rep_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_err_rep_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff7fff) | (0x8000 & (((ioat_dma_devcap_t )(_fieldval)) << 15)));
}

static inline uint8_t ioat_dma_devcap_pwr_limit_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_pwr_limit_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0x3fc0000) >> 18));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_pwr_limit_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_pwr_limit_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfc03ffff) | (0x3fc0000 & (((ioat_dma_devcap_t )(_fieldval)) << 18)));
}

static inline uint8_t ioat_dma_devcap_pwr_scale_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_pwr_scale_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0xc000000) >> 26));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_pwr_scale_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_pwr_scale_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf3ffffff) | (0xc000000 & (((ioat_dma_devcap_t )(_fieldval)) << 26)));
}

static inline uint8_t ioat_dma_devcap_flr_extract(ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_flr_extract(ioat_dma_devcap_t _regval)
{
    return((uint8_t )((_regval & 0x10000000) >> 28));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_flr_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_flr_insert(ioat_dma_devcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xefffffff) | (0x10000000 & (((ioat_dma_devcap_t )(_fieldval)) << 28)));
}

static inline int ioat_dma_devcap_prtval(char *_s, size_t _size, ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_devcap_prtval(char *_s, size_t _size, ioat_dma_devcap_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " max_payload =\t%" PRIx8 "\t(Maximum PCIe payload size)\n", ioat_dma_devcap_max_payload_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " phantom =\t%" PRIx8 "\t(Phantom functions supported)\n", ioat_dma_devcap_phantom_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ext_tag =\t%" PRIx8 "\t(Extended tag supported)\n", ioat_dma_devcap_ext_tag_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ep_latency_0 =\t%" PRIx8 "\t(Endpoint L0 acceptable latency)\n", ioat_dma_devcap_ep_latency_0_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ep_latency_1 =\t%" PRIx8 "\t(Endpoint L1 acceptable latency)\n", ioat_dma_devcap_ep_latency_1_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " att_btn =\t%" PRIx8 "\t(Attention button present on device)\n", ioat_dma_devcap_att_btn_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " att_ind =\t%" PRIx8 "\t(Attention indicator present on device)\n", ioat_dma_devcap_att_ind_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pwr_ind =\t%" PRIx8 "\t(Power indicator present on device)\n", ioat_dma_devcap_pwr_ind_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " err_rep =\t%" PRIx8 "\t(Role based error reporting)\n", ioat_dma_devcap_err_rep_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pwr_limit =\t%" PRIx8 "\t(Captured slot power limit value)\n", ioat_dma_devcap_pwr_limit_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pwr_scale =\t%" PRIx8 "\t(Captured slot power limit scale)\n", ioat_dma_devcap_pwr_scale_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " flr =\t%" PRIx8 "\t(FLR supported)\n", ioat_dma_devcap_flr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_devcon_t
 * Description: Implicit type of The PCI Express Device Control register register
 * Fields:
 *   corr_err	(size 1, offset 0, init 0):	RO	Enable correctable error reporting
 *   non_fat_err	(size 1, offset 1, init 0):	RO	Enable non-fatal error reporting
 *   fatal_err	(size 1, offset 2, init 0):	RO	Enable fatal error reporting
 *   unsup_rep	(size 1, offset 3, init 0):	RO	Enable unsupported request reporting
 *   relaxed_ord	(size 1, offset 4, init 0):	RW	Enable Relaxed ordering
 *   max_palyoad	(size 3, offset 5, init 0):	RO	Maximum payload size
 *   ext_tag_en	(size 1, offset 8, init 0):	RO	Enable extended tab field
 *   phantom_en	(size 1, offset 9, init 0):	RO	Enable phantom functions
 *   aux_pwr_en	(size 1, offset 10, init 0):	RO	Enable Auxiliary power managmenet
 *   no_snoop	(size 1, offset 11, init 0):	RW	Enable the no-snoop functionality
 *   max_rd_sz	(size 3, offset 12, init 0):	RO	Maximum read request size
 *   flr	(size 1, offset 15, init 0):	RW	Initiate FLR: reset only per FLR ECN
 */
typedef uint16_t ioat_dma_devcon_t;
#define ioat_dma_devcon_default 0x0
static inline uint8_t ioat_dma_devcon_corr_err_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_corr_err_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_corr_err_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_corr_err_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((ioat_dma_devcon_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_devcon_non_fat_err_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_non_fat_err_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_non_fat_err_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_non_fat_err_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffd) | (0x2 & (((ioat_dma_devcon_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_devcon_fatal_err_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_fatal_err_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_fatal_err_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_fatal_err_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffb) | (0x4 & (((ioat_dma_devcon_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_devcon_unsup_rep_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_unsup_rep_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_unsup_rep_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_unsup_rep_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff7) | (0x8 & (((ioat_dma_devcon_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_devcon_relaxed_ord_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_relaxed_ord_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_relaxed_ord_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_relaxed_ord_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffef) | (0x10 & (((ioat_dma_devcon_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_devcon_max_palyoad_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_max_palyoad_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0xe0) >> 5));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_max_palyoad_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_max_palyoad_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xff1f) | (0xe0 & (((ioat_dma_devcon_t )(_fieldval)) << 5)));
}

static inline uint8_t ioat_dma_devcon_ext_tag_en_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_ext_tag_en_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_ext_tag_en_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_ext_tag_en_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfeff) | (0x100 & (((ioat_dma_devcon_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_devcon_phantom_en_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_phantom_en_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x200) >> 9));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_phantom_en_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_phantom_en_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfdff) | (0x200 & (((ioat_dma_devcon_t )(_fieldval)) << 9)));
}

static inline uint8_t ioat_dma_devcon_aux_pwr_en_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_aux_pwr_en_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_aux_pwr_en_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_aux_pwr_en_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfbff) | (0x400 & (((ioat_dma_devcon_t )(_fieldval)) << 10)));
}

static inline uint8_t ioat_dma_devcon_no_snoop_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_no_snoop_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x800) >> 11));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_no_snoop_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_no_snoop_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf7ff) | (0x800 & (((ioat_dma_devcon_t )(_fieldval)) << 11)));
}

static inline uint8_t ioat_dma_devcon_max_rd_sz_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_max_rd_sz_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x7000) >> 12));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_max_rd_sz_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_max_rd_sz_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0x8fff) | (0x7000 & (((ioat_dma_devcon_t )(_fieldval)) << 12)));
}

static inline uint8_t ioat_dma_devcon_flr_extract(ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_flr_extract(ioat_dma_devcon_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_flr_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_flr_insert(ioat_dma_devcon_t _regval, uint8_t _fieldval)
{
    return((_regval & 0x7fff) | (0x8000 & (((ioat_dma_devcon_t )(_fieldval)) << 15)));
}

static inline int ioat_dma_devcon_prtval(char *_s, size_t _size, ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_devcon_prtval(char *_s, size_t _size, ioat_dma_devcon_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " corr_err =\t%" PRIx8 "\t(Enable correctable error reporting)\n", ioat_dma_devcon_corr_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " non_fat_err =\t%" PRIx8 "\t(Enable non-fatal error reporting)\n", ioat_dma_devcon_non_fat_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " fatal_err =\t%" PRIx8 "\t(Enable fatal error reporting)\n", ioat_dma_devcon_fatal_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unsup_rep =\t%" PRIx8 "\t(Enable unsupported request reporting)\n", ioat_dma_devcon_unsup_rep_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " relaxed_ord =\t%" PRIx8 "\t(Enable Relaxed ordering)\n", ioat_dma_devcon_relaxed_ord_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " max_palyoad =\t%" PRIx8 "\t(Maximum payload size)\n", ioat_dma_devcon_max_palyoad_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ext_tag_en =\t%" PRIx8 "\t(Enable extended tab field)\n", ioat_dma_devcon_ext_tag_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " phantom_en =\t%" PRIx8 "\t(Enable phantom functions)\n", ioat_dma_devcon_phantom_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " aux_pwr_en =\t%" PRIx8 "\t(Enable Auxiliary power managmenet)\n", ioat_dma_devcon_aux_pwr_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " no_snoop =\t%" PRIx8 "\t(Enable the no-snoop functionality)\n", ioat_dma_devcon_no_snoop_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " max_rd_sz =\t%" PRIx8 "\t(Maximum read request size)\n", ioat_dma_devcon_max_rd_sz_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " flr =\t%" PRIx8 "\t(Initiate FLR: reset only per FLR ECN)\n", ioat_dma_devcon_flr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_devsts_t
 * Description: Implicit type of Device Status Register register
 * Fields:
 *   corr_err	(size 1, offset 0, init 0):	RO	correctable error detected
 *   non_fat_err	(size 1, offset 1, init 0):	RO	non-fatal error detected
 *   fatal_err	(size 1, offset 2, init 0):	RO	fatal error detected
 *   unsup_req	(size 1, offset 3, init 0):	RO	Unsupported request detected
 *   aux_power	(size 1, offset 4, init 0):	RO	Auxiliary power detected
 *   tr_pending	(size 1, offset 5, init 0):	RO	Transaction pending
 *   _anon6	(size 10, offset 6, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_devsts_t;
#define ioat_dma_devsts_default 0x0
static inline uint8_t ioat_dma_devsts_corr_err_extract(ioat_dma_devsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_corr_err_extract(ioat_dma_devsts_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_devsts_t ioat_dma_devsts_corr_err_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devsts_t ioat_dma_devsts_corr_err_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((ioat_dma_devsts_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_devsts_non_fat_err_extract(ioat_dma_devsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_non_fat_err_extract(ioat_dma_devsts_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_devsts_t ioat_dma_devsts_non_fat_err_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devsts_t ioat_dma_devsts_non_fat_err_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffd) | (0x2 & (((ioat_dma_devsts_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_devsts_fatal_err_extract(ioat_dma_devsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_fatal_err_extract(ioat_dma_devsts_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_devsts_t ioat_dma_devsts_fatal_err_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devsts_t ioat_dma_devsts_fatal_err_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffb) | (0x4 & (((ioat_dma_devsts_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_devsts_unsup_req_extract(ioat_dma_devsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_unsup_req_extract(ioat_dma_devsts_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_devsts_t ioat_dma_devsts_unsup_req_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devsts_t ioat_dma_devsts_unsup_req_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff7) | (0x8 & (((ioat_dma_devsts_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_devsts_aux_power_extract(ioat_dma_devsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_aux_power_extract(ioat_dma_devsts_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_devsts_t ioat_dma_devsts_aux_power_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devsts_t ioat_dma_devsts_aux_power_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffef) | (0x10 & (((ioat_dma_devsts_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_devsts_tr_pending_extract(ioat_dma_devsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_tr_pending_extract(ioat_dma_devsts_t _regval)
{
    return((uint8_t )((_regval & 0x20) >> 5));
}

static inline ioat_dma_devsts_t ioat_dma_devsts_tr_pending_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devsts_t ioat_dma_devsts_tr_pending_insert(ioat_dma_devsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffdf) | (0x20 & (((ioat_dma_devsts_t )(_fieldval)) << 5)));
}

static inline int ioat_dma_devsts_prtval(char *_s, size_t _size, ioat_dma_devsts_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_devsts_prtval(char *_s, size_t _size, ioat_dma_devsts_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " corr_err =\t%" PRIx8 "\t(correctable error detected)\n", ioat_dma_devsts_corr_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " non_fat_err =\t%" PRIx8 "\t(non-fatal error detected)\n", ioat_dma_devsts_non_fat_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " fatal_err =\t%" PRIx8 "\t(fatal error detected)\n", ioat_dma_devsts_fatal_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unsup_req =\t%" PRIx8 "\t(Unsupported request detected)\n", ioat_dma_devsts_unsup_req_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " aux_power =\t%" PRIx8 "\t(Auxiliary power detected)\n", ioat_dma_devsts_aux_power_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tr_pending =\t%" PRIx8 "\t(Transaction pending)\n", ioat_dma_devsts_tr_pending_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_devcap2_t
 * Description: Implicit type of Device Capability Register 2 register
 * Fields:
 *   compl_timeout_values	(size 4, offset 0, init 0):	RO	Completion timeout values supported
 *   compl_timeout_disable	(size 1, offset 4, init 0):	RO	Completion timeout disable supported
 *   _anon5	(size 27, offset 5, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_devcap2_t;
#define ioat_dma_devcap2_default 0x0
static inline uint8_t ioat_dma_devcap2_compl_timeout_values_extract(ioat_dma_devcap2_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap2_compl_timeout_values_extract(ioat_dma_devcap2_t _regval)
{
    return((uint8_t )((_regval & 0xf) >> 0));
}

static inline ioat_dma_devcap2_t ioat_dma_devcap2_compl_timeout_values_insert(ioat_dma_devcap2_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap2_t ioat_dma_devcap2_compl_timeout_values_insert(ioat_dma_devcap2_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff0) | (0xf & (((ioat_dma_devcap2_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_devcap2_compl_timeout_disable_extract(ioat_dma_devcap2_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap2_compl_timeout_disable_extract(ioat_dma_devcap2_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_devcap2_t ioat_dma_devcap2_compl_timeout_disable_insert(ioat_dma_devcap2_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcap2_t ioat_dma_devcap2_compl_timeout_disable_insert(ioat_dma_devcap2_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffef) | (0x10 & (((ioat_dma_devcap2_t )(_fieldval)) << 4)));
}

static inline int ioat_dma_devcap2_prtval(char *_s, size_t _size, ioat_dma_devcap2_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_devcap2_prtval(char *_s, size_t _size, ioat_dma_devcap2_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_timeout_values =\t%" PRIx8 "\t(Completion timeout values supported)\n", ioat_dma_devcap2_compl_timeout_values_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_timeout_disable =\t%" PRIx8 "\t(Completion timeout disable supported)\n", ioat_dma_devcap2_compl_timeout_disable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_devcon2_t
 * Description: Implicit type of Device Configuration Register 2 register
 * Fields:
 *   compl_timeout_values	(size 4, offset 0, init 0):	RO	Completion timeout values
 *   compl_timeout_disable	(size 1, offset 4, init 0):	RW	Completion timeout disable
 *   _anon5	(size 11, offset 5, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_devcon2_t;
#define ioat_dma_devcon2_default 0x0
static inline uint8_t ioat_dma_devcon2_compl_timeout_values_extract(ioat_dma_devcon2_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon2_compl_timeout_values_extract(ioat_dma_devcon2_t _regval)
{
    return((uint8_t )((_regval & 0xf) >> 0));
}

static inline ioat_dma_devcon2_t ioat_dma_devcon2_compl_timeout_values_insert(ioat_dma_devcon2_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon2_t ioat_dma_devcon2_compl_timeout_values_insert(ioat_dma_devcon2_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff0) | (0xf & (((ioat_dma_devcon2_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_devcon2_compl_timeout_disable_extract(ioat_dma_devcon2_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon2_compl_timeout_disable_extract(ioat_dma_devcon2_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_devcon2_t ioat_dma_devcon2_compl_timeout_disable_insert(ioat_dma_devcon2_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_devcon2_t ioat_dma_devcon2_compl_timeout_disable_insert(ioat_dma_devcon2_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffef) | (0x10 & (((ioat_dma_devcon2_t )(_fieldval)) << 4)));
}

static inline int ioat_dma_devcon2_prtval(char *_s, size_t _size, ioat_dma_devcon2_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_devcon2_prtval(char *_s, size_t _size, ioat_dma_devcon2_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_timeout_values =\t%" PRIx8 "\t(Completion timeout values)\n", ioat_dma_devcon2_compl_timeout_values_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_timeout_disable =\t%" PRIx8 "\t(Completion timeout disable)\n", ioat_dma_devcon2_compl_timeout_disable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_pmcap_t
 * Description: Implicit type of Power Management Capability register
 * Fields:
 *   capid	(size 8, offset 0, init 0):	RO	Capability ID (PM cap ID)
 *   next	(size 8, offset 8, init 0):	RO	Pointer to the next capability field
 *   version	(size 3, offset 16, init 0):	RO	Power management version
 *   pme_clock	(size 1, offset 19, init 0):	RO	Power management clock
 *   _anon20	(size 1, offset 20, init 0):	RSVD	_
 *   dev_init	(size 1, offset 21, init 0):	RO	Device specific initialization
 *   aux_current	(size 3, offset 22, init 0):	RO	Auxiliary current
 *   d1_sup	(size 1, offset 25, init 0):	RO	D2 om state supported
 *   d2_sup	(size 1, offset 26, init 0):	RO	D2 om state supported
 *   _anon27	(size 5, offset 27, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_pmcap_t;
#define ioat_dma_pmcap_default 0x0
static inline uint8_t ioat_dma_pmcap_capid_extract(ioat_dma_pmcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_capid_extract(ioat_dma_pmcap_t _regval)
{
    return((uint8_t )((_regval & 0xff) >> 0));
}

static inline ioat_dma_pmcap_t ioat_dma_pmcap_capid_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcap_t ioat_dma_pmcap_capid_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff00) | (0xff & (((ioat_dma_pmcap_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_pmcap_next_extract(ioat_dma_pmcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_next_extract(ioat_dma_pmcap_t _regval)
{
    return((uint8_t )((_regval & 0xff00) >> 8));
}

static inline ioat_dma_pmcap_t ioat_dma_pmcap_next_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcap_t ioat_dma_pmcap_next_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff00ff) | (0xff00 & (((ioat_dma_pmcap_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_pmcap_version_extract(ioat_dma_pmcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_version_extract(ioat_dma_pmcap_t _regval)
{
    return((uint8_t )((_regval & 0x70000) >> 16));
}

static inline ioat_dma_pmcap_t ioat_dma_pmcap_version_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcap_t ioat_dma_pmcap_version_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff8ffff) | (0x70000 & (((ioat_dma_pmcap_t )(_fieldval)) << 16)));
}

static inline uint8_t ioat_dma_pmcap_pme_clock_extract(ioat_dma_pmcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_pme_clock_extract(ioat_dma_pmcap_t _regval)
{
    return((uint8_t )((_regval & 0x80000) >> 19));
}

static inline ioat_dma_pmcap_t ioat_dma_pmcap_pme_clock_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcap_t ioat_dma_pmcap_pme_clock_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff7ffff) | (0x80000 & (((ioat_dma_pmcap_t )(_fieldval)) << 19)));
}

static inline uint8_t ioat_dma_pmcap_dev_init_extract(ioat_dma_pmcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_dev_init_extract(ioat_dma_pmcap_t _regval)
{
    return((uint8_t )((_regval & 0x200000) >> 21));
}

static inline ioat_dma_pmcap_t ioat_dma_pmcap_dev_init_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcap_t ioat_dma_pmcap_dev_init_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffdfffff) | (0x200000 & (((ioat_dma_pmcap_t )(_fieldval)) << 21)));
}

static inline uint8_t ioat_dma_pmcap_aux_current_extract(ioat_dma_pmcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_aux_current_extract(ioat_dma_pmcap_t _regval)
{
    return((uint8_t )((_regval & 0x1c00000) >> 22));
}

static inline ioat_dma_pmcap_t ioat_dma_pmcap_aux_current_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcap_t ioat_dma_pmcap_aux_current_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfe3fffff) | (0x1c00000 & (((ioat_dma_pmcap_t )(_fieldval)) << 22)));
}

static inline uint8_t ioat_dma_pmcap_d1_sup_extract(ioat_dma_pmcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_d1_sup_extract(ioat_dma_pmcap_t _regval)
{
    return((uint8_t )((_regval & 0x2000000) >> 25));
}

static inline ioat_dma_pmcap_t ioat_dma_pmcap_d1_sup_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcap_t ioat_dma_pmcap_d1_sup_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfdffffff) | (0x2000000 & (((ioat_dma_pmcap_t )(_fieldval)) << 25)));
}

static inline uint8_t ioat_dma_pmcap_d2_sup_extract(ioat_dma_pmcap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_d2_sup_extract(ioat_dma_pmcap_t _regval)
{
    return((uint8_t )((_regval & 0x4000000) >> 26));
}

static inline ioat_dma_pmcap_t ioat_dma_pmcap_d2_sup_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcap_t ioat_dma_pmcap_d2_sup_insert(ioat_dma_pmcap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfbffffff) | (0x4000000 & (((ioat_dma_pmcap_t )(_fieldval)) << 26)));
}

static inline int ioat_dma_pmcap_prtval(char *_s, size_t _size, ioat_dma_pmcap_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_pmcap_prtval(char *_s, size_t _size, ioat_dma_pmcap_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " capid =\t%" PRIx8 "\t(Capability ID (PM cap ID))\n", ioat_dma_pmcap_capid_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " next =\t%" PRIx8 "\t(Pointer to the next capability field)\n", ioat_dma_pmcap_next_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " version =\t%" PRIx8 "\t(Power management version)\n", ioat_dma_pmcap_version_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pme_clock =\t%" PRIx8 "\t(Power management clock)\n", ioat_dma_pmcap_pme_clock_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dev_init =\t%" PRIx8 "\t(Device specific initialization)\n", ioat_dma_pmcap_dev_init_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " aux_current =\t%" PRIx8 "\t(Auxiliary current)\n", ioat_dma_pmcap_aux_current_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " d1_sup =\t%" PRIx8 "\t(D2 om state supported)\n", ioat_dma_pmcap_d1_sup_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " d2_sup =\t%" PRIx8 "\t(D2 om state supported)\n", ioat_dma_pmcap_d2_sup_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_pmcsr_t
 * Description: Implicit type of Power Management Control and Status. register
 * Fields:
 *   pwr_state	(size 2, offset 0, init 0):	RW	Powerstate to set
 *   _anon2	(size 1, offset 2, init 0):	RSVD	_
 *   no_soft_rst	(size 1, offset 3, init 0):	RO	No Softreset
 *   _anon4	(size 4, offset 4, init 0):	RSVD	_
 *   pme_en	(size 1, offset 8, init 0):	RO	Power Management Enabled
 *   data_select	(size 4, offset 9, init 0):	RO	Data Select
 *   data_scale	(size 2, offset 13, init 0):	RO	Data Scale
 *   pme_status	(size 1, offset 15, init 0):	RO	PME Status
 *   _anon16	(size 6, offset 16, init 0):	RSVD	_
 *   b2_b3_sup	(size 1, offset 22, init 0):	RO	B2-B3 Support
 *   clk_ctrl_en	(size 1, offset 23, init 0):	RO	Bus power clock control enabled
 *   data	(size 8, offset 24, init 0):	RO	Data field
 */
typedef uint32_t ioat_dma_pmcsr_t;
#define ioat_dma_pmcsr_default 0x0
static inline uint8_t ioat_dma_pmcsr_pwr_state_extract(ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_pwr_state_extract(ioat_dma_pmcsr_t _regval)
{
    return((uint8_t )((_regval & 0x3) >> 0));
}

static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_pwr_state_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_pwr_state_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffc) | (0x3 & (((ioat_dma_pmcsr_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_pmcsr_no_soft_rst_extract(ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_no_soft_rst_extract(ioat_dma_pmcsr_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_no_soft_rst_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_no_soft_rst_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff7) | (0x8 & (((ioat_dma_pmcsr_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_pmcsr_pme_en_extract(ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_pme_en_extract(ioat_dma_pmcsr_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_pme_en_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_pme_en_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffeff) | (0x100 & (((ioat_dma_pmcsr_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_pmcsr_data_select_extract(ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_data_select_extract(ioat_dma_pmcsr_t _regval)
{
    return((uint8_t )((_regval & 0x1e00) >> 9));
}

static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_data_select_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_data_select_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffe1ff) | (0x1e00 & (((ioat_dma_pmcsr_t )(_fieldval)) << 9)));
}

static inline uint8_t ioat_dma_pmcsr_data_scale_extract(ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_data_scale_extract(ioat_dma_pmcsr_t _regval)
{
    return((uint8_t )((_regval & 0x6000) >> 13));
}

static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_data_scale_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_data_scale_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff9fff) | (0x6000 & (((ioat_dma_pmcsr_t )(_fieldval)) << 13)));
}

static inline uint8_t ioat_dma_pmcsr_pme_status_extract(ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_pme_status_extract(ioat_dma_pmcsr_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_pme_status_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_pme_status_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff7fff) | (0x8000 & (((ioat_dma_pmcsr_t )(_fieldval)) << 15)));
}

static inline uint8_t ioat_dma_pmcsr_b2_b3_sup_extract(ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_b2_b3_sup_extract(ioat_dma_pmcsr_t _regval)
{
    return((uint8_t )((_regval & 0x400000) >> 22));
}

static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_b2_b3_sup_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_b2_b3_sup_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffbfffff) | (0x400000 & (((ioat_dma_pmcsr_t )(_fieldval)) << 22)));
}

static inline uint8_t ioat_dma_pmcsr_clk_ctrl_en_extract(ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_clk_ctrl_en_extract(ioat_dma_pmcsr_t _regval)
{
    return((uint8_t )((_regval & 0x800000) >> 23));
}

static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_clk_ctrl_en_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_clk_ctrl_en_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xff7fffff) | (0x800000 & (((ioat_dma_pmcsr_t )(_fieldval)) << 23)));
}

static inline uint8_t ioat_dma_pmcsr_data_extract(ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_data_extract(ioat_dma_pmcsr_t _regval)
{
    return((uint8_t )((_regval & 0xff000000) >> 24));
}

static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_data_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_data_insert(ioat_dma_pmcsr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff) | (0xff000000 & (((ioat_dma_pmcsr_t )(_fieldval)) << 24)));
}

static inline int ioat_dma_pmcsr_prtval(char *_s, size_t _size, ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_pmcsr_prtval(char *_s, size_t _size, ioat_dma_pmcsr_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pwr_state =\t%" PRIx8 "\t(Powerstate to set)\n", ioat_dma_pmcsr_pwr_state_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " no_soft_rst =\t%" PRIx8 "\t(No Softreset)\n", ioat_dma_pmcsr_no_soft_rst_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pme_en =\t%" PRIx8 "\t(Power Management Enabled)\n", ioat_dma_pmcsr_pme_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " data_select =\t%" PRIx8 "\t(Data Select)\n", ioat_dma_pmcsr_data_select_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " data_scale =\t%" PRIx8 "\t(Data Scale)\n", ioat_dma_pmcsr_data_scale_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pme_status =\t%" PRIx8 "\t(PME Status)\n", ioat_dma_pmcsr_pme_status_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " b2_b3_sup =\t%" PRIx8 "\t(B2-B3 Support)\n", ioat_dma_pmcsr_b2_b3_sup_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " clk_ctrl_en =\t%" PRIx8 "\t(Bus power clock control enabled)\n", ioat_dma_pmcsr_clk_ctrl_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " data =\t%" PRIx8 "\t(Data field)\n", ioat_dma_pmcsr_data_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dmauncerrsts_t
 * Description: Implicit type of DMA Cluster Uncorrectable Error Status register
 * Fields:
 *   _anon0	(size 2, offset 0, init 0):	RSVD	_
 *   dp_status	(size 1, offset 2, init 0):	RWCS	Received poisoned data from dp status
 *   hw_parity	(size 1, offset 3, init 0):	RWCS	DMA internal HW parity error
 *   _anon4	(size 3, offset 4, init 0):	RSVD	_
 *   compl_hdr	(size 1, offset 7, init 0):	RWCS	Read completion error staturs
 *   _anon8	(size 2, offset 8, init 0):	RSVD	_
 *   addr_dec	(size 1, offset 10, init 0):	RWCS	Read address decode error statuts
 *   _anon11	(size 1, offset 11, init 0):	RSVD	_
 *   syndrome	(size 1, offset 12, init 0):	RWCS	Syndrome multiple errors
 *   _anon13	(size 19, offset 13, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_dmauncerrsts_t;
#define ioat_dma_dmauncerrsts_default 0x0
static inline uint8_t ioat_dma_dmauncerrsts_dp_status_extract(ioat_dma_dmauncerrsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsts_dp_status_extract(ioat_dma_dmauncerrsts_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_dp_status_insert(ioat_dma_dmauncerrsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_dp_status_insert(ioat_dma_dmauncerrsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffb) | (0x4 & (((ioat_dma_dmauncerrsts_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_dmauncerrsts_hw_parity_extract(ioat_dma_dmauncerrsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsts_hw_parity_extract(ioat_dma_dmauncerrsts_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_hw_parity_insert(ioat_dma_dmauncerrsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_hw_parity_insert(ioat_dma_dmauncerrsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff7) | (0x8 & (((ioat_dma_dmauncerrsts_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_dmauncerrsts_compl_hdr_extract(ioat_dma_dmauncerrsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsts_compl_hdr_extract(ioat_dma_dmauncerrsts_t _regval)
{
    return((uint8_t )((_regval & 0x80) >> 7));
}

static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_compl_hdr_insert(ioat_dma_dmauncerrsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_compl_hdr_insert(ioat_dma_dmauncerrsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff7f) | (0x80 & (((ioat_dma_dmauncerrsts_t )(_fieldval)) << 7)));
}

static inline uint8_t ioat_dma_dmauncerrsts_addr_dec_extract(ioat_dma_dmauncerrsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsts_addr_dec_extract(ioat_dma_dmauncerrsts_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_addr_dec_insert(ioat_dma_dmauncerrsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_addr_dec_insert(ioat_dma_dmauncerrsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffbff) | (0x400 & (((ioat_dma_dmauncerrsts_t )(_fieldval)) << 10)));
}

static inline uint8_t ioat_dma_dmauncerrsts_syndrome_extract(ioat_dma_dmauncerrsts_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsts_syndrome_extract(ioat_dma_dmauncerrsts_t _regval)
{
    return((uint8_t )((_regval & 0x1000) >> 12));
}

static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_syndrome_insert(ioat_dma_dmauncerrsts_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_syndrome_insert(ioat_dma_dmauncerrsts_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffefff) | (0x1000 & (((ioat_dma_dmauncerrsts_t )(_fieldval)) << 12)));
}

static inline int ioat_dma_dmauncerrsts_prtval(char *_s, size_t _size, ioat_dma_dmauncerrsts_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dmauncerrsts_prtval(char *_s, size_t _size, ioat_dma_dmauncerrsts_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dp_status =\t%" PRIx8 "\t(Received poisoned data from dp status)\n", ioat_dma_dmauncerrsts_dp_status_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " hw_parity =\t%" PRIx8 "\t(DMA internal HW parity error)\n", ioat_dma_dmauncerrsts_hw_parity_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_hdr =\t%" PRIx8 "\t(Read completion error staturs)\n", ioat_dma_dmauncerrsts_compl_hdr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " addr_dec =\t%" PRIx8 "\t(Read address decode error statuts)\n", ioat_dma_dmauncerrsts_addr_dec_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " syndrome =\t%" PRIx8 "\t(Syndrome multiple errors)\n", ioat_dma_dmauncerrsts_syndrome_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dmauncerrmsk_t
 * Description: Implicit type of DMA Cluster Uncorrectable Error Mask register
 * Fields:
 *   _anon0	(size 2, offset 0, init 0):	RSVD	_
 *   dp_status	(size 1, offset 2, init 0):	RW	Received poisoned data from dp status
 *   hw_parity	(size 1, offset 3, init 0):	RW	DMA internal HW parity error
 *   _anon4	(size 3, offset 4, init 0):	RSVD	_
 *   compl_hdr	(size 1, offset 7, init 0):	RW	Read completion error staturs
 *   _anon8	(size 2, offset 8, init 0):	RSVD	_
 *   addr_dec	(size 1, offset 10, init 0):	RW	Read address decode error statuts
 *   _anon11	(size 1, offset 11, init 0):	RSVD	_
 *   syndrome	(size 1, offset 12, init 0):	RW	Syndrome multiple errors
 *   _anon13	(size 19, offset 13, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_dmauncerrmsk_t;
#define ioat_dma_dmauncerrmsk_default 0x0
static inline uint8_t ioat_dma_dmauncerrmsk_dp_status_extract(ioat_dma_dmauncerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrmsk_dp_status_extract(ioat_dma_dmauncerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_dp_status_insert(ioat_dma_dmauncerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_dp_status_insert(ioat_dma_dmauncerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffb) | (0x4 & (((ioat_dma_dmauncerrmsk_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_dmauncerrmsk_hw_parity_extract(ioat_dma_dmauncerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrmsk_hw_parity_extract(ioat_dma_dmauncerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_hw_parity_insert(ioat_dma_dmauncerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_hw_parity_insert(ioat_dma_dmauncerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff7) | (0x8 & (((ioat_dma_dmauncerrmsk_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_dmauncerrmsk_compl_hdr_extract(ioat_dma_dmauncerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrmsk_compl_hdr_extract(ioat_dma_dmauncerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x80) >> 7));
}

static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_compl_hdr_insert(ioat_dma_dmauncerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_compl_hdr_insert(ioat_dma_dmauncerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff7f) | (0x80 & (((ioat_dma_dmauncerrmsk_t )(_fieldval)) << 7)));
}

static inline uint8_t ioat_dma_dmauncerrmsk_addr_dec_extract(ioat_dma_dmauncerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrmsk_addr_dec_extract(ioat_dma_dmauncerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_addr_dec_insert(ioat_dma_dmauncerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_addr_dec_insert(ioat_dma_dmauncerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffbff) | (0x400 & (((ioat_dma_dmauncerrmsk_t )(_fieldval)) << 10)));
}

static inline uint8_t ioat_dma_dmauncerrmsk_syndrome_extract(ioat_dma_dmauncerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrmsk_syndrome_extract(ioat_dma_dmauncerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x1000) >> 12));
}

static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_syndrome_insert(ioat_dma_dmauncerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_syndrome_insert(ioat_dma_dmauncerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffefff) | (0x1000 & (((ioat_dma_dmauncerrmsk_t )(_fieldval)) << 12)));
}

static inline int ioat_dma_dmauncerrmsk_prtval(char *_s, size_t _size, ioat_dma_dmauncerrmsk_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dmauncerrmsk_prtval(char *_s, size_t _size, ioat_dma_dmauncerrmsk_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dp_status =\t%" PRIx8 "\t(Received poisoned data from dp status)\n", ioat_dma_dmauncerrmsk_dp_status_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " hw_parity =\t%" PRIx8 "\t(DMA internal HW parity error)\n", ioat_dma_dmauncerrmsk_hw_parity_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_hdr =\t%" PRIx8 "\t(Read completion error staturs)\n", ioat_dma_dmauncerrmsk_compl_hdr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " addr_dec =\t%" PRIx8 "\t(Read address decode error statuts)\n", ioat_dma_dmauncerrmsk_addr_dec_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " syndrome =\t%" PRIx8 "\t(Syndrome multiple errors)\n", ioat_dma_dmauncerrmsk_syndrome_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dmauncerrsev_t
 * Description: Implicit type of DMA Cluster Uncorrectable Error Severity. register
 * Fields:
 *   _anon0	(size 2, offset 0, init 0):	RSVD	_
 *   dp_status	(size 1, offset 2, init 0):	RW	Received poisoned data from dp status
 *   hw_parity	(size 1, offset 3, init 0):	RW	DMA internal HW parity error
 *   _anon4	(size 3, offset 4, init 0):	RSVD	_
 *   compl_hdr	(size 1, offset 7, init 0):	RW	Read completion error staturs
 *   _anon8	(size 2, offset 8, init 0):	RSVD	_
 *   addr_dec	(size 1, offset 10, init 0):	RW	Read address decode error statuts
 *   _anon11	(size 1, offset 11, init 0):	RSVD	_
 *   syndrome	(size 1, offset 12, init 0):	RW	Syndrome multiple errors
 *   _anon13	(size 19, offset 13, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_dmauncerrsev_t;
#define ioat_dma_dmauncerrsev_default 0x0
static inline uint8_t ioat_dma_dmauncerrsev_dp_status_extract(ioat_dma_dmauncerrsev_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsev_dp_status_extract(ioat_dma_dmauncerrsev_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_dp_status_insert(ioat_dma_dmauncerrsev_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_dp_status_insert(ioat_dma_dmauncerrsev_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffb) | (0x4 & (((ioat_dma_dmauncerrsev_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_dmauncerrsev_hw_parity_extract(ioat_dma_dmauncerrsev_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsev_hw_parity_extract(ioat_dma_dmauncerrsev_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_hw_parity_insert(ioat_dma_dmauncerrsev_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_hw_parity_insert(ioat_dma_dmauncerrsev_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff7) | (0x8 & (((ioat_dma_dmauncerrsev_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_dmauncerrsev_compl_hdr_extract(ioat_dma_dmauncerrsev_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsev_compl_hdr_extract(ioat_dma_dmauncerrsev_t _regval)
{
    return((uint8_t )((_regval & 0x80) >> 7));
}

static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_compl_hdr_insert(ioat_dma_dmauncerrsev_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_compl_hdr_insert(ioat_dma_dmauncerrsev_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff7f) | (0x80 & (((ioat_dma_dmauncerrsev_t )(_fieldval)) << 7)));
}

static inline uint8_t ioat_dma_dmauncerrsev_addr_dec_extract(ioat_dma_dmauncerrsev_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsev_addr_dec_extract(ioat_dma_dmauncerrsev_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_addr_dec_insert(ioat_dma_dmauncerrsev_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_addr_dec_insert(ioat_dma_dmauncerrsev_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffbff) | (0x400 & (((ioat_dma_dmauncerrsev_t )(_fieldval)) << 10)));
}

static inline uint8_t ioat_dma_dmauncerrsev_syndrome_extract(ioat_dma_dmauncerrsev_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsev_syndrome_extract(ioat_dma_dmauncerrsev_t _regval)
{
    return((uint8_t )((_regval & 0x1000) >> 12));
}

static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_syndrome_insert(ioat_dma_dmauncerrsev_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_syndrome_insert(ioat_dma_dmauncerrsev_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffefff) | (0x1000 & (((ioat_dma_dmauncerrsev_t )(_fieldval)) << 12)));
}

static inline int ioat_dma_dmauncerrsev_prtval(char *_s, size_t _size, ioat_dma_dmauncerrsev_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dmauncerrsev_prtval(char *_s, size_t _size, ioat_dma_dmauncerrsev_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dp_status =\t%" PRIx8 "\t(Received poisoned data from dp status)\n", ioat_dma_dmauncerrsev_dp_status_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " hw_parity =\t%" PRIx8 "\t(DMA internal HW parity error)\n", ioat_dma_dmauncerrsev_hw_parity_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_hdr =\t%" PRIx8 "\t(Read completion error staturs)\n", ioat_dma_dmauncerrsev_compl_hdr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " addr_dec =\t%" PRIx8 "\t(Read address decode error statuts)\n", ioat_dma_dmauncerrsev_addr_dec_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " syndrome =\t%" PRIx8 "\t(Syndrome multiple errors)\n", ioat_dma_dmauncerrsev_syndrome_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dmauncerrptr_t
 * Description: Implicit type of DMA Cluster Uncorrectable Error Pointer register
 * Fields:
 *   uncerrptr	(size 5, offset 0, init 0):	RO	oints to the first uncorrectable error logged in the DMAUNCERRSTS register.
 *   _anon5	(size 3, offset 5, init 0):	RSVD	_
 */
typedef uint8_t ioat_dma_dmauncerrptr_t;
#define ioat_dma_dmauncerrptr_default 0x0
static inline uint8_t ioat_dma_dmauncerrptr_uncerrptr_extract(ioat_dma_dmauncerrptr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrptr_uncerrptr_extract(ioat_dma_dmauncerrptr_t _regval)
{
    return((uint8_t )((_regval & 0x1f) >> 0));
}

static inline ioat_dma_dmauncerrptr_t ioat_dma_dmauncerrptr_uncerrptr_insert(ioat_dma_dmauncerrptr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrptr_t ioat_dma_dmauncerrptr_uncerrptr_insert(ioat_dma_dmauncerrptr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xe0) | (0x1f & (((ioat_dma_dmauncerrptr_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_dmauncerrptr_prtval(char *_s, size_t _size, ioat_dma_dmauncerrptr_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dmauncerrptr_prtval(char *_s, size_t _size, ioat_dma_dmauncerrptr_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " uncerrptr =\t%" PRIx8 "\t(oints to the first uncorrectable error logged in the DMAUNCERRSTS register.)\n", ioat_dma_dmauncerrptr_uncerrptr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dmaglberrptr_t
 * Description: Implicit type of DMA Cluster Global Error Pointer register
 * Fields:
 *   glbl_err	(size 4, offset 0, init 0):	RW	Points to 8 possible sources of uncorrectable rrors
 *   _anon4	(size 4, offset 4, init 0):	RSVD	_
 */
typedef uint8_t ioat_dma_dmaglberrptr_t;
#define ioat_dma_dmaglberrptr_default 0x0
static inline uint8_t ioat_dma_dmaglberrptr_glbl_err_extract(ioat_dma_dmaglberrptr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmaglberrptr_glbl_err_extract(ioat_dma_dmaglberrptr_t _regval)
{
    return((uint8_t )((_regval & 0xf) >> 0));
}

static inline ioat_dma_dmaglberrptr_t ioat_dma_dmaglberrptr_glbl_err_insert(ioat_dma_dmaglberrptr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmaglberrptr_t ioat_dma_dmaglberrptr_glbl_err_insert(ioat_dma_dmaglberrptr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf0) | (0xf & (((ioat_dma_dmaglberrptr_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_dmaglberrptr_prtval(char *_s, size_t _size, ioat_dma_dmaglberrptr_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dmaglberrptr_prtval(char *_s, size_t _size, ioat_dma_dmaglberrptr_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " glbl_err =\t%" PRIx8 "\t(Points to 8 possible sources of uncorrectable rrors)\n", ioat_dma_dmaglberrptr_glbl_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chanerr_int_t
 * Description: Implicit type of Internal DMA Channel Error Status Registers. register
 * Fields:
 *   dmatranserr	(size 1, offset 0, init 0):	RWCS	DMA Transfer Source address error
 *   dmaxfererr	(size 1, offset 1, init 0):	RWCS	DMA Transfer Destination address error
 *   nxtdescerr	(size 1, offset 2, init 0):	RWCS	Next Descriptor Address error
 *   descerr	(size 1, offset 3, init 0):	RWCS	Descriptor error
 *   chanaddr	(size 1, offset 4, init 0):	RWCS	Channel address value error
 *   chancmderr	(size 1, offset 5, init 0):	RWCS	Channel command error
 *   cdataerr	(size 1, offset 6, init 0):	RWCS	Data parity error
 *   dmadataerr	(size 1, offset 7, init 0):	RWCS	DMA Data Parity error
 *   rddataerr	(size 1, offset 8, init 0):	RWCS	Read Data error
 *   wrdataerr	(size 1, offset 9, init 0):	RWCS	Write data error
 *   descctrlerr	(size 1, offset 10, init 0):	RWCS	Description control  error
 *   desclenerr	(size 1, offset 11, init 0):	RWCS	Description length error
 *   cmpaddrerr	(size 1, offset 12, init 0):	RWCS	Completion Address error
 *   intcfgerr	(size 1, offset 13, init 0):	RWCS	Interrupt confiuguratio error
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   unaffilerr	(size 1, offset 15, init 0):	RO	Unaffiliated Error
 *   crc_err	(size 1, offset 16, init 0):	RWCS	CRC test failed
 *   xorqerr	(size 1, offset 17, init 0):	RWCS	Xor error
 *   desccnterr	(size 1, offset 18, init 0):	RWCS	Descriptor Count error
 *   _anon19	(size 13, offset 19, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_chanerr_int_t;
#define ioat_dma_chanerr_int_default 0x0
static inline uint8_t ioat_dma_chanerr_int_dmatranserr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_dmatranserr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_dmatranserr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_dmatranserr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffe) | (0x1 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_chanerr_int_dmaxfererr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_dmaxfererr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_dmaxfererr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_dmaxfererr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffd) | (0x2 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_chanerr_int_nxtdescerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_nxtdescerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_nxtdescerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_nxtdescerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffb) | (0x4 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_chanerr_int_descerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_descerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_descerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_descerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff7) | (0x8 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_chanerr_int_chanaddr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_chanaddr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_chanaddr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_chanaddr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffef) | (0x10 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_chanerr_int_chancmderr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_chancmderr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x20) >> 5));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_chancmderr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_chancmderr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffdf) | (0x20 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 5)));
}

static inline uint8_t ioat_dma_chanerr_int_cdataerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_cdataerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x40) >> 6));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_cdataerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_cdataerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffbf) | (0x40 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 6)));
}

static inline uint8_t ioat_dma_chanerr_int_dmadataerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_dmadataerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x80) >> 7));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_dmadataerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_dmadataerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff7f) | (0x80 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 7)));
}

static inline uint8_t ioat_dma_chanerr_int_rddataerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_rddataerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_rddataerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_rddataerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffeff) | (0x100 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_chanerr_int_wrdataerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_wrdataerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x200) >> 9));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_wrdataerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_wrdataerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffdff) | (0x200 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 9)));
}

static inline uint8_t ioat_dma_chanerr_int_descctrlerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_descctrlerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_descctrlerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_descctrlerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffbff) | (0x400 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 10)));
}

static inline uint8_t ioat_dma_chanerr_int_desclenerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_desclenerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x800) >> 11));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_desclenerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_desclenerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffff7ff) | (0x800 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 11)));
}

static inline uint8_t ioat_dma_chanerr_int_cmpaddrerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_cmpaddrerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x1000) >> 12));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_cmpaddrerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_cmpaddrerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffefff) | (0x1000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 12)));
}

static inline uint8_t ioat_dma_chanerr_int_intcfgerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_intcfgerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x2000) >> 13));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_intcfgerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_intcfgerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffdfff) | (0x2000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 13)));
}

static inline uint8_t ioat_dma_chanerr_int_unaffilerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_unaffilerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_unaffilerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_unaffilerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff7fff) | (0x8000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 15)));
}

static inline uint8_t ioat_dma_chanerr_int_crc_err_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_crc_err_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x10000) >> 16));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_crc_err_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_crc_err_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffeffff) | (0x10000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 16)));
}

static inline uint8_t ioat_dma_chanerr_int_xorqerr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_xorqerr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x20000) >> 17));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_xorqerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_xorqerr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffdffff) | (0x20000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 17)));
}

static inline uint8_t ioat_dma_chanerr_int_desccnterr_extract(ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_desccnterr_extract(ioat_dma_chanerr_int_t _regval)
{
    return((uint8_t )((_regval & 0x40000) >> 18));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_desccnterr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_desccnterr_insert(ioat_dma_chanerr_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffbffff) | (0x40000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 18)));
}

static inline int ioat_dma_chanerr_int_prtval(char *_s, size_t _size, ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chanerr_int_prtval(char *_s, size_t _size, ioat_dma_chanerr_int_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmatranserr =\t%" PRIx8 "\t(DMA Transfer Source address error)\n", ioat_dma_chanerr_int_dmatranserr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmaxfererr =\t%" PRIx8 "\t(DMA Transfer Destination address error)\n", ioat_dma_chanerr_int_dmaxfererr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " nxtdescerr =\t%" PRIx8 "\t(Next Descriptor Address error)\n", ioat_dma_chanerr_int_nxtdescerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descerr =\t%" PRIx8 "\t(Descriptor error)\n", ioat_dma_chanerr_int_descerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanaddr =\t%" PRIx8 "\t(Channel address value error)\n", ioat_dma_chanerr_int_chanaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chancmderr =\t%" PRIx8 "\t(Channel command error)\n", ioat_dma_chanerr_int_chancmderr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cdataerr =\t%" PRIx8 "\t(Data parity error)\n", ioat_dma_chanerr_int_cdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmadataerr =\t%" PRIx8 "\t(DMA Data Parity error)\n", ioat_dma_chanerr_int_dmadataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rddataerr =\t%" PRIx8 "\t(Read Data error)\n", ioat_dma_chanerr_int_rddataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " wrdataerr =\t%" PRIx8 "\t(Write data error)\n", ioat_dma_chanerr_int_wrdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descctrlerr =\t%" PRIx8 "\t(Description control  error)\n", ioat_dma_chanerr_int_descctrlerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desclenerr =\t%" PRIx8 "\t(Description length error)\n", ioat_dma_chanerr_int_desclenerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpaddrerr =\t%" PRIx8 "\t(Completion Address error)\n", ioat_dma_chanerr_int_cmpaddrerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intcfgerr =\t%" PRIx8 "\t(Interrupt confiuguratio error)\n", ioat_dma_chanerr_int_intcfgerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unaffilerr =\t%" PRIx8 "\t(Unaffiliated Error)\n", ioat_dma_chanerr_int_unaffilerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc_err =\t%" PRIx8 "\t(CRC test failed)\n", ioat_dma_chanerr_int_crc_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xorqerr =\t%" PRIx8 "\t(Xor error)\n", ioat_dma_chanerr_int_xorqerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desccnterr =\t%" PRIx8 "\t(Descriptor Count error)\n", ioat_dma_chanerr_int_desccnterr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chanerrmsk_int_t
 * Description: Implicit type of Internal DMA Channel Error Mask Registers. register
 * Fields:
 *   dmatranserr	(size 1, offset 0, init 0):	RWCS	DMA Transfer Source address error
 *   dmaxfererr	(size 1, offset 1, init 0):	RWCS	DMA Transfer Destination address error
 *   nxtdescerr	(size 1, offset 2, init 0):	RWCS	Next Descriptor Address error
 *   descerr	(size 1, offset 3, init 0):	RWCS	Descriptor error
 *   chanaddr	(size 1, offset 4, init 0):	RWCS	Channel address value error
 *   chancmderr	(size 1, offset 5, init 0):	RWCS	Channel command error
 *   cdataerr	(size 1, offset 6, init 0):	RWCS	Data parity error
 *   dmadataerr	(size 1, offset 7, init 0):	RWCS	DMA Data Parity error
 *   rddataerr	(size 1, offset 8, init 0):	RWCS	Read Data error
 *   wrdataerr	(size 1, offset 9, init 0):	RWCS	Write data error
 *   descctrlerr	(size 1, offset 10, init 0):	RWCS	Description control  error
 *   desclenerr	(size 1, offset 11, init 0):	RWCS	Description length error
 *   cmpaddrerr	(size 1, offset 12, init 0):	RWCS	Completion Address error
 *   intcfgerr	(size 1, offset 13, init 0):	RWCS	Interrupt confiuguratio error
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   unaffilerr	(size 1, offset 15, init 0):	RO	Unaffiliated Error
 *   crc_err	(size 1, offset 16, init 0):	RWCS	CRC test failed
 *   xorqerr	(size 1, offset 17, init 0):	RWCS	Xor error
 *   desccnterr	(size 1, offset 18, init 0):	RWCS	Descriptor Count error
 *   _anon19	(size 13, offset 19, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_chanerrmsk_int_t;
#define ioat_dma_chanerrmsk_int_default 0x0
static inline uint8_t ioat_dma_chanerrmsk_int_dmatranserr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_dmatranserr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_dmatranserr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_dmatranserr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffe) | (0x1 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_dmaxfererr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_dmaxfererr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_dmaxfererr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_dmaxfererr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffd) | (0x2 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_nxtdescerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_nxtdescerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_nxtdescerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_nxtdescerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffb) | (0x4 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_descerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_descerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_descerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_descerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff7) | (0x8 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_chanaddr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_chanaddr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_chanaddr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_chanaddr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffef) | (0x10 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_chancmderr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_chancmderr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x20) >> 5));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_chancmderr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_chancmderr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffdf) | (0x20 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 5)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_cdataerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_cdataerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x40) >> 6));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_cdataerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_cdataerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffbf) | (0x40 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 6)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_dmadataerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_dmadataerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x80) >> 7));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_dmadataerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_dmadataerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff7f) | (0x80 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 7)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_rddataerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_rddataerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_rddataerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_rddataerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffeff) | (0x100 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_wrdataerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_wrdataerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x200) >> 9));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_wrdataerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_wrdataerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffdff) | (0x200 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 9)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_descctrlerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_descctrlerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_descctrlerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_descctrlerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffbff) | (0x400 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 10)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_desclenerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_desclenerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x800) >> 11));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_desclenerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_desclenerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffff7ff) | (0x800 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 11)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_cmpaddrerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_cmpaddrerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x1000) >> 12));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_cmpaddrerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_cmpaddrerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffefff) | (0x1000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 12)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_intcfgerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_intcfgerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x2000) >> 13));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_intcfgerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_intcfgerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffdfff) | (0x2000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 13)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_unaffilerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_unaffilerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_unaffilerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_unaffilerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff7fff) | (0x8000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 15)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_crc_err_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_crc_err_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x10000) >> 16));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_crc_err_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_crc_err_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffeffff) | (0x10000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 16)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_xorqerr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_xorqerr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x20000) >> 17));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_xorqerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_xorqerr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffdffff) | (0x20000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 17)));
}

static inline uint8_t ioat_dma_chanerrmsk_int_desccnterr_extract(ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_desccnterr_extract(ioat_dma_chanerrmsk_int_t _regval)
{
    return((uint8_t )((_regval & 0x40000) >> 18));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_desccnterr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_desccnterr_insert(ioat_dma_chanerrmsk_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffbffff) | (0x40000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 18)));
}

static inline int ioat_dma_chanerrmsk_int_prtval(char *_s, size_t _size, ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chanerrmsk_int_prtval(char *_s, size_t _size, ioat_dma_chanerrmsk_int_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmatranserr =\t%" PRIx8 "\t(DMA Transfer Source address error)\n", ioat_dma_chanerrmsk_int_dmatranserr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmaxfererr =\t%" PRIx8 "\t(DMA Transfer Destination address error)\n", ioat_dma_chanerrmsk_int_dmaxfererr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " nxtdescerr =\t%" PRIx8 "\t(Next Descriptor Address error)\n", ioat_dma_chanerrmsk_int_nxtdescerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descerr =\t%" PRIx8 "\t(Descriptor error)\n", ioat_dma_chanerrmsk_int_descerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanaddr =\t%" PRIx8 "\t(Channel address value error)\n", ioat_dma_chanerrmsk_int_chanaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chancmderr =\t%" PRIx8 "\t(Channel command error)\n", ioat_dma_chanerrmsk_int_chancmderr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cdataerr =\t%" PRIx8 "\t(Data parity error)\n", ioat_dma_chanerrmsk_int_cdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmadataerr =\t%" PRIx8 "\t(DMA Data Parity error)\n", ioat_dma_chanerrmsk_int_dmadataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rddataerr =\t%" PRIx8 "\t(Read Data error)\n", ioat_dma_chanerrmsk_int_rddataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " wrdataerr =\t%" PRIx8 "\t(Write data error)\n", ioat_dma_chanerrmsk_int_wrdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descctrlerr =\t%" PRIx8 "\t(Description control  error)\n", ioat_dma_chanerrmsk_int_descctrlerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desclenerr =\t%" PRIx8 "\t(Description length error)\n", ioat_dma_chanerrmsk_int_desclenerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpaddrerr =\t%" PRIx8 "\t(Completion Address error)\n", ioat_dma_chanerrmsk_int_cmpaddrerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intcfgerr =\t%" PRIx8 "\t(Interrupt confiuguratio error)\n", ioat_dma_chanerrmsk_int_intcfgerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unaffilerr =\t%" PRIx8 "\t(Unaffiliated Error)\n", ioat_dma_chanerrmsk_int_unaffilerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc_err =\t%" PRIx8 "\t(CRC test failed)\n", ioat_dma_chanerrmsk_int_crc_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xorqerr =\t%" PRIx8 "\t(Xor error)\n", ioat_dma_chanerrmsk_int_xorqerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desccnterr =\t%" PRIx8 "\t(Descriptor Count error)\n", ioat_dma_chanerrmsk_int_desccnterr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chanerrsev_int_t
 * Description: Implicit type of Internal DMA Channel Error Severity Registers. register
 * Fields:
 *   dmatranserr	(size 1, offset 0, init 0):	RWCS	DMA Transfer Source address error
 *   dmaxfererr	(size 1, offset 1, init 0):	RWCS	DMA Transfer Destination address error
 *   nxtdescerr	(size 1, offset 2, init 0):	RWCS	Next Descriptor Address error
 *   descerr	(size 1, offset 3, init 0):	RWCS	Descriptor error
 *   chanaddr	(size 1, offset 4, init 0):	RWCS	Channel address value error
 *   chancmderr	(size 1, offset 5, init 0):	RWCS	Channel command error
 *   cdataerr	(size 1, offset 6, init 0):	RWCS	Data parity error
 *   dmadataerr	(size 1, offset 7, init 0):	RWCS	DMA Data Parity error
 *   rddataerr	(size 1, offset 8, init 0):	RWCS	Read Data error
 *   wrdataerr	(size 1, offset 9, init 0):	RWCS	Write data error
 *   descctrlerr	(size 1, offset 10, init 0):	RWCS	Description control  error
 *   desclenerr	(size 1, offset 11, init 0):	RWCS	Description length error
 *   cmpaddrerr	(size 1, offset 12, init 0):	RWCS	Completion Address error
 *   intcfgerr	(size 1, offset 13, init 0):	RWCS	Interrupt confiuguratio error
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   unaffilerr	(size 1, offset 15, init 0):	RO	Unaffiliated Error
 *   crc_err	(size 1, offset 16, init 0):	RWCS	CRC test failed
 *   xorqerr	(size 1, offset 17, init 0):	RWCS	Xor error
 *   desccnterr	(size 1, offset 18, init 0):	RWCS	Descriptor Count error
 *   _anon19	(size 13, offset 19, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_chanerrsev_int_t;
#define ioat_dma_chanerrsev_int_default 0x0
static inline uint8_t ioat_dma_chanerrsev_int_dmatranserr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_dmatranserr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_dmatranserr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_dmatranserr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffe) | (0x1 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_chanerrsev_int_dmaxfererr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_dmaxfererr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_dmaxfererr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_dmaxfererr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffd) | (0x2 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_chanerrsev_int_nxtdescerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_nxtdescerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_nxtdescerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_nxtdescerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffb) | (0x4 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_chanerrsev_int_descerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_descerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_descerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_descerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff7) | (0x8 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_chanerrsev_int_chanaddr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_chanaddr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_chanaddr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_chanaddr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffef) | (0x10 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_chanerrsev_int_chancmderr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_chancmderr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x20) >> 5));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_chancmderr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_chancmderr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffdf) | (0x20 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 5)));
}

static inline uint8_t ioat_dma_chanerrsev_int_cdataerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_cdataerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x40) >> 6));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_cdataerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_cdataerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffbf) | (0x40 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 6)));
}

static inline uint8_t ioat_dma_chanerrsev_int_dmadataerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_dmadataerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x80) >> 7));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_dmadataerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_dmadataerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff7f) | (0x80 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 7)));
}

static inline uint8_t ioat_dma_chanerrsev_int_rddataerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_rddataerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_rddataerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_rddataerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffeff) | (0x100 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_chanerrsev_int_wrdataerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_wrdataerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x200) >> 9));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_wrdataerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_wrdataerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffdff) | (0x200 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 9)));
}

static inline uint8_t ioat_dma_chanerrsev_int_descctrlerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_descctrlerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_descctrlerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_descctrlerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffbff) | (0x400 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 10)));
}

static inline uint8_t ioat_dma_chanerrsev_int_desclenerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_desclenerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x800) >> 11));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_desclenerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_desclenerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffff7ff) | (0x800 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 11)));
}

static inline uint8_t ioat_dma_chanerrsev_int_cmpaddrerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_cmpaddrerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x1000) >> 12));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_cmpaddrerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_cmpaddrerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffefff) | (0x1000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 12)));
}

static inline uint8_t ioat_dma_chanerrsev_int_intcfgerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_intcfgerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x2000) >> 13));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_intcfgerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_intcfgerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffdfff) | (0x2000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 13)));
}

static inline uint8_t ioat_dma_chanerrsev_int_unaffilerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_unaffilerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_unaffilerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_unaffilerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff7fff) | (0x8000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 15)));
}

static inline uint8_t ioat_dma_chanerrsev_int_crc_err_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_crc_err_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x10000) >> 16));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_crc_err_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_crc_err_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffeffff) | (0x10000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 16)));
}

static inline uint8_t ioat_dma_chanerrsev_int_xorqerr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_xorqerr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x20000) >> 17));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_xorqerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_xorqerr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffdffff) | (0x20000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 17)));
}

static inline uint8_t ioat_dma_chanerrsev_int_desccnterr_extract(ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_desccnterr_extract(ioat_dma_chanerrsev_int_t _regval)
{
    return((uint8_t )((_regval & 0x40000) >> 18));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_desccnterr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_desccnterr_insert(ioat_dma_chanerrsev_int_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffbffff) | (0x40000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 18)));
}

static inline int ioat_dma_chanerrsev_int_prtval(char *_s, size_t _size, ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chanerrsev_int_prtval(char *_s, size_t _size, ioat_dma_chanerrsev_int_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmatranserr =\t%" PRIx8 "\t(DMA Transfer Source address error)\n", ioat_dma_chanerrsev_int_dmatranserr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmaxfererr =\t%" PRIx8 "\t(DMA Transfer Destination address error)\n", ioat_dma_chanerrsev_int_dmaxfererr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " nxtdescerr =\t%" PRIx8 "\t(Next Descriptor Address error)\n", ioat_dma_chanerrsev_int_nxtdescerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descerr =\t%" PRIx8 "\t(Descriptor error)\n", ioat_dma_chanerrsev_int_descerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanaddr =\t%" PRIx8 "\t(Channel address value error)\n", ioat_dma_chanerrsev_int_chanaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chancmderr =\t%" PRIx8 "\t(Channel command error)\n", ioat_dma_chanerrsev_int_chancmderr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cdataerr =\t%" PRIx8 "\t(Data parity error)\n", ioat_dma_chanerrsev_int_cdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmadataerr =\t%" PRIx8 "\t(DMA Data Parity error)\n", ioat_dma_chanerrsev_int_dmadataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rddataerr =\t%" PRIx8 "\t(Read Data error)\n", ioat_dma_chanerrsev_int_rddataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " wrdataerr =\t%" PRIx8 "\t(Write data error)\n", ioat_dma_chanerrsev_int_wrdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descctrlerr =\t%" PRIx8 "\t(Description control  error)\n", ioat_dma_chanerrsev_int_descctrlerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desclenerr =\t%" PRIx8 "\t(Description length error)\n", ioat_dma_chanerrsev_int_desclenerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpaddrerr =\t%" PRIx8 "\t(Completion Address error)\n", ioat_dma_chanerrsev_int_cmpaddrerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intcfgerr =\t%" PRIx8 "\t(Interrupt confiuguratio error)\n", ioat_dma_chanerrsev_int_intcfgerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unaffilerr =\t%" PRIx8 "\t(Unaffiliated Error)\n", ioat_dma_chanerrsev_int_unaffilerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc_err =\t%" PRIx8 "\t(CRC test failed)\n", ioat_dma_chanerrsev_int_crc_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xorqerr =\t%" PRIx8 "\t(Xor error)\n", ioat_dma_chanerrsev_int_xorqerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desccnterr =\t%" PRIx8 "\t(Descriptor Count error)\n", ioat_dma_chanerrsev_int_desccnterr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chanerrptr_t
 * Description: Implicit type of DMA Channel Error Pointer. register
 * Fields:
 *   chan_err_ptr	(size 5, offset 0, init 0):	RO	DMA Channel error pointer
 *   _anon5	(size 3, offset 5, init 0):	RSVD	_
 */
typedef uint8_t ioat_dma_chanerrptr_t;
#define ioat_dma_chanerrptr_default 0x0
static inline uint8_t ioat_dma_chanerrptr_chan_err_ptr_extract(ioat_dma_chanerrptr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrptr_chan_err_ptr_extract(ioat_dma_chanerrptr_t _regval)
{
    return((uint8_t )((_regval & 0x1f) >> 0));
}

static inline ioat_dma_chanerrptr_t ioat_dma_chanerrptr_chan_err_ptr_insert(ioat_dma_chanerrptr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrptr_t ioat_dma_chanerrptr_chan_err_ptr_insert(ioat_dma_chanerrptr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xe0) | (0x1f & (((ioat_dma_chanerrptr_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_chanerrptr_prtval(char *_s, size_t _size, ioat_dma_chanerrptr_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chanerrptr_prtval(char *_s, size_t _size, ioat_dma_chanerrptr_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chan_err_ptr =\t%" PRIx8 "\t(DMA Channel error pointer)\n", ioat_dma_chanerrptr_chan_err_ptr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chancnt_t
 * Description: Implicit type of Channel Count register
 * Fields:
 *   num	(size 5, offset 0, init 0):	RO	Number of channels present
 *   _anon5	(size 3, offset 5, init 0):	RSVD	_
 */
typedef uint8_t ioat_dma_chancnt_t;
#define ioat_dma_chancnt_default 0x0
static inline uint8_t ioat_dma_chancnt_num_extract(ioat_dma_chancnt_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancnt_num_extract(ioat_dma_chancnt_t _regval)
{
    return((uint8_t )((_regval & 0x1f) >> 0));
}

static inline ioat_dma_chancnt_t ioat_dma_chancnt_num_insert(ioat_dma_chancnt_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chancnt_t ioat_dma_chancnt_num_insert(ioat_dma_chancnt_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xe0) | (0x1f & (((ioat_dma_chancnt_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_chancnt_prtval(char *_s, size_t _size, ioat_dma_chancnt_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chancnt_prtval(char *_s, size_t _size, ioat_dma_chancnt_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " num =\t%" PRIx8 "\t(Number of channels present)\n", ioat_dma_chancnt_num_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_xfercap_t
 * Description: Implicit type of Transfer Capacity register
 * Fields:
 *   max	(size 5, offset 0, init 0):	RO	Maximum transfer capability
 *   _anon5	(size 3, offset 5, init 0):	RSVD	_
 */
typedef uint8_t ioat_dma_xfercap_t;
#define ioat_dma_xfercap_default 0x0
static inline uint8_t ioat_dma_xfercap_max_extract(ioat_dma_xfercap_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_xfercap_max_extract(ioat_dma_xfercap_t _regval)
{
    return((uint8_t )((_regval & 0x1f) >> 0));
}

static inline ioat_dma_xfercap_t ioat_dma_xfercap_max_insert(ioat_dma_xfercap_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_xfercap_t ioat_dma_xfercap_max_insert(ioat_dma_xfercap_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xe0) | (0x1f & (((ioat_dma_xfercap_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_xfercap_prtval(char *_s, size_t _size, ioat_dma_xfercap_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_xfercap_prtval(char *_s, size_t _size, ioat_dma_xfercap_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " max =\t%" PRIx8 "\t(Maximum transfer capability)\n", ioat_dma_xfercap_max_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_genctrl_t
 * Description: Implicit type of DMA General Control register
 * Fields:
 *   dbgen	(size 1, offset 0, init 0):	RW	DB Generation
 *   _anon1	(size 7, offset 1, init 0):	RSVD	_
 */
typedef uint8_t ioat_dma_genctrl_t;
#define ioat_dma_genctrl_default 0x0
static inline uint8_t ioat_dma_genctrl_dbgen_extract(ioat_dma_genctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_genctrl_dbgen_extract(ioat_dma_genctrl_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_genctrl_t ioat_dma_genctrl_dbgen_insert(ioat_dma_genctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_genctrl_t ioat_dma_genctrl_dbgen_insert(ioat_dma_genctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfe) | (0x1 & (((ioat_dma_genctrl_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_genctrl_prtval(char *_s, size_t _size, ioat_dma_genctrl_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_genctrl_prtval(char *_s, size_t _size, ioat_dma_genctrl_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dbgen =\t%" PRIx8 "\t(DB Generation)\n", ioat_dma_genctrl_dbgen_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_intrctrl_t
 * Description: Implicit type of Interrupt Control Register register
 * Fields:
 *   intp_en	(size 1, offset 0, init 0):	RW	Master interrupt enable bit. (not used in MSI-X model)
 *   intp_sts	(size 1, offset 1, init 0):	RO	Interrupt status. (not used in MSI-X model)
 *   intp	(size 1, offset 2, init 0):	RO	Interrupt. Set when status bit in attention is set
 *   msix_vec	(size 1, offset 3, init 0):	RW	MSI-X Vector Control. (Ignored by CB)
 *   _anon4	(size 4, offset 4, init 0):	RSVD	_
 */
typedef uint8_t ioat_dma_intrctrl_t;
#define ioat_dma_intrctrl_default 0x0
static inline uint8_t ioat_dma_intrctrl_intp_en_extract(ioat_dma_intrctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intrctrl_intp_en_extract(ioat_dma_intrctrl_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_intp_en_insert(ioat_dma_intrctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_intp_en_insert(ioat_dma_intrctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfe) | (0x1 & (((ioat_dma_intrctrl_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_intrctrl_intp_sts_extract(ioat_dma_intrctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intrctrl_intp_sts_extract(ioat_dma_intrctrl_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_intp_sts_insert(ioat_dma_intrctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_intp_sts_insert(ioat_dma_intrctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfd) | (0x2 & (((ioat_dma_intrctrl_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_intrctrl_intp_extract(ioat_dma_intrctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intrctrl_intp_extract(ioat_dma_intrctrl_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_intp_insert(ioat_dma_intrctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_intp_insert(ioat_dma_intrctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfb) | (0x4 & (((ioat_dma_intrctrl_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_intrctrl_msix_vec_extract(ioat_dma_intrctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intrctrl_msix_vec_extract(ioat_dma_intrctrl_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_msix_vec_insert(ioat_dma_intrctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_msix_vec_insert(ioat_dma_intrctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf7) | (0x8 & (((ioat_dma_intrctrl_t )(_fieldval)) << 3)));
}

static inline int ioat_dma_intrctrl_prtval(char *_s, size_t _size, ioat_dma_intrctrl_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_intrctrl_prtval(char *_s, size_t _size, ioat_dma_intrctrl_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intp_en =\t%" PRIx8 "\t(Master interrupt enable bit. (not used in MSI-X model))\n", ioat_dma_intrctrl_intp_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intp_sts =\t%" PRIx8 "\t(Interrupt status. (not used in MSI-X model))\n", ioat_dma_intrctrl_intp_sts_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intp =\t%" PRIx8 "\t(Interrupt. Set when status bit in attention is set)\n", ioat_dma_intrctrl_intp_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " msix_vec =\t%" PRIx8 "\t(MSI-X Vector Control. (Ignored by CB))\n", ioat_dma_intrctrl_msix_vec_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_attnstatus_t
 * Description: Implicit type of Attention Status Register register
 * Fields:
 *   chanattn	(size 1, offset 0, init 0):	RO	Channel Attention. Represents the interrupt status
 *   _anon1	(size 31, offset 1, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_attnstatus_t;
#define ioat_dma_attnstatus_default 0x0
static inline uint8_t ioat_dma_attnstatus_chanattn_extract(ioat_dma_attnstatus_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_attnstatus_chanattn_extract(ioat_dma_attnstatus_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_attnstatus_t ioat_dma_attnstatus_chanattn_insert(ioat_dma_attnstatus_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_attnstatus_t ioat_dma_attnstatus_chanattn_insert(ioat_dma_attnstatus_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffe) | (0x1 & (((ioat_dma_attnstatus_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_attnstatus_prtval(char *_s, size_t _size, ioat_dma_attnstatus_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_attnstatus_prtval(char *_s, size_t _size, ioat_dma_attnstatus_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanattn =\t%" PRIx8 "\t(Channel Attention. Represents the interrupt status)\n", ioat_dma_attnstatus_chanattn_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_cbver_t
 * Description: Implicit type of Crystal Beach Version Number register
 * Fields:
 *   minor	(size 4, offset 0, init 0):	RO	Minor Version Number
 *   major	(size 4, offset 4, init 0):	RO	Major Version Number
 */
typedef uint8_t ioat_dma_cbver_t;
#define ioat_dma_cbver_default 0x0
static inline uint8_t ioat_dma_cbver_minor_extract(ioat_dma_cbver_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cbver_minor_extract(ioat_dma_cbver_t _regval)
{
    return((uint8_t )((_regval & 0xf) >> 0));
}

static inline ioat_dma_cbver_t ioat_dma_cbver_minor_insert(ioat_dma_cbver_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_cbver_t ioat_dma_cbver_minor_insert(ioat_dma_cbver_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf0) | (0xf & (((ioat_dma_cbver_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_cbver_major_extract(ioat_dma_cbver_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cbver_major_extract(ioat_dma_cbver_t _regval)
{
    return((uint8_t )((_regval & 0xf0) >> 4));
}

static inline ioat_dma_cbver_t ioat_dma_cbver_major_insert(ioat_dma_cbver_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_cbver_t ioat_dma_cbver_major_insert(ioat_dma_cbver_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf) | (0xf0 & (((ioat_dma_cbver_t )(_fieldval)) << 4)));
}

static inline int ioat_dma_cbver_prtval(char *_s, size_t _size, ioat_dma_cbver_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_cbver_prtval(char *_s, size_t _size, ioat_dma_cbver_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " minor =\t%" PRIx8 "\t(Minor Version Number)\n", ioat_dma_cbver_minor_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " major =\t%" PRIx8 "\t(Major Version Number)\n", ioat_dma_cbver_major_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_intrdelay_t
 * Description: Implicit type of Interrupt Delay Register register
 * Fields:
 *   delay_us	(size 14, offset 0, init 0):	RW	Interrupt delay time in micro seconds
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   coalesc	(size 1, offset 15, init 0):	RO	Interrupt Coalescing is supported
 */
typedef uint16_t ioat_dma_intrdelay_t;
#define ioat_dma_intrdelay_default 0x0
static inline uint16_t ioat_dma_intrdelay_delay_us_extract(ioat_dma_intrdelay_t _regval) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_intrdelay_delay_us_extract(ioat_dma_intrdelay_t _regval)
{
    return((uint16_t )((_regval & 0x3fff) >> 0));
}

static inline ioat_dma_intrdelay_t ioat_dma_intrdelay_delay_us_insert(ioat_dma_intrdelay_t _regval, uint16_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_intrdelay_t ioat_dma_intrdelay_delay_us_insert(ioat_dma_intrdelay_t _regval, uint16_t _fieldval)
{
    return((_regval & 0xc000) | (0x3fff & (((ioat_dma_intrdelay_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_intrdelay_coalesc_extract(ioat_dma_intrdelay_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intrdelay_coalesc_extract(ioat_dma_intrdelay_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_intrdelay_t ioat_dma_intrdelay_coalesc_insert(ioat_dma_intrdelay_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_intrdelay_t ioat_dma_intrdelay_coalesc_insert(ioat_dma_intrdelay_t _regval, uint8_t _fieldval)
{
    return((_regval & 0x7fff) | (0x8000 & (((ioat_dma_intrdelay_t )(_fieldval)) << 15)));
}

static inline int ioat_dma_intrdelay_prtval(char *_s, size_t _size, ioat_dma_intrdelay_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_intrdelay_prtval(char *_s, size_t _size, ioat_dma_intrdelay_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " delay_us =\t%" PRIx16 "\t(Interrupt delay time in micro seconds)\n", ioat_dma_intrdelay_delay_us_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " coalesc =\t%" PRIx8 "\t(Interrupt Coalescing is supported)\n", ioat_dma_intrdelay_coalesc_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_cs_status_t
 * Description: Implicit type of Chipset Status Register register
 * Fields:
 *   _anon0	(size 1, offset 0, init 0):	RSVD	_
 *   mmio_restrict	(size 1, offset 1, init 0):	RO	MMIO Restriction
 *   mem_bypass	(size 1, offset 2, init 0):	RO	Memory bypass
 *   addr_remap	(size 1, offset 3, init 0):	RO	Address Remapping: reflects the TE bit of VT-d
 *   _anon4	(size 12, offset 4, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_cs_status_t;
#define ioat_dma_cs_status_default 0x0
static inline uint8_t ioat_dma_cs_status_mmio_restrict_extract(ioat_dma_cs_status_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cs_status_mmio_restrict_extract(ioat_dma_cs_status_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_cs_status_t ioat_dma_cs_status_mmio_restrict_insert(ioat_dma_cs_status_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_cs_status_t ioat_dma_cs_status_mmio_restrict_insert(ioat_dma_cs_status_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffd) | (0x2 & (((ioat_dma_cs_status_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_cs_status_mem_bypass_extract(ioat_dma_cs_status_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cs_status_mem_bypass_extract(ioat_dma_cs_status_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_cs_status_t ioat_dma_cs_status_mem_bypass_insert(ioat_dma_cs_status_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_cs_status_t ioat_dma_cs_status_mem_bypass_insert(ioat_dma_cs_status_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffb) | (0x4 & (((ioat_dma_cs_status_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_cs_status_addr_remap_extract(ioat_dma_cs_status_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cs_status_addr_remap_extract(ioat_dma_cs_status_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_cs_status_t ioat_dma_cs_status_addr_remap_insert(ioat_dma_cs_status_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_cs_status_t ioat_dma_cs_status_addr_remap_insert(ioat_dma_cs_status_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff7) | (0x8 & (((ioat_dma_cs_status_t )(_fieldval)) << 3)));
}

static inline int ioat_dma_cs_status_prtval(char *_s, size_t _size, ioat_dma_cs_status_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_cs_status_prtval(char *_s, size_t _size, ioat_dma_cs_status_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mmio_restrict =\t%" PRIx8 "\t(MMIO Restriction)\n", ioat_dma_cs_status_mmio_restrict_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mem_bypass =\t%" PRIx8 "\t(Memory bypass)\n", ioat_dma_cs_status_mem_bypass_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " addr_remap =\t%" PRIx8 "\t(Address Remapping: reflects the TE bit of VT-d)\n", ioat_dma_cs_status_addr_remap_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dmacapability_t
 * Description: Implicit type of DMA Capability Register register
 * Fields:
 *   pagebreak	(size 1, offset 0, init 0):	RO	Transfers crossing physical pages supported
 *   crc	(size 1, offset 1, init 0):	RO	CRC generation supported
 *   markerskip	(size 1, offset 2, init 0):	RO	Marker skipping is supported
 *   _anon3	(size 1, offset 3, init 0):	RSVD	_
 *   dca	(size 1, offset 4, init 0):	RW	Direct Cache Access is supported
 *   move_crc	(size 1, offset 5, init 0):	RO	Move and CRC op codes are supported
 *   block_fill	(size 1, offset 6, init 0):	RO	Block fill OP code is supported
 *   ext_apic_id	(size 1, offset 7, init 0):	RO	32bit APIC IDs are supported (otherwise 8bit APIC)
 *   xor	(size 1, offset 8, init 0):	RO	Only XOR for RAID 5 / 6 supported
 *   pq	(size 1, offset 9, init 0):	RO	Parity and Quotient Opcodes for RAID 5 / 6
 *   _anon10	(size 22, offset 10, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_dmacapability_t;
#define ioat_dma_dmacapability_default 0x0
static inline uint8_t ioat_dma_dmacapability_pagebreak_extract(ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_pagebreak_extract(ioat_dma_dmacapability_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_pagebreak_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_pagebreak_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffe) | (0x1 & (((ioat_dma_dmacapability_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_dmacapability_crc_extract(ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_crc_extract(ioat_dma_dmacapability_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_crc_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_crc_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffd) | (0x2 & (((ioat_dma_dmacapability_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_dmacapability_markerskip_extract(ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_markerskip_extract(ioat_dma_dmacapability_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_markerskip_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_markerskip_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffb) | (0x4 & (((ioat_dma_dmacapability_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_dmacapability_dca_extract(ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_dca_extract(ioat_dma_dmacapability_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_dca_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_dca_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffef) | (0x10 & (((ioat_dma_dmacapability_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_dmacapability_move_crc_extract(ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_move_crc_extract(ioat_dma_dmacapability_t _regval)
{
    return((uint8_t )((_regval & 0x20) >> 5));
}

static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_move_crc_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_move_crc_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffdf) | (0x20 & (((ioat_dma_dmacapability_t )(_fieldval)) << 5)));
}

static inline uint8_t ioat_dma_dmacapability_block_fill_extract(ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_block_fill_extract(ioat_dma_dmacapability_t _regval)
{
    return((uint8_t )((_regval & 0x40) >> 6));
}

static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_block_fill_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_block_fill_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffbf) | (0x40 & (((ioat_dma_dmacapability_t )(_fieldval)) << 6)));
}

static inline uint8_t ioat_dma_dmacapability_ext_apic_id_extract(ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_ext_apic_id_extract(ioat_dma_dmacapability_t _regval)
{
    return((uint8_t )((_regval & 0x80) >> 7));
}

static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_ext_apic_id_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_ext_apic_id_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff7f) | (0x80 & (((ioat_dma_dmacapability_t )(_fieldval)) << 7)));
}

static inline uint8_t ioat_dma_dmacapability_xor_extract(ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_xor_extract(ioat_dma_dmacapability_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_xor_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_xor_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffeff) | (0x100 & (((ioat_dma_dmacapability_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_dmacapability_pq_extract(ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_pq_extract(ioat_dma_dmacapability_t _regval)
{
    return((uint8_t )((_regval & 0x200) >> 9));
}

static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_pq_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_pq_insert(ioat_dma_dmacapability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffdff) | (0x200 & (((ioat_dma_dmacapability_t )(_fieldval)) << 9)));
}

static inline int ioat_dma_dmacapability_prtval(char *_s, size_t _size, ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dmacapability_prtval(char *_s, size_t _size, ioat_dma_dmacapability_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pagebreak =\t%" PRIx8 "\t(Transfers crossing physical pages supported)\n", ioat_dma_dmacapability_pagebreak_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc =\t%" PRIx8 "\t(CRC generation supported)\n", ioat_dma_dmacapability_crc_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " markerskip =\t%" PRIx8 "\t(Marker skipping is supported)\n", ioat_dma_dmacapability_markerskip_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dca =\t%" PRIx8 "\t(Direct Cache Access is supported)\n", ioat_dma_dmacapability_dca_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " move_crc =\t%" PRIx8 "\t(Move and CRC op codes are supported)\n", ioat_dma_dmacapability_move_crc_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " block_fill =\t%" PRIx8 "\t(Block fill OP code is supported)\n", ioat_dma_dmacapability_block_fill_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ext_apic_id =\t%" PRIx8 "\t(32bit APIC IDs are supported (otherwise 8bit APIC))\n", ioat_dma_dmacapability_ext_apic_id_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xor =\t%" PRIx8 "\t(Only XOR for RAID 5 / 6 supported)\n", ioat_dma_dmacapability_xor_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pq =\t%" PRIx8 "\t(Parity and Quotient Opcodes for RAID 5 / 6)\n", ioat_dma_dmacapability_pq_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chanctrl_t
 * Description: Implicit type of Channel Control Register register
 * Fields:
 *   intp_dis	(size 1, offset 0, init 0):	RWC	Interrupt disable
 *   _anon1	(size 1, offset 1, init 0):	RSVD	_
 *   err_cmp_en	(size 1, offset 2, init 0):	RW	Error Completion Enabled
 *   err_abort	(size 1, offset 3, init 0):	RW	Any Error Abort Enbled
 *   err_int_en	(size 1, offset 4, init 0):	RW	Error Interrupt Enabled
 *   snoop_ctrl	(size 1, offset 5, init 0):	RW	Descriptor address snoop control
 *   _anon6	(size 2, offset 6, init 0):	RSVD	_
 *   in_use	(size 1, offset 8, init 0):	RW	Channel is in use
 *   dca_en	(size 1, offset 9, init 0):	RW	Direct Cache access enabled
 *   _anon10	(size 6, offset 10, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_chanctrl_t;
#define ioat_dma_chanctrl_default 0x0
static inline uint8_t ioat_dma_chanctrl_intp_dis_extract(ioat_dma_chanctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_intp_dis_extract(ioat_dma_chanctrl_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_intp_dis_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_intp_dis_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((ioat_dma_chanctrl_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_chanctrl_err_cmp_en_extract(ioat_dma_chanctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_err_cmp_en_extract(ioat_dma_chanctrl_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_err_cmp_en_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_err_cmp_en_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffb) | (0x4 & (((ioat_dma_chanctrl_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_chanctrl_err_abort_extract(ioat_dma_chanctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_err_abort_extract(ioat_dma_chanctrl_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_err_abort_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_err_abort_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff7) | (0x8 & (((ioat_dma_chanctrl_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_chanctrl_err_int_en_extract(ioat_dma_chanctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_err_int_en_extract(ioat_dma_chanctrl_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_err_int_en_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_err_int_en_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffef) | (0x10 & (((ioat_dma_chanctrl_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_chanctrl_snoop_ctrl_extract(ioat_dma_chanctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_snoop_ctrl_extract(ioat_dma_chanctrl_t _regval)
{
    return((uint8_t )((_regval & 0x20) >> 5));
}

static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_snoop_ctrl_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_snoop_ctrl_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffdf) | (0x20 & (((ioat_dma_chanctrl_t )(_fieldval)) << 5)));
}

static inline uint8_t ioat_dma_chanctrl_in_use_extract(ioat_dma_chanctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_in_use_extract(ioat_dma_chanctrl_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_in_use_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_in_use_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfeff) | (0x100 & (((ioat_dma_chanctrl_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_chanctrl_dca_en_extract(ioat_dma_chanctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_dca_en_extract(ioat_dma_chanctrl_t _regval)
{
    return((uint8_t )((_regval & 0x200) >> 9));
}

static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_dca_en_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_dca_en_insert(ioat_dma_chanctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfdff) | (0x200 & (((ioat_dma_chanctrl_t )(_fieldval)) << 9)));
}

static inline int ioat_dma_chanctrl_prtval(char *_s, size_t _size, ioat_dma_chanctrl_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chanctrl_prtval(char *_s, size_t _size, ioat_dma_chanctrl_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intp_dis =\t%" PRIx8 "\t(Interrupt disable)\n", ioat_dma_chanctrl_intp_dis_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " err_cmp_en =\t%" PRIx8 "\t(Error Completion Enabled)\n", ioat_dma_chanctrl_err_cmp_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " err_abort =\t%" PRIx8 "\t(Any Error Abort Enbled)\n", ioat_dma_chanctrl_err_abort_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " err_int_en =\t%" PRIx8 "\t(Error Interrupt Enabled)\n", ioat_dma_chanctrl_err_int_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " snoop_ctrl =\t%" PRIx8 "\t(Descriptor address snoop control)\n", ioat_dma_chanctrl_snoop_ctrl_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " in_use =\t%" PRIx8 "\t(Channel is in use)\n", ioat_dma_chanctrl_in_use_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dca_en =\t%" PRIx8 "\t(Direct Cache access enabled)\n", ioat_dma_chanctrl_dca_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dma_comp_t
 * Description: Implicit type of DMA Compatibility Register register
 * Fields:
 *   v1	(size 1, offset 0, init 0):	RO	NOT compatible with CB Version 1
 *   v2	(size 1, offset 1, init 0):	RO	Compatible with CB Version 2
 *   v3	(size 1, offset 2, init 0):	RO	Compatible with CB Version 3
 *   _anon3	(size 13, offset 3, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_dma_comp_t;
#define ioat_dma_dma_comp_default 0x0
static inline uint8_t ioat_dma_dma_comp_v1_extract(ioat_dma_dma_comp_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dma_comp_v1_extract(ioat_dma_dma_comp_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_dma_comp_t ioat_dma_dma_comp_v1_insert(ioat_dma_dma_comp_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dma_comp_t ioat_dma_dma_comp_v1_insert(ioat_dma_dma_comp_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((ioat_dma_dma_comp_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_dma_comp_v2_extract(ioat_dma_dma_comp_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dma_comp_v2_extract(ioat_dma_dma_comp_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_dma_comp_t ioat_dma_dma_comp_v2_insert(ioat_dma_dma_comp_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dma_comp_t ioat_dma_dma_comp_v2_insert(ioat_dma_dma_comp_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffd) | (0x2 & (((ioat_dma_dma_comp_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_dma_comp_v3_extract(ioat_dma_dma_comp_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dma_comp_v3_extract(ioat_dma_dma_comp_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_dma_comp_t ioat_dma_dma_comp_v3_insert(ioat_dma_dma_comp_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dma_comp_t ioat_dma_dma_comp_v3_insert(ioat_dma_dma_comp_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffb) | (0x4 & (((ioat_dma_dma_comp_t )(_fieldval)) << 2)));
}

static inline int ioat_dma_dma_comp_prtval(char *_s, size_t _size, ioat_dma_dma_comp_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dma_comp_prtval(char *_s, size_t _size, ioat_dma_dma_comp_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " v1 =\t%" PRIx8 "\t(NOT compatible with CB Version 1)\n", ioat_dma_dma_comp_v1_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " v2 =\t%" PRIx8 "\t(Compatible with CB Version 2)\n", ioat_dma_dma_comp_v2_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " v3 =\t%" PRIx8 "\t(Compatible with CB Version 3)\n", ioat_dma_dma_comp_v3_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chancmd_t
 * Description: Implicit type of DMA Channel Command Register. register
 * Fields:
 *   start	(size 1, offset 0, init 0):	RW	Start
 *   append	(size 1, offset 1, init 0):	RW	Append
 *   susp	(size 1, offset 2, init 0):	RW	Suspend the DMA channel
 *   abort	(size 1, offset 3, init 0):	RW	Abort
 *   resume	(size 1, offset 4, init 0):	RW	resume
 *   reset	(size 1, offset 5, init 0):	RW	Reset DMA channel
 *   _anon6	(size 2, offset 6, init 0):	RSVD	_
 */
typedef uint8_t ioat_dma_chancmd_t;
#define ioat_dma_chancmd_default 0x0
static inline uint8_t ioat_dma_chancmd_start_extract(ioat_dma_chancmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_start_extract(ioat_dma_chancmd_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_chancmd_t ioat_dma_chancmd_start_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chancmd_t ioat_dma_chancmd_start_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfe) | (0x1 & (((ioat_dma_chancmd_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_chancmd_append_extract(ioat_dma_chancmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_append_extract(ioat_dma_chancmd_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_chancmd_t ioat_dma_chancmd_append_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chancmd_t ioat_dma_chancmd_append_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfd) | (0x2 & (((ioat_dma_chancmd_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_chancmd_susp_extract(ioat_dma_chancmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_susp_extract(ioat_dma_chancmd_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_chancmd_t ioat_dma_chancmd_susp_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chancmd_t ioat_dma_chancmd_susp_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfb) | (0x4 & (((ioat_dma_chancmd_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_chancmd_abort_extract(ioat_dma_chancmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_abort_extract(ioat_dma_chancmd_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_chancmd_t ioat_dma_chancmd_abort_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chancmd_t ioat_dma_chancmd_abort_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf7) | (0x8 & (((ioat_dma_chancmd_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_chancmd_resume_extract(ioat_dma_chancmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_resume_extract(ioat_dma_chancmd_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_chancmd_t ioat_dma_chancmd_resume_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chancmd_t ioat_dma_chancmd_resume_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xef) | (0x10 & (((ioat_dma_chancmd_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_chancmd_reset_extract(ioat_dma_chancmd_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_reset_extract(ioat_dma_chancmd_t _regval)
{
    return((uint8_t )((_regval & 0x20) >> 5));
}

static inline ioat_dma_chancmd_t ioat_dma_chancmd_reset_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chancmd_t ioat_dma_chancmd_reset_insert(ioat_dma_chancmd_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xdf) | (0x20 & (((ioat_dma_chancmd_t )(_fieldval)) << 5)));
}

static inline int ioat_dma_chancmd_prtval(char *_s, size_t _size, ioat_dma_chancmd_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chancmd_prtval(char *_s, size_t _size, ioat_dma_chancmd_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " start =\t%" PRIx8 "\t(Start)\n", ioat_dma_chancmd_start_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " append =\t%" PRIx8 "\t(Append)\n", ioat_dma_chancmd_append_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " susp =\t%" PRIx8 "\t(Suspend the DMA channel)\n", ioat_dma_chancmd_susp_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " abort =\t%" PRIx8 "\t(Abort)\n", ioat_dma_chancmd_abort_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " resume =\t%" PRIx8 "\t(resume)\n", ioat_dma_chancmd_resume_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " reset =\t%" PRIx8 "\t(Reset DMA channel)\n", ioat_dma_chancmd_reset_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chansts_lo_t
 * Description: Implicit type of Channel Status Lo Register. register
 * Fields:
 *   dma_trans_state	(size 3, offset 0, init 0):	RO	DMA transfer State
 *   _anon3	(size 3, offset 3, init 0):	RSVD	_
 *   cmpdscaddr	(size 26, offset 6, init 0):	RO	Uppder address of the last descriptor processed
 */
typedef uint32_t ioat_dma_chansts_lo_t;
#define ioat_dma_chansts_lo_default 0x0
static inline uint8_t ioat_dma_chansts_lo_dma_trans_state_extract(ioat_dma_chansts_lo_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chansts_lo_dma_trans_state_extract(ioat_dma_chansts_lo_t _regval)
{
    return((uint8_t )((_regval & 0x7) >> 0));
}

static inline ioat_dma_chansts_lo_t ioat_dma_chansts_lo_dma_trans_state_insert(ioat_dma_chansts_lo_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chansts_lo_t ioat_dma_chansts_lo_dma_trans_state_insert(ioat_dma_chansts_lo_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff8) | (0x7 & (((ioat_dma_chansts_lo_t )(_fieldval)) << 0)));
}

static inline uint32_t ioat_dma_chansts_lo_cmpdscaddr_extract(ioat_dma_chansts_lo_t _regval) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chansts_lo_cmpdscaddr_extract(ioat_dma_chansts_lo_t _regval)
{
    return((uint32_t )((_regval & 0xffffffc0) >> 6));
}

static inline ioat_dma_chansts_lo_t ioat_dma_chansts_lo_cmpdscaddr_insert(ioat_dma_chansts_lo_t _regval, uint32_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chansts_lo_t ioat_dma_chansts_lo_cmpdscaddr_insert(ioat_dma_chansts_lo_t _regval, uint32_t _fieldval)
{
    return((_regval & 0x3f) | (0xffffffc0 & (((ioat_dma_chansts_lo_t )(_fieldval)) << 6)));
}

static inline int ioat_dma_chansts_lo_prtval(char *_s, size_t _size, ioat_dma_chansts_lo_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chansts_lo_prtval(char *_s, size_t _size, ioat_dma_chansts_lo_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dma_trans_state =\t%" PRIx8 "\t(DMA transfer State)\n", ioat_dma_chansts_lo_dma_trans_state_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpdscaddr =\t%" PRIx32 "\t(Uppder address of the last descriptor processed)\n", ioat_dma_chansts_lo_cmpdscaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chainaddr_lo_t
 * Description: Implicit type of Descriptor Chain Address Lo Register. register
 * Fields:
 *   _anon0	(size 6, offset 0, init 0):	MBZ	_
 *   descaddr_lo	(size 26, offset 6, init 0):	RW	Address of the first descriptor
 */
typedef uint32_t ioat_dma_chainaddr_lo_t;
#define ioat_dma_chainaddr_lo_default 0x0
static inline uint32_t ioat_dma_chainaddr_lo_descaddr_lo_extract(ioat_dma_chainaddr_lo_t _regval) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chainaddr_lo_descaddr_lo_extract(ioat_dma_chainaddr_lo_t _regval)
{
    return((uint32_t )((_regval & 0xffffffc0) >> 6));
}

static inline ioat_dma_chainaddr_lo_t ioat_dma_chainaddr_lo_descaddr_lo_insert(ioat_dma_chainaddr_lo_t _regval, uint32_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chainaddr_lo_t ioat_dma_chainaddr_lo_descaddr_lo_insert(ioat_dma_chainaddr_lo_t _regval, uint32_t _fieldval)
{
    return((_regval & 0x3f) | (0xffffffc0 & (((ioat_dma_chainaddr_lo_t )(_fieldval)) << 6)));
}

static inline int ioat_dma_chainaddr_lo_prtval(char *_s, size_t _size, ioat_dma_chainaddr_lo_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chainaddr_lo_prtval(char *_s, size_t _size, ioat_dma_chainaddr_lo_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descaddr_lo =\t%" PRIx32 "\t(Address of the first descriptor)\n", ioat_dma_chainaddr_lo_descaddr_lo_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chanerr_t
 * Description: Implicit type of Channel Error Register register
 * Fields:
 *   dmatranserr	(size 1, offset 0, init 0):	RWCS	DMA Transfer Source address error
 *   dmaxfererr	(size 1, offset 1, init 0):	RWCS	DMA Transfer Destination address error
 *   nxtdescerr	(size 1, offset 2, init 0):	RWCS	Next Descriptor Address error
 *   descerr	(size 1, offset 3, init 0):	RWCS	Descriptor error
 *   chanaddr	(size 1, offset 4, init 0):	RWCS	Channel address value error
 *   chancmderr	(size 1, offset 5, init 0):	RWCS	Channel command error
 *   cdataerr	(size 1, offset 6, init 0):	RWCS	Data parity error
 *   dmadataerr	(size 1, offset 7, init 0):	RWCS	DMA Data Parity error
 *   rddataerr	(size 1, offset 8, init 0):	RWCS	Read Data error
 *   wrdataerr	(size 1, offset 9, init 0):	RWCS	Write data error
 *   descctrlerr	(size 1, offset 10, init 0):	RWCS	Description control  error
 *   desclenerr	(size 1, offset 11, init 0):	RWCS	Description length error
 *   cmpaddrerr	(size 1, offset 12, init 0):	RWCS	Completion Address error
 *   intcfgerr	(size 1, offset 13, init 0):	RWCS	Interrupt confiuguratio error
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   unaffilerr	(size 1, offset 15, init 0):	RO	Unaffiliated Error
 *   crc_err	(size 1, offset 16, init 0):	RWCS	CRC test failed
 *   xorqerr	(size 1, offset 17, init 0):	RWCS	Xor error
 *   desccnterr	(size 1, offset 18, init 0):	RWCS	Descriptor Count error
 *   _anon19	(size 13, offset 19, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_chanerr_t;
#define ioat_dma_chanerr_default 0x0
static inline uint8_t ioat_dma_chanerr_dmatranserr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_dmatranserr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_dmatranserr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_dmatranserr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffe) | (0x1 & (((ioat_dma_chanerr_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_chanerr_dmaxfererr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_dmaxfererr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_dmaxfererr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_dmaxfererr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffd) | (0x2 & (((ioat_dma_chanerr_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_chanerr_nxtdescerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_nxtdescerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_nxtdescerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_nxtdescerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffb) | (0x4 & (((ioat_dma_chanerr_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_chanerr_descerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_descerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_descerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_descerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff7) | (0x8 & (((ioat_dma_chanerr_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_chanerr_chanaddr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_chanaddr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_chanaddr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_chanaddr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffef) | (0x10 & (((ioat_dma_chanerr_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_chanerr_chancmderr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_chancmderr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x20) >> 5));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_chancmderr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_chancmderr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffdf) | (0x20 & (((ioat_dma_chanerr_t )(_fieldval)) << 5)));
}

static inline uint8_t ioat_dma_chanerr_cdataerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_cdataerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x40) >> 6));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_cdataerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_cdataerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffbf) | (0x40 & (((ioat_dma_chanerr_t )(_fieldval)) << 6)));
}

static inline uint8_t ioat_dma_chanerr_dmadataerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_dmadataerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x80) >> 7));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_dmadataerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_dmadataerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff7f) | (0x80 & (((ioat_dma_chanerr_t )(_fieldval)) << 7)));
}

static inline uint8_t ioat_dma_chanerr_rddataerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_rddataerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_rddataerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_rddataerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffeff) | (0x100 & (((ioat_dma_chanerr_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_chanerr_wrdataerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_wrdataerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x200) >> 9));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_wrdataerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_wrdataerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffdff) | (0x200 & (((ioat_dma_chanerr_t )(_fieldval)) << 9)));
}

static inline uint8_t ioat_dma_chanerr_descctrlerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_descctrlerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_descctrlerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_descctrlerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffbff) | (0x400 & (((ioat_dma_chanerr_t )(_fieldval)) << 10)));
}

static inline uint8_t ioat_dma_chanerr_desclenerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_desclenerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x800) >> 11));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_desclenerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_desclenerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffff7ff) | (0x800 & (((ioat_dma_chanerr_t )(_fieldval)) << 11)));
}

static inline uint8_t ioat_dma_chanerr_cmpaddrerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_cmpaddrerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x1000) >> 12));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_cmpaddrerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_cmpaddrerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffefff) | (0x1000 & (((ioat_dma_chanerr_t )(_fieldval)) << 12)));
}

static inline uint8_t ioat_dma_chanerr_intcfgerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_intcfgerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x2000) >> 13));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_intcfgerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_intcfgerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffdfff) | (0x2000 & (((ioat_dma_chanerr_t )(_fieldval)) << 13)));
}

static inline uint8_t ioat_dma_chanerr_unaffilerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_unaffilerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_unaffilerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_unaffilerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff7fff) | (0x8000 & (((ioat_dma_chanerr_t )(_fieldval)) << 15)));
}

static inline uint8_t ioat_dma_chanerr_crc_err_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_crc_err_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x10000) >> 16));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_crc_err_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_crc_err_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffeffff) | (0x10000 & (((ioat_dma_chanerr_t )(_fieldval)) << 16)));
}

static inline uint8_t ioat_dma_chanerr_xorqerr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_xorqerr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x20000) >> 17));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_xorqerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_xorqerr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffdffff) | (0x20000 & (((ioat_dma_chanerr_t )(_fieldval)) << 17)));
}

static inline uint8_t ioat_dma_chanerr_desccnterr_extract(ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_desccnterr_extract(ioat_dma_chanerr_t _regval)
{
    return((uint8_t )((_regval & 0x40000) >> 18));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_desccnterr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_desccnterr_insert(ioat_dma_chanerr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffbffff) | (0x40000 & (((ioat_dma_chanerr_t )(_fieldval)) << 18)));
}

static inline int ioat_dma_chanerr_prtval(char *_s, size_t _size, ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chanerr_prtval(char *_s, size_t _size, ioat_dma_chanerr_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmatranserr =\t%" PRIx8 "\t(DMA Transfer Source address error)\n", ioat_dma_chanerr_dmatranserr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmaxfererr =\t%" PRIx8 "\t(DMA Transfer Destination address error)\n", ioat_dma_chanerr_dmaxfererr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " nxtdescerr =\t%" PRIx8 "\t(Next Descriptor Address error)\n", ioat_dma_chanerr_nxtdescerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descerr =\t%" PRIx8 "\t(Descriptor error)\n", ioat_dma_chanerr_descerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanaddr =\t%" PRIx8 "\t(Channel address value error)\n", ioat_dma_chanerr_chanaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chancmderr =\t%" PRIx8 "\t(Channel command error)\n", ioat_dma_chanerr_chancmderr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cdataerr =\t%" PRIx8 "\t(Data parity error)\n", ioat_dma_chanerr_cdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmadataerr =\t%" PRIx8 "\t(DMA Data Parity error)\n", ioat_dma_chanerr_dmadataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rddataerr =\t%" PRIx8 "\t(Read Data error)\n", ioat_dma_chanerr_rddataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " wrdataerr =\t%" PRIx8 "\t(Write data error)\n", ioat_dma_chanerr_wrdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descctrlerr =\t%" PRIx8 "\t(Description control  error)\n", ioat_dma_chanerr_descctrlerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desclenerr =\t%" PRIx8 "\t(Description length error)\n", ioat_dma_chanerr_desclenerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpaddrerr =\t%" PRIx8 "\t(Completion Address error)\n", ioat_dma_chanerr_cmpaddrerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intcfgerr =\t%" PRIx8 "\t(Interrupt confiuguratio error)\n", ioat_dma_chanerr_intcfgerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unaffilerr =\t%" PRIx8 "\t(Unaffiliated Error)\n", ioat_dma_chanerr_unaffilerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc_err =\t%" PRIx8 "\t(CRC test failed)\n", ioat_dma_chanerr_crc_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xorqerr =\t%" PRIx8 "\t(Xor error)\n", ioat_dma_chanerr_xorqerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desccnterr =\t%" PRIx8 "\t(Descriptor Count error)\n", ioat_dma_chanerr_desccnterr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_chanerrmsk_t
 * Description: Implicit type of Channel Error Mask Register. register
 * Fields:
 *   dmatranserr	(size 1, offset 0, init 0):	RWCS	DMA Transfer Source address error
 *   dmaxfererr	(size 1, offset 1, init 0):	RWCS	DMA Transfer Destination address error
 *   nxtdescerr	(size 1, offset 2, init 0):	RWCS	Next Descriptor Address error
 *   descerr	(size 1, offset 3, init 0):	RWCS	Descriptor error
 *   chanaddr	(size 1, offset 4, init 0):	RWCS	Channel address value error
 *   chancmderr	(size 1, offset 5, init 0):	RWCS	Channel command error
 *   cdataerr	(size 1, offset 6, init 0):	RWCS	Data parity error
 *   dmadataerr	(size 1, offset 7, init 0):	RWCS	DMA Data Parity error
 *   rddataerr	(size 1, offset 8, init 0):	RWCS	Read Data error
 *   wrdataerr	(size 1, offset 9, init 0):	RWCS	Write data error
 *   descctrlerr	(size 1, offset 10, init 0):	RWCS	Description control  error
 *   desclenerr	(size 1, offset 11, init 0):	RWCS	Description length error
 *   cmpaddrerr	(size 1, offset 12, init 0):	RWCS	Completion Address error
 *   intcfgerr	(size 1, offset 13, init 0):	RWCS	Interrupt confiuguratio error
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   unaffilerr	(size 1, offset 15, init 0):	RO	Unaffiliated Error
 *   crc_err	(size 1, offset 16, init 0):	RWCS	CRC test failed
 *   xorqerr	(size 1, offset 17, init 0):	RWCS	Xor error
 *   desccnterr	(size 1, offset 18, init 0):	RWCS	Descriptor Count error
 *   _anon19	(size 13, offset 19, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_chanerrmsk_t;
#define ioat_dma_chanerrmsk_default 0x0
static inline uint8_t ioat_dma_chanerrmsk_dmatranserr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_dmatranserr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_dmatranserr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_dmatranserr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffe) | (0x1 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_chanerrmsk_dmaxfererr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_dmaxfererr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_dmaxfererr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_dmaxfererr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffd) | (0x2 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 1)));
}

static inline uint8_t ioat_dma_chanerrmsk_nxtdescerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_nxtdescerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_nxtdescerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_nxtdescerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffb) | (0x4 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 2)));
}

static inline uint8_t ioat_dma_chanerrmsk_descerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_descerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_descerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_descerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff7) | (0x8 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_chanerrmsk_chanaddr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_chanaddr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_chanaddr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_chanaddr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffef) | (0x10 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 4)));
}

static inline uint8_t ioat_dma_chanerrmsk_chancmderr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_chancmderr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x20) >> 5));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_chancmderr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_chancmderr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffdf) | (0x20 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 5)));
}

static inline uint8_t ioat_dma_chanerrmsk_cdataerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_cdataerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x40) >> 6));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_cdataerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_cdataerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffbf) | (0x40 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 6)));
}

static inline uint8_t ioat_dma_chanerrmsk_dmadataerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_dmadataerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x80) >> 7));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_dmadataerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_dmadataerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff7f) | (0x80 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 7)));
}

static inline uint8_t ioat_dma_chanerrmsk_rddataerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_rddataerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x100) >> 8));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_rddataerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_rddataerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffeff) | (0x100 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_chanerrmsk_wrdataerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_wrdataerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x200) >> 9));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_wrdataerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_wrdataerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffdff) | (0x200 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 9)));
}

static inline uint8_t ioat_dma_chanerrmsk_descctrlerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_descctrlerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x400) >> 10));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_descctrlerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_descctrlerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffbff) | (0x400 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 10)));
}

static inline uint8_t ioat_dma_chanerrmsk_desclenerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_desclenerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x800) >> 11));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_desclenerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_desclenerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffff7ff) | (0x800 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 11)));
}

static inline uint8_t ioat_dma_chanerrmsk_cmpaddrerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_cmpaddrerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x1000) >> 12));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_cmpaddrerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_cmpaddrerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffefff) | (0x1000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 12)));
}

static inline uint8_t ioat_dma_chanerrmsk_intcfgerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_intcfgerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x2000) >> 13));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_intcfgerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_intcfgerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffdfff) | (0x2000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 13)));
}

static inline uint8_t ioat_dma_chanerrmsk_unaffilerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_unaffilerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x8000) >> 15));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_unaffilerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_unaffilerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff7fff) | (0x8000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 15)));
}

static inline uint8_t ioat_dma_chanerrmsk_crc_err_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_crc_err_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x10000) >> 16));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_crc_err_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_crc_err_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffeffff) | (0x10000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 16)));
}

static inline uint8_t ioat_dma_chanerrmsk_xorqerr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_xorqerr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x20000) >> 17));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_xorqerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_xorqerr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffdffff) | (0x20000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 17)));
}

static inline uint8_t ioat_dma_chanerrmsk_desccnterr_extract(ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_desccnterr_extract(ioat_dma_chanerrmsk_t _regval)
{
    return((uint8_t )((_regval & 0x40000) >> 18));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_desccnterr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_desccnterr_insert(ioat_dma_chanerrmsk_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffbffff) | (0x40000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 18)));
}

static inline int ioat_dma_chanerrmsk_prtval(char *_s, size_t _size, ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_chanerrmsk_prtval(char *_s, size_t _size, ioat_dma_chanerrmsk_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmatranserr =\t%" PRIx8 "\t(DMA Transfer Source address error)\n", ioat_dma_chanerrmsk_dmatranserr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmaxfererr =\t%" PRIx8 "\t(DMA Transfer Destination address error)\n", ioat_dma_chanerrmsk_dmaxfererr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " nxtdescerr =\t%" PRIx8 "\t(Next Descriptor Address error)\n", ioat_dma_chanerrmsk_nxtdescerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descerr =\t%" PRIx8 "\t(Descriptor error)\n", ioat_dma_chanerrmsk_descerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanaddr =\t%" PRIx8 "\t(Channel address value error)\n", ioat_dma_chanerrmsk_chanaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chancmderr =\t%" PRIx8 "\t(Channel command error)\n", ioat_dma_chanerrmsk_chancmderr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cdataerr =\t%" PRIx8 "\t(Data parity error)\n", ioat_dma_chanerrmsk_cdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmadataerr =\t%" PRIx8 "\t(DMA Data Parity error)\n", ioat_dma_chanerrmsk_dmadataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rddataerr =\t%" PRIx8 "\t(Read Data error)\n", ioat_dma_chanerrmsk_rddataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " wrdataerr =\t%" PRIx8 "\t(Write data error)\n", ioat_dma_chanerrmsk_wrdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descctrlerr =\t%" PRIx8 "\t(Description control  error)\n", ioat_dma_chanerrmsk_descctrlerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desclenerr =\t%" PRIx8 "\t(Description length error)\n", ioat_dma_chanerrmsk_desclenerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpaddrerr =\t%" PRIx8 "\t(Completion Address error)\n", ioat_dma_chanerrmsk_cmpaddrerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intcfgerr =\t%" PRIx8 "\t(Interrupt confiuguratio error)\n", ioat_dma_chanerrmsk_intcfgerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unaffilerr =\t%" PRIx8 "\t(Unaffiliated Error)\n", ioat_dma_chanerrmsk_unaffilerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc_err =\t%" PRIx8 "\t(CRC test failed)\n", ioat_dma_chanerrmsk_crc_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xorqerr =\t%" PRIx8 "\t(Xor error)\n", ioat_dma_chanerrmsk_xorqerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desccnterr =\t%" PRIx8 "\t(Descriptor Count error)\n", ioat_dma_chanerrmsk_desccnterr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dcactrl_t
 * Description: Implicit type of DCA Control Register register
 * Fields:
 *   target_cpu	(size 16, offset 0, init 0):	RW	Specifies the APCI ID of the target CPU for compl writes
 *   _anon16	(size 16, offset 16, init 0):	RSVD	_
 */
typedef uint32_t ioat_dma_dcactrl_t;
#define ioat_dma_dcactrl_default 0x0
static inline uint16_t ioat_dma_dcactrl_target_cpu_extract(ioat_dma_dcactrl_t _regval) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_dcactrl_target_cpu_extract(ioat_dma_dcactrl_t _regval)
{
    return((uint16_t )((_regval & 0xffff) >> 0));
}

static inline ioat_dma_dcactrl_t ioat_dma_dcactrl_target_cpu_insert(ioat_dma_dcactrl_t _regval, uint16_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dcactrl_t ioat_dma_dcactrl_target_cpu_insert(ioat_dma_dcactrl_t _regval, uint16_t _fieldval)
{
    return((_regval & 0xffff0000) | (0xffff & (((ioat_dma_dcactrl_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_dcactrl_prtval(char *_s, size_t _size, ioat_dma_dcactrl_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dcactrl_prtval(char *_s, size_t _size, ioat_dma_dcactrl_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " target_cpu =\t%" PRIx16 "\t(Specifies the APCI ID of the target CPU for compl writes)\n", ioat_dma_dcactrl_target_cpu_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dca_ver_t
 * Description: Implicit type of DCA Version Number Register register
 * Fields:
 *   minor	(size 4, offset 0, init 0):	RO	Major Revision Number
 *   major	(size 4, offset 4, init 0):	RO	Major Revision Number
 */
typedef uint8_t ioat_dma_dca_ver_t;
#define ioat_dma_dca_ver_default 0x0
static inline uint8_t ioat_dma_dca_ver_minor_extract(ioat_dma_dca_ver_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_ver_minor_extract(ioat_dma_dca_ver_t _regval)
{
    return((uint8_t )((_regval & 0xf) >> 0));
}

static inline ioat_dma_dca_ver_t ioat_dma_dca_ver_minor_insert(ioat_dma_dca_ver_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_ver_t ioat_dma_dca_ver_minor_insert(ioat_dma_dca_ver_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf0) | (0xf & (((ioat_dma_dca_ver_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_dca_ver_major_extract(ioat_dma_dca_ver_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_ver_major_extract(ioat_dma_dca_ver_t _regval)
{
    return((uint8_t )((_regval & 0xf0) >> 4));
}

static inline ioat_dma_dca_ver_t ioat_dma_dca_ver_major_insert(ioat_dma_dca_ver_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_ver_t ioat_dma_dca_ver_major_insert(ioat_dma_dca_ver_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xf) | (0xf0 & (((ioat_dma_dca_ver_t )(_fieldval)) << 4)));
}

static inline int ioat_dma_dca_ver_prtval(char *_s, size_t _size, ioat_dma_dca_ver_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dca_ver_prtval(char *_s, size_t _size, ioat_dma_dca_ver_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " minor =\t%" PRIx8 "\t(Major Revision Number)\n", ioat_dma_dca_ver_minor_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " major =\t%" PRIx8 "\t(Major Revision Number)\n", ioat_dma_dca_ver_major_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_csi_capability_t
 * Description: Implicit type of Intel QPI Compability Register register
 * Fields:
 *   prefetch_hint	(size 1, offset 0, init 0):	RO	Prefetch hint
 *   _anon1	(size 15, offset 1, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_csi_capability_t;
#define ioat_dma_csi_capability_default 0x0
static inline uint8_t ioat_dma_csi_capability_prefetch_hint_extract(ioat_dma_csi_capability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_csi_capability_prefetch_hint_extract(ioat_dma_csi_capability_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_csi_capability_t ioat_dma_csi_capability_prefetch_hint_insert(ioat_dma_csi_capability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_csi_capability_t ioat_dma_csi_capability_prefetch_hint_insert(ioat_dma_csi_capability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((ioat_dma_csi_capability_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_csi_capability_prtval(char *_s, size_t _size, ioat_dma_csi_capability_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_csi_capability_prtval(char *_s, size_t _size, ioat_dma_csi_capability_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " prefetch_hint =\t%" PRIx8 "\t(Prefetch hint)\n", ioat_dma_csi_capability_prefetch_hint_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_pcie_capability_t
 * Description: Implicit type of PCI Express Cabability Register register
 * Fields:
 *   memwr_en	(size 1, offset 0, init 0):	RO	Enable Memory Writes on PCI Express
 *   _anon1	(size 15, offset 1, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_pcie_capability_t;
#define ioat_dma_pcie_capability_default 0x0
static inline uint8_t ioat_dma_pcie_capability_memwr_en_extract(ioat_dma_pcie_capability_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcie_capability_memwr_en_extract(ioat_dma_pcie_capability_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_pcie_capability_t ioat_dma_pcie_capability_memwr_en_insert(ioat_dma_pcie_capability_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcie_capability_t ioat_dma_pcie_capability_memwr_en_insert(ioat_dma_pcie_capability_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((ioat_dma_pcie_capability_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_pcie_capability_prtval(char *_s, size_t _size, ioat_dma_pcie_capability_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_pcie_capability_prtval(char *_s, size_t _size, ioat_dma_pcie_capability_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " memwr_en =\t%" PRIx8 "\t(Enable Memory Writes on PCI Express)\n", ioat_dma_pcie_capability_memwr_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_csi_cap_enable_t
 * Description: Implicit type of Intel QPI Compability Enable Register register
 * Fields:
 *   prefetch_hint	(size 1, offset 0, init 0):	RW	Prefetch hint
 *   _anon1	(size 15, offset 1, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_csi_cap_enable_t;
#define ioat_dma_csi_cap_enable_default 0x0
static inline uint8_t ioat_dma_csi_cap_enable_prefetch_hint_extract(ioat_dma_csi_cap_enable_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_csi_cap_enable_prefetch_hint_extract(ioat_dma_csi_cap_enable_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_csi_cap_enable_t ioat_dma_csi_cap_enable_prefetch_hint_insert(ioat_dma_csi_cap_enable_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_csi_cap_enable_t ioat_dma_csi_cap_enable_prefetch_hint_insert(ioat_dma_csi_cap_enable_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((ioat_dma_csi_cap_enable_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_csi_cap_enable_prtval(char *_s, size_t _size, ioat_dma_csi_cap_enable_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_csi_cap_enable_prtval(char *_s, size_t _size, ioat_dma_csi_cap_enable_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " prefetch_hint =\t%" PRIx8 "\t(Prefetch hint)\n", ioat_dma_csi_cap_enable_prefetch_hint_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_pcie_cap_enable_t
 * Description: Implicit type of PCI Express Cabability Enable Register register
 * Fields:
 *   memwr_en	(size 1, offset 0, init 0):	RW	Enable Memory Writes on PCI Express
 *   _anon1	(size 15, offset 1, init 0):	RSVD	_
 */
typedef uint16_t ioat_dma_pcie_cap_enable_t;
#define ioat_dma_pcie_cap_enable_default 0x0
static inline uint8_t ioat_dma_pcie_cap_enable_memwr_en_extract(ioat_dma_pcie_cap_enable_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcie_cap_enable_memwr_en_extract(ioat_dma_pcie_cap_enable_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_pcie_cap_enable_t ioat_dma_pcie_cap_enable_memwr_en_insert(ioat_dma_pcie_cap_enable_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pcie_cap_enable_t ioat_dma_pcie_cap_enable_memwr_en_insert(ioat_dma_pcie_cap_enable_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((ioat_dma_pcie_cap_enable_t )(_fieldval)) << 0)));
}

static inline int ioat_dma_pcie_cap_enable_prtval(char *_s, size_t _size, ioat_dma_pcie_cap_enable_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_pcie_cap_enable_prtval(char *_s, size_t _size, ioat_dma_pcie_cap_enable_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " memwr_en =\t%" PRIx8 "\t(Enable Memory Writes on PCI Express)\n", ioat_dma_pcie_cap_enable_memwr_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_apicid_tag_map_t
 * Description: Implicit type of APICID to Tag Map Register. register
 * Fields:
 *   tag_map_0	(size 8, offset 0, init 0):	RW	Tag Map 0
 *   tag_map_1	(size 8, offset 8, init 0):	RW	Tag Map 1
 *   tag_map_2	(size 8, offset 16, init 0):	RW	Tag Map 2
 *   tag_map_3	(size 8, offset 24, init 0):	RW	Tag Map 3
 *   tag_map_4	(size 8, offset 32, init 0):	RW	Tag Map 4
 *   _anon40	(size 24, offset 40, init 0):	RSVD	_
 */
typedef uint64_t ioat_dma_apicid_tag_map_t;
#define ioat_dma_apicid_tag_map_default 0x0
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_0_extract(ioat_dma_apicid_tag_map_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_0_extract(ioat_dma_apicid_tag_map_t _regval)
{
    return((uint8_t )((_regval & 0xff) >> 0));
}

static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_tag_map_0_insert(ioat_dma_apicid_tag_map_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_tag_map_0_insert(ioat_dma_apicid_tag_map_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffffffffff00) | (0xff & (((ioat_dma_apicid_tag_map_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_apicid_tag_map_tag_map_1_extract(ioat_dma_apicid_tag_map_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_1_extract(ioat_dma_apicid_tag_map_t _regval)
{
    return((uint8_t )((_regval & 0xff00) >> 8));
}

static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_tag_map_1_insert(ioat_dma_apicid_tag_map_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_tag_map_1_insert(ioat_dma_apicid_tag_map_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffffffff00ff) | (0xff00 & (((ioat_dma_apicid_tag_map_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_apicid_tag_map_tag_map_2_extract(ioat_dma_apicid_tag_map_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_2_extract(ioat_dma_apicid_tag_map_t _regval)
{
    return((uint8_t )((_regval & 0xff0000) >> 16));
}

static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_tag_map_2_insert(ioat_dma_apicid_tag_map_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_tag_map_2_insert(ioat_dma_apicid_tag_map_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffffff00ffff) | (0xff0000 & (((ioat_dma_apicid_tag_map_t )(_fieldval)) << 16)));
}

static inline uint8_t ioat_dma_apicid_tag_map_tag_map_3_extract(ioat_dma_apicid_tag_map_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_3_extract(ioat_dma_apicid_tag_map_t _regval)
{
    return((uint8_t )((_regval & 0xff000000) >> 24));
}

static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_tag_map_3_insert(ioat_dma_apicid_tag_map_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_tag_map_3_insert(ioat_dma_apicid_tag_map_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffffff00ffffff) | (0xff000000 & (((ioat_dma_apicid_tag_map_t )(_fieldval)) << 24)));
}

static inline uint8_t ioat_dma_apicid_tag_map_tag_map_4_extract(ioat_dma_apicid_tag_map_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_4_extract(ioat_dma_apicid_tag_map_t _regval)
{
    return((uint8_t )((_regval & 0xff00000000) >> 32));
}

static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_tag_map_4_insert(ioat_dma_apicid_tag_map_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_tag_map_4_insert(ioat_dma_apicid_tag_map_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff00ffffffff) | (0xff00000000 & (((ioat_dma_apicid_tag_map_t )(_fieldval)) << 32)));
}

static inline int ioat_dma_apicid_tag_map_prtval(char *_s, size_t _size, ioat_dma_apicid_tag_map_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_apicid_tag_map_prtval(char *_s, size_t _size, ioat_dma_apicid_tag_map_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tag_map_0 =\t%" PRIx8 "\t(Tag Map 0)\n", ioat_dma_apicid_tag_map_tag_map_0_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tag_map_1 =\t%" PRIx8 "\t(Tag Map 1)\n", ioat_dma_apicid_tag_map_tag_map_1_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tag_map_2 =\t%" PRIx8 "\t(Tag Map 2)\n", ioat_dma_apicid_tag_map_tag_map_2_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tag_map_3 =\t%" PRIx8 "\t(Tag Map 3)\n", ioat_dma_apicid_tag_map_tag_map_3_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tag_map_4 =\t%" PRIx8 "\t(Tag Map 4)\n", ioat_dma_apicid_tag_map_tag_map_4_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dca_reqid0_t
 * Description: Implicit type of Global DCA Requester ID Table Registers. register
 * Fields:
 *   fun	(size 3, offset 0, init 0):	RW	PCI Device Function
 *   dev	(size 5, offset 3, init 0):	RW	PCI Device Id
 *   bus	(size 8, offset 8, init 0):	RW	PCI Bus number
 *   _anon16	(size 12, offset 16, init 0):	RSVD	_
 *   ignore	(size 1, offset 28, init 0):	RW	If set, function number is ignore for DCA identification
 *   valid	(size 1, offset 29, init 0):	RW	If set, bits 15:0 are used for DCA identification
 *   _anon30	(size 1, offset 30, init 0):	RSVD	_
 *   last	(size 1, offset 31, init 0):	RO	Last Requested ID register
 */
typedef uint32_t ioat_dma_dca_reqid0_t;
#define ioat_dma_dca_reqid0_default 0x0
static inline uint8_t ioat_dma_dca_reqid0_fun_extract(ioat_dma_dca_reqid0_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_fun_extract(ioat_dma_dca_reqid0_t _regval)
{
    return((uint8_t )((_regval & 0x7) >> 0));
}

static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_fun_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_fun_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff8) | (0x7 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_dca_reqid0_dev_extract(ioat_dma_dca_reqid0_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_dev_extract(ioat_dma_dca_reqid0_t _regval)
{
    return((uint8_t )((_regval & 0xf8) >> 3));
}

static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_dev_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_dev_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff07) | (0xf8 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_dca_reqid0_bus_extract(ioat_dma_dca_reqid0_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_bus_extract(ioat_dma_dca_reqid0_t _regval)
{
    return((uint8_t )((_regval & 0xff00) >> 8));
}

static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_bus_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_bus_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff00ff) | (0xff00 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_dca_reqid0_ignore_extract(ioat_dma_dca_reqid0_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_ignore_extract(ioat_dma_dca_reqid0_t _regval)
{
    return((uint8_t )((_regval & 0x10000000) >> 28));
}

static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_ignore_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_ignore_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xefffffff) | (0x10000000 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 28)));
}

static inline uint8_t ioat_dma_dca_reqid0_valid_extract(ioat_dma_dca_reqid0_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_valid_extract(ioat_dma_dca_reqid0_t _regval)
{
    return((uint8_t )((_regval & 0x20000000) >> 29));
}

static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_valid_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_valid_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xdfffffff) | (0x20000000 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 29)));
}

static inline uint8_t ioat_dma_dca_reqid0_last_extract(ioat_dma_dca_reqid0_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_last_extract(ioat_dma_dca_reqid0_t _regval)
{
    return((uint8_t )((_regval & 0x80000000) >> 31));
}

static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_last_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_last_insert(ioat_dma_dca_reqid0_t _regval, uint8_t _fieldval)
{
    return((_regval & 0x7fffffff) | (0x80000000 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 31)));
}

static inline int ioat_dma_dca_reqid0_prtval(char *_s, size_t _size, ioat_dma_dca_reqid0_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dca_reqid0_prtval(char *_s, size_t _size, ioat_dma_dca_reqid0_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " fun =\t%" PRIx8 "\t(PCI Device Function)\n", ioat_dma_dca_reqid0_fun_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dev =\t%" PRIx8 "\t(PCI Device Id)\n", ioat_dma_dca_reqid0_dev_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bus =\t%" PRIx8 "\t(PCI Bus number)\n", ioat_dma_dca_reqid0_bus_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ignore =\t%" PRIx8 "\t(If set, function number is ignore for DCA identification)\n", ioat_dma_dca_reqid0_ignore_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " valid =\t%" PRIx8 "\t(If set, bits 15:0 are used for DCA identification)\n", ioat_dma_dca_reqid0_valid_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " last =\t%" PRIx8 "\t(Last Requested ID register)\n", ioat_dma_dca_reqid0_last_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_dca_reqid1_t
 * Description: Implicit type of Global DCA Requester ID Table Registers. register
 * Fields:
 *   fun	(size 3, offset 0, init 0):	RW	PCI Device Function
 *   dev	(size 5, offset 3, init 0):	RW	PCI Device Id
 *   bus	(size 8, offset 8, init 0):	RW	PCI Bus number
 *   _anon16	(size 12, offset 16, init 0):	RSVD	_
 *   ignore	(size 1, offset 28, init 0):	RW	If set, function number is ignore for DCA identification
 *   valid	(size 1, offset 29, init 0):	RW	If set, bits 15:0 are used for DCA identification
 *   _anon30	(size 1, offset 30, init 0):	RSVD	_
 *   last	(size 1, offset 31, init 0):	RO	Last Requested ID register
 */
typedef uint32_t ioat_dma_dca_reqid1_t;
#define ioat_dma_dca_reqid1_default 0x0
static inline uint8_t ioat_dma_dca_reqid1_fun_extract(ioat_dma_dca_reqid1_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_fun_extract(ioat_dma_dca_reqid1_t _regval)
{
    return((uint8_t )((_regval & 0x7) >> 0));
}

static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_fun_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_fun_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff8) | (0x7 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 0)));
}

static inline uint8_t ioat_dma_dca_reqid1_dev_extract(ioat_dma_dca_reqid1_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_dev_extract(ioat_dma_dca_reqid1_t _regval)
{
    return((uint8_t )((_regval & 0xf8) >> 3));
}

static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_dev_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_dev_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffffff07) | (0xf8 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 3)));
}

static inline uint8_t ioat_dma_dca_reqid1_bus_extract(ioat_dma_dca_reqid1_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_bus_extract(ioat_dma_dca_reqid1_t _regval)
{
    return((uint8_t )((_regval & 0xff00) >> 8));
}

static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_bus_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_bus_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffff00ff) | (0xff00 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 8)));
}

static inline uint8_t ioat_dma_dca_reqid1_ignore_extract(ioat_dma_dca_reqid1_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_ignore_extract(ioat_dma_dca_reqid1_t _regval)
{
    return((uint8_t )((_regval & 0x10000000) >> 28));
}

static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_ignore_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_ignore_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xefffffff) | (0x10000000 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 28)));
}

static inline uint8_t ioat_dma_dca_reqid1_valid_extract(ioat_dma_dca_reqid1_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_valid_extract(ioat_dma_dca_reqid1_t _regval)
{
    return((uint8_t )((_regval & 0x20000000) >> 29));
}

static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_valid_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_valid_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xdfffffff) | (0x20000000 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 29)));
}

static inline uint8_t ioat_dma_dca_reqid1_last_extract(ioat_dma_dca_reqid1_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_last_extract(ioat_dma_dca_reqid1_t _regval)
{
    return((uint8_t )((_regval & 0x80000000) >> 31));
}

static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_last_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_last_insert(ioat_dma_dca_reqid1_t _regval, uint8_t _fieldval)
{
    return((_regval & 0x7fffffff) | (0x80000000 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 31)));
}

static inline int ioat_dma_dca_reqid1_prtval(char *_s, size_t _size, ioat_dma_dca_reqid1_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_dca_reqid1_prtval(char *_s, size_t _size, ioat_dma_dca_reqid1_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " fun =\t%" PRIx8 "\t(PCI Device Function)\n", ioat_dma_dca_reqid1_fun_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dev =\t%" PRIx8 "\t(PCI Device Id)\n", ioat_dma_dca_reqid1_dev_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bus =\t%" PRIx8 "\t(PCI Bus number)\n", ioat_dma_dca_reqid1_bus_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ignore =\t%" PRIx8 "\t(If set, function number is ignore for DCA identification)\n", ioat_dma_dca_reqid1_ignore_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " valid =\t%" PRIx8 "\t(If set, bits 15:0 are used for DCA identification)\n", ioat_dma_dca_reqid1_valid_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " last =\t%" PRIx8 "\t(Last Requested ID register)\n", ioat_dma_dca_reqid1_last_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_msgaddr_lo_t
 * Description: Implicit type of MSI-X Lower Address Registers. register
 * Fields:
 *   chmsgaddr_const	(size 2, offset 0, init 0):	RO	
 *   chmsgaddr	(size 30, offset 2, init 0):	RW	Specifies the local APIC to which this MSI-X interrupt needs to be sent
 */
typedef uint32_t ioat_dma_msgaddr_lo_t;
#define ioat_dma_msgaddr_lo_default 0x0
static inline uint8_t ioat_dma_msgaddr_lo_chmsgaddr_const_extract(ioat_dma_msgaddr_lo_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_msgaddr_lo_chmsgaddr_const_extract(ioat_dma_msgaddr_lo_t _regval)
{
    return((uint8_t )((_regval & 0x3) >> 0));
}

static inline ioat_dma_msgaddr_lo_t ioat_dma_msgaddr_lo_chmsgaddr_const_insert(ioat_dma_msgaddr_lo_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_msgaddr_lo_t ioat_dma_msgaddr_lo_chmsgaddr_const_insert(ioat_dma_msgaddr_lo_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffc) | (0x3 & (((ioat_dma_msgaddr_lo_t )(_fieldval)) << 0)));
}

static inline uint32_t ioat_dma_msgaddr_lo_chmsgaddr_extract(ioat_dma_msgaddr_lo_t _regval) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_msgaddr_lo_chmsgaddr_extract(ioat_dma_msgaddr_lo_t _regval)
{
    return((uint32_t )((_regval & 0xfffffffc) >> 2));
}

static inline ioat_dma_msgaddr_lo_t ioat_dma_msgaddr_lo_chmsgaddr_insert(ioat_dma_msgaddr_lo_t _regval, uint32_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_msgaddr_lo_t ioat_dma_msgaddr_lo_chmsgaddr_insert(ioat_dma_msgaddr_lo_t _regval, uint32_t _fieldval)
{
    return((_regval & 0x3) | (0xfffffffc & (((ioat_dma_msgaddr_lo_t )(_fieldval)) << 2)));
}

static inline int ioat_dma_msgaddr_lo_prtval(char *_s, size_t _size, ioat_dma_msgaddr_lo_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_msgaddr_lo_prtval(char *_s, size_t _size, ioat_dma_msgaddr_lo_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chmsgaddr_const =\t%" PRIx8 "\t()\n", ioat_dma_msgaddr_lo_chmsgaddr_const_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chmsgaddr =\t%" PRIx32 "\t(Specifies the local APIC to which this MSI-X interrupt needs to be sent)\n", ioat_dma_msgaddr_lo_chmsgaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_vecctrl_t
 * Description: Implicit type of MSI-X Vector Control Registers. register
 * Fields:
 *   chmask	(size 1, offset 0, init 0):	RW	When a bit is set, the channel is prohibited from sending a message
 *   chvecctrlcnst	(size 31, offset 1, init 0):	RO	chvecctrlcnst
 */
typedef uint32_t ioat_dma_vecctrl_t;
#define ioat_dma_vecctrl_default 0x0
static inline uint8_t ioat_dma_vecctrl_chmask_extract(ioat_dma_vecctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_vecctrl_chmask_extract(ioat_dma_vecctrl_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_vecctrl_t ioat_dma_vecctrl_chmask_insert(ioat_dma_vecctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_vecctrl_t ioat_dma_vecctrl_chmask_insert(ioat_dma_vecctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffe) | (0x1 & (((ioat_dma_vecctrl_t )(_fieldval)) << 0)));
}

static inline uint32_t ioat_dma_vecctrl_chvecctrlcnst_extract(ioat_dma_vecctrl_t _regval) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_vecctrl_chvecctrlcnst_extract(ioat_dma_vecctrl_t _regval)
{
    return((uint32_t )((_regval & 0xfffffffe) >> 1));
}

static inline ioat_dma_vecctrl_t ioat_dma_vecctrl_chvecctrlcnst_insert(ioat_dma_vecctrl_t _regval, uint32_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_vecctrl_t ioat_dma_vecctrl_chvecctrlcnst_insert(ioat_dma_vecctrl_t _regval, uint32_t _fieldval)
{
    return((_regval & 0x1) | (0xfffffffe & (((ioat_dma_vecctrl_t )(_fieldval)) << 1)));
}

static inline int ioat_dma_vecctrl_prtval(char *_s, size_t _size, ioat_dma_vecctrl_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_vecctrl_prtval(char *_s, size_t _size, ioat_dma_vecctrl_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chmask =\t%" PRIx8 "\t(When a bit is set, the channel is prohibited from sending a message)\n", ioat_dma_vecctrl_chmask_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chvecctrlcnst =\t%" PRIx32 "\t(chvecctrlcnst)\n", ioat_dma_vecctrl_chvecctrlcnst_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: ioat_dma_pendingbits_t
 * Description: Implicit type of MSI-X Interrupt Pending Bits Registers. register
 * Fields:
 *   chmsipend	(size 1, offset 0, init 0):	RW	Pending Bit (when set) indicates that the DMA engine has a pending MSI-X
 *   chmsipendcnst	(size 31, offset 1, init 0):	RO	Unused
 */
typedef uint32_t ioat_dma_pendingbits_t;
#define ioat_dma_pendingbits_default 0x0
static inline uint8_t ioat_dma_pendingbits_chmsipend_extract(ioat_dma_pendingbits_t _regval) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pendingbits_chmsipend_extract(ioat_dma_pendingbits_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline ioat_dma_pendingbits_t ioat_dma_pendingbits_chmsipend_insert(ioat_dma_pendingbits_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pendingbits_t ioat_dma_pendingbits_chmsipend_insert(ioat_dma_pendingbits_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffe) | (0x1 & (((ioat_dma_pendingbits_t )(_fieldval)) << 0)));
}

static inline uint32_t ioat_dma_pendingbits_chmsipendcnst_extract(ioat_dma_pendingbits_t _regval) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_pendingbits_chmsipendcnst_extract(ioat_dma_pendingbits_t _regval)
{
    return((uint32_t )((_regval & 0xfffffffe) >> 1));
}

static inline ioat_dma_pendingbits_t ioat_dma_pendingbits_chmsipendcnst_insert(ioat_dma_pendingbits_t _regval, uint32_t _fieldval) __attribute__ ((always_inline));
static inline ioat_dma_pendingbits_t ioat_dma_pendingbits_chmsipendcnst_insert(ioat_dma_pendingbits_t _regval, uint32_t _fieldval)
{
    return((_regval & 0x1) | (0xfffffffe & (((ioat_dma_pendingbits_t )(_fieldval)) << 1)));
}

static inline int ioat_dma_pendingbits_prtval(char *_s, size_t _size, ioat_dma_pendingbits_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_pendingbits_prtval(char *_s, size_t _size, ioat_dma_pendingbits_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chmsipend =\t%" PRIx8 "\t(Pending Bit (when set) indicates that the DMA engine has a pending MSI-X)\n", ioat_dma_pendingbits_chmsipend_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chmsipendcnst =\t%" PRIx32 "\t(Unused)\n", ioat_dma_pendingbits_chmsipendcnst_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Data type: ioat_dma_tag_map_t
 * Description: Tag Map datatype
 * Fields:
 *   map	(size 4, offset 0, init 0):	RW	Map values
 *   _anon4	(size 2, offset 4, init 0):	RSVD	_
 *   maptype	(size 2, offset 6, init 0):	RW	Type as specified in tag_map_* values
 */
typedef uint8_t *ioat_dma_tag_map_t;
typedef uint8_t ioat_dma_tag_map_array_t[1];
static const size_t ioat_dma_tag_map_size = sizeof(ioat_dma_tag_map_array_t );
static inline uint8_t ioat_dma_tag_map_map_extract(ioat_dma_tag_map_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_tag_map_map_extract(ioat_dma_tag_map_t _dtptr)
{
    return(((*((uint8_t *)(0 + _dtptr))) & 0xf) >> 0);
}

static inline void ioat_dma_tag_map_map_insert(ioat_dma_tag_map_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_tag_map_map_insert(ioat_dma_tag_map_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(0 + _dtptr)) = (((*((uint8_t *)(0 + _dtptr))) & 0xf0) | (0xf & (_fieldval << 0)));
}

static inline uint8_t ioat_dma_tag_map_maptype_extract(ioat_dma_tag_map_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_tag_map_maptype_extract(ioat_dma_tag_map_t _dtptr)
{
    return(((*((uint8_t *)(0 + _dtptr))) & 0xc0) >> 6);
}

static inline void ioat_dma_tag_map_maptype_insert(ioat_dma_tag_map_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_tag_map_maptype_insert(ioat_dma_tag_map_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(0 + _dtptr)) = (((*((uint8_t *)(0 + _dtptr))) & 0x3f) | (0xc0 & (_fieldval << 6)));
}

static inline int ioat_dma_tag_map_prtval(char *_s, size_t _size, ioat_dma_tag_map_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_tag_map_prtval(char *_s, size_t _size, ioat_dma_tag_map_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " map =\t%" PRIx8 "\t(Map values)\n", ioat_dma_tag_map_map_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " maptype =\t%" PRIx8 "\t(Type as specified in tag_map_* values)\n", ioat_dma_tag_map_maptype_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Data type: ioat_dma_desc_ctrl_t
 * Description: IOAT DMA Descriptor control field
 * Fields:
 *   int_en	(size 1, offset 0, init 0):	RW	Interrupt enable
 *   src_snoop_dis	(size 1, offset 1, init 0):	RW	Disable snooping of source address
 *   dest_snoop_dis	(size 1, offset 2, init 0):	RW	Disable snooping of destination address
 *   compl_write	(size 1, offset 3, init 0):	RW	
 *   fence	(size 1, offset 4, init 0):	RW	
 *   null	(size 1, offset 5, init 0):	RW	
 *   src_brk	(size 1, offset 6, init 0):	RW	
 *   dest_brk	(size 1, offset 7, init 0):	RW	
 *   bundle	(size 1, offset 8, init 0):	RW	
 *   dest_dca	(size 1, offset 9, init 0):	RW	
 *   hint	(size 1, offset 10, init 0):	RW	
 *   _anon11	(size 13, offset 11, init 0):	RSVD	_
 *   op	(size 8, offset 24, init 0):	RW	OP Code to execute
 */
typedef uint8_t *ioat_dma_desc_ctrl_t;
typedef uint8_t ioat_dma_desc_ctrl_array_t[4];
static const size_t ioat_dma_desc_ctrl_size = sizeof(ioat_dma_desc_ctrl_array_t );
static inline uint8_t ioat_dma_desc_ctrl_int_en_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_int_en_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(0 + _dtptr))) & 0x1) >> 0);
}

static inline void ioat_dma_desc_ctrl_int_en_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_int_en_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(0 + _dtptr)) = (((*((uint8_t *)(0 + _dtptr))) & 0xfe) | (0x1 & (_fieldval << 0)));
}

static inline uint8_t ioat_dma_desc_ctrl_src_snoop_dis_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_src_snoop_dis_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(0 + _dtptr))) & 0x2) >> 1);
}

static inline void ioat_dma_desc_ctrl_src_snoop_dis_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_src_snoop_dis_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(0 + _dtptr)) = (((*((uint8_t *)(0 + _dtptr))) & 0xfd) | (0x2 & (_fieldval << 1)));
}

static inline uint8_t ioat_dma_desc_ctrl_dest_snoop_dis_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_dest_snoop_dis_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(0 + _dtptr))) & 0x4) >> 2);
}

static inline void ioat_dma_desc_ctrl_dest_snoop_dis_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_dest_snoop_dis_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(0 + _dtptr)) = (((*((uint8_t *)(0 + _dtptr))) & 0xfb) | (0x4 & (_fieldval << 2)));
}

static inline uint8_t ioat_dma_desc_ctrl_compl_write_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_compl_write_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(0 + _dtptr))) & 0x8) >> 3);
}

static inline void ioat_dma_desc_ctrl_compl_write_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_compl_write_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(0 + _dtptr)) = (((*((uint8_t *)(0 + _dtptr))) & 0xf7) | (0x8 & (_fieldval << 3)));
}

static inline uint8_t ioat_dma_desc_ctrl_fence_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_fence_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(0 + _dtptr))) & 0x10) >> 4);
}

static inline void ioat_dma_desc_ctrl_fence_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_fence_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(0 + _dtptr)) = (((*((uint8_t *)(0 + _dtptr))) & 0xef) | (0x10 & (_fieldval << 4)));
}

static inline uint8_t ioat_dma_desc_ctrl_null_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_null_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(0 + _dtptr))) & 0x20) >> 5);
}

static inline void ioat_dma_desc_ctrl_null_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_null_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(0 + _dtptr)) = (((*((uint8_t *)(0 + _dtptr))) & 0xdf) | (0x20 & (_fieldval << 5)));
}

static inline uint8_t ioat_dma_desc_ctrl_src_brk_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_src_brk_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(0 + _dtptr))) & 0x40) >> 6);
}

static inline void ioat_dma_desc_ctrl_src_brk_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_src_brk_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(0 + _dtptr)) = (((*((uint8_t *)(0 + _dtptr))) & 0xbf) | (0x40 & (_fieldval << 6)));
}

static inline uint8_t ioat_dma_desc_ctrl_dest_brk_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_dest_brk_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(0 + _dtptr))) & 0x80) >> 7);
}

static inline void ioat_dma_desc_ctrl_dest_brk_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_dest_brk_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(0 + _dtptr)) = (((*((uint8_t *)(0 + _dtptr))) & 0x7f) | (0x80 & (_fieldval << 7)));
}

static inline uint8_t ioat_dma_desc_ctrl_bundle_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_bundle_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(1 + _dtptr))) & 0x1) >> 0);
}

static inline void ioat_dma_desc_ctrl_bundle_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_bundle_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(1 + _dtptr)) = (((*((uint8_t *)(1 + _dtptr))) & 0xfe) | (0x1 & (_fieldval << 0)));
}

static inline uint8_t ioat_dma_desc_ctrl_dest_dca_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_dest_dca_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(1 + _dtptr))) & 0x2) >> 1);
}

static inline void ioat_dma_desc_ctrl_dest_dca_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_dest_dca_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(1 + _dtptr)) = (((*((uint8_t *)(1 + _dtptr))) & 0xfd) | (0x2 & (_fieldval << 1)));
}

static inline uint8_t ioat_dma_desc_ctrl_hint_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_hint_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(1 + _dtptr))) & 0x4) >> 2);
}

static inline void ioat_dma_desc_ctrl_hint_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_hint_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(1 + _dtptr)) = (((*((uint8_t *)(1 + _dtptr))) & 0xfb) | (0x4 & (_fieldval << 2)));
}

static inline uint8_t ioat_dma_desc_ctrl_op_extract(ioat_dma_desc_ctrl_t _dtptr) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_desc_ctrl_op_extract(ioat_dma_desc_ctrl_t _dtptr)
{
    return(((*((uint8_t *)(3 + _dtptr))) & 0xff) >> 0);
}

static inline void ioat_dma_desc_ctrl_op_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_op_insert(ioat_dma_desc_ctrl_t _dtptr, uint8_t _fieldval)
{
    *((uint8_t *)(3 + _dtptr)) = (((*((uint8_t *)(3 + _dtptr))) & 0x0) | (0xff & (_fieldval << 0)));
}

static inline int ioat_dma_desc_ctrl_prtval(char *_s, size_t _size, ioat_dma_desc_ctrl_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_desc_ctrl_prtval(char *_s, size_t _size, ioat_dma_desc_ctrl_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " int_en =\t%" PRIx8 "\t(Interrupt enable)\n", ioat_dma_desc_ctrl_int_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " src_snoop_dis =\t%" PRIx8 "\t(Disable snooping of source address)\n", ioat_dma_desc_ctrl_src_snoop_dis_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dest_snoop_dis =\t%" PRIx8 "\t(Disable snooping of destination address)\n", ioat_dma_desc_ctrl_dest_snoop_dis_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_write =\t%" PRIx8 "\t()\n", ioat_dma_desc_ctrl_compl_write_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " fence =\t%" PRIx8 "\t()\n", ioat_dma_desc_ctrl_fence_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " null =\t%" PRIx8 "\t()\n", ioat_dma_desc_ctrl_null_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " src_brk =\t%" PRIx8 "\t()\n", ioat_dma_desc_ctrl_src_brk_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dest_brk =\t%" PRIx8 "\t()\n", ioat_dma_desc_ctrl_dest_brk_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bundle =\t%" PRIx8 "\t()\n", ioat_dma_desc_ctrl_bundle_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dest_dca =\t%" PRIx8 "\t()\n", ioat_dma_desc_ctrl_dest_dca_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " hint =\t%" PRIx8 "\t()\n", ioat_dma_desc_ctrl_hint_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " op =\t%" PRIx8 "\t(OP Code to execute)\n", ioat_dma_desc_ctrl_op_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Data type: ioat_dma_desc_t
 * Description: IOAT DMA Descriptor
 * Fields:
 *   size	(size 32, offset 0, init 0):	RW	Size of the transfer
 *   ctrl	(size 32, offset 32, init 0):	RW	Descriptor control field
 *   src	(size 64, offset 64, init 0):	RW	Physical address of the source
 *   dst	(size 64, offset 128, init 0):	RW	Physical address of the destination
 *   next	(size 64, offset 192, init 0):	RW	Physical address of the next descriptor
 *   _anon256	(size 64, offset 256, init 0):	RSVD	_
 *   _anon320	(size 64, offset 320, init 0):	RSVD	_
 *   user1	(size 64, offset 384, init 0):	RW	
 *   user2	(size 64, offset 448, init 0):	RW	
 */
typedef uint8_t *ioat_dma_desc_t;
typedef uint8_t ioat_dma_desc_array_t[64];
static const size_t ioat_dma_desc_size = sizeof(ioat_dma_desc_array_t );
static inline uint32_t ioat_dma_desc_size_extract(ioat_dma_desc_t _dtptr) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_desc_size_extract(ioat_dma_desc_t _dtptr)
{
    return(((*((uint32_t *)(0 + _dtptr))) & 0xffffffff) >> 0);
}

static inline void ioat_dma_desc_size_insert(ioat_dma_desc_t _dtptr, uint32_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_size_insert(ioat_dma_desc_t _dtptr, uint32_t _fieldval)
{
    *((uint32_t *)(0 + _dtptr)) = (((*((uint32_t *)(0 + _dtptr))) & 0x0) | (0xffffffff & (_fieldval << 0)));
}

static inline uint32_t ioat_dma_desc_ctrl_extract(ioat_dma_desc_t _dtptr) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_desc_ctrl_extract(ioat_dma_desc_t _dtptr)
{
    return(((*((uint32_t *)(4 + _dtptr))) & 0xffffffff) >> 0);
}

static inline void ioat_dma_desc_ctrl_insert(ioat_dma_desc_t _dtptr, uint32_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_ctrl_insert(ioat_dma_desc_t _dtptr, uint32_t _fieldval)
{
    *((uint32_t *)(4 + _dtptr)) = (((*((uint32_t *)(4 + _dtptr))) & 0x0) | (0xffffffff & (_fieldval << 0)));
}

static inline uint64_t ioat_dma_desc_src_extract(ioat_dma_desc_t _dtptr) __attribute__ ((always_inline));
static inline uint64_t ioat_dma_desc_src_extract(ioat_dma_desc_t _dtptr)
{
    return(((*((uint64_t *)(8 + _dtptr))) & 0xffffffffffffffff) >> 0);
}

static inline void ioat_dma_desc_src_insert(ioat_dma_desc_t _dtptr, uint64_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_src_insert(ioat_dma_desc_t _dtptr, uint64_t _fieldval)
{
    *((uint64_t *)(8 + _dtptr)) = (((*((uint64_t *)(8 + _dtptr))) & 0x0) | (0xffffffffffffffff & (_fieldval << 0)));
}

static inline uint64_t ioat_dma_desc_dst_extract(ioat_dma_desc_t _dtptr) __attribute__ ((always_inline));
static inline uint64_t ioat_dma_desc_dst_extract(ioat_dma_desc_t _dtptr)
{
    return(((*((uint64_t *)(16 + _dtptr))) & 0xffffffffffffffff) >> 0);
}

static inline void ioat_dma_desc_dst_insert(ioat_dma_desc_t _dtptr, uint64_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_dst_insert(ioat_dma_desc_t _dtptr, uint64_t _fieldval)
{
    *((uint64_t *)(16 + _dtptr)) = (((*((uint64_t *)(16 + _dtptr))) & 0x0) | (0xffffffffffffffff & (_fieldval << 0)));
}

static inline uint64_t ioat_dma_desc_next_extract(ioat_dma_desc_t _dtptr) __attribute__ ((always_inline));
static inline uint64_t ioat_dma_desc_next_extract(ioat_dma_desc_t _dtptr)
{
    return(((*((uint64_t *)(24 + _dtptr))) & 0xffffffffffffffff) >> 0);
}

static inline void ioat_dma_desc_next_insert(ioat_dma_desc_t _dtptr, uint64_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_next_insert(ioat_dma_desc_t _dtptr, uint64_t _fieldval)
{
    *((uint64_t *)(24 + _dtptr)) = (((*((uint64_t *)(24 + _dtptr))) & 0x0) | (0xffffffffffffffff & (_fieldval << 0)));
}

static inline uint64_t ioat_dma_desc_user1_extract(ioat_dma_desc_t _dtptr) __attribute__ ((always_inline));
static inline uint64_t ioat_dma_desc_user1_extract(ioat_dma_desc_t _dtptr)
{
    return(((*((uint64_t *)(48 + _dtptr))) & 0xffffffffffffffff) >> 0);
}

static inline void ioat_dma_desc_user1_insert(ioat_dma_desc_t _dtptr, uint64_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_user1_insert(ioat_dma_desc_t _dtptr, uint64_t _fieldval)
{
    *((uint64_t *)(48 + _dtptr)) = (((*((uint64_t *)(48 + _dtptr))) & 0x0) | (0xffffffffffffffff & (_fieldval << 0)));
}

static inline uint64_t ioat_dma_desc_user2_extract(ioat_dma_desc_t _dtptr) __attribute__ ((always_inline));
static inline uint64_t ioat_dma_desc_user2_extract(ioat_dma_desc_t _dtptr)
{
    return(((*((uint64_t *)(56 + _dtptr))) & 0xffffffffffffffff) >> 0);
}

static inline void ioat_dma_desc_user2_insert(ioat_dma_desc_t _dtptr, uint64_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_desc_user2_insert(ioat_dma_desc_t _dtptr, uint64_t _fieldval)
{
    *((uint64_t *)(56 + _dtptr)) = (((*((uint64_t *)(56 + _dtptr))) & 0x0) | (0xffffffffffffffff & (_fieldval << 0)));
}

static inline int ioat_dma_desc_prtval(char *_s, size_t _size, ioat_dma_desc_t _regval) __attribute__ ((always_inline));
static inline int ioat_dma_desc_prtval(char *_s, size_t _size, ioat_dma_desc_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " size =\t%" PRIx32 "\t(Size of the transfer)\n", ioat_dma_desc_size_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ctrl =\t%" PRIx32 "\t(Descriptor control field)\n", ioat_dma_desc_ctrl_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " src =\t%" PRIx64 "\t(Physical address of the source)\n", ioat_dma_desc_src_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dst =\t%" PRIx64 "\t(Physical address of the destination)\n", ioat_dma_desc_dst_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " next =\t%" PRIx64 "\t(Physical address of the next descriptor)\n", ioat_dma_desc_next_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " user1 =\t%" PRIx64 "\t()\n", ioat_dma_desc_user1_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " user2 =\t%" PRIx64 "\t()\n", ioat_dma_desc_user2_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Device representation structure
 */
struct __DN(t) {
    mackerel_addr_t cfg_base;
    mackerel_addr_t bar;
};
typedef struct __DN(t) __DN(t);

/*
 * Initial register values (currently 0)
 */
enum ioat_dma_initials {
    ioat_dma_vid_initial = 0x0,
    ioat_dma_did_initial = 0x0,
    ioat_dma_pcicmd_initial = 0x0,
    ioat_dma_pcists_initial = 0x0,
    ioat_dma_rid_ccr_initial = 0x0,
    ioat_dma_clsr_initial = 0x0,
    ioat_dma_hdr_initial = 0x0,
    ioat_dma_cb_bar_initial = 0x0,
    ioat_dma_svid_initial = 0x0,
    ioat_dma_sdid_initial = 0x0,
    ioat_dma_capptr_initial = 0x0,
    ioat_dma_intl_initial = 0x0,
    ioat_dma_intpin_initial = 0x0,
    ioat_dma_devcfg_initial = 0x0,
    ioat_dma_msixcapid_initial = 0x0,
    ioat_dma_msixnxtptr_initial = 0x0,
    ioat_dma_msixmsgctl_initial = 0x0,
    ioat_dma_tableoff_bir_initial = 0x0,
    ioat_dma_pbaoff_bir_initial = 0x0,
    ioat_dma_capid_initial = 0x0,
    ioat_dma_nextptr_initial = 0x0,
    ioat_dma_expcap_initial = 0x0,
    ioat_dma_devcap_initial = 0x0,
    ioat_dma_devcon_initial = 0x0,
    ioat_dma_devsts_initial = 0x0,
    ioat_dma_devcap2_initial = 0x0,
    ioat_dma_devcon2_initial = 0x0,
    ioat_dma_pmcap_initial = 0x0,
    ioat_dma_pmcsr_initial = 0x0,
    ioat_dma_dmauncerrsts_initial = 0x0,
    ioat_dma_dmauncerrmsk_initial = 0x0,
    ioat_dma_dmauncerrsev_initial = 0x0,
    ioat_dma_dmauncerrptr_initial = 0x0,
    ioat_dma_dmaglberrptr_initial = 0x0,
    ioat_dma_chanerr_int_initial = 0x0,
    ioat_dma_chanerrmsk_int_initial = 0x0,
    ioat_dma_chanerrsev_int_initial = 0x0,
    ioat_dma_chanerrptr_initial = 0x0,
    ioat_dma_chancnt_initial = 0x0,
    ioat_dma_xfercap_initial = 0x0,
    ioat_dma_genctrl_initial = 0x0,
    ioat_dma_intrctrl_initial = 0x0,
    ioat_dma_attnstatus_initial = 0x0,
    ioat_dma_cbver_initial = 0x0,
    ioat_dma_intrdelay_initial = 0x0,
    ioat_dma_cs_status_initial = 0x0,
    ioat_dma_dmacapability_initial = 0x0,
    ioat_dma_dcaoffset_initial = 0x0,
    ioat_dma_cbprio_initial = 0x0,
    ioat_dma_chanctrl_initial = 0x0,
    ioat_dma_dma_comp_initial = 0x0,
    ioat_dma_chancmd_initial = 0x0,
    ioat_dma_dmacount_initial = 0x0,
    ioat_dma_chansts_lo_initial = 0x0,
    ioat_dma_chansts_hi_initial = 0x0,
    ioat_dma_chainaddr_lo_initial = 0x0,
    ioat_dma_chainaddr_hi_initial = 0x0,
    ioat_dma_chancmp_lo_initial = 0x0,
    ioat_dma_chancmp_hi_initial = 0x0,
    ioat_dma_chanerr_initial = 0x0,
    ioat_dma_chanerrmsk_initial = 0x0,
    ioat_dma_dcactrl_initial = 0x0,
    ioat_dma_dca_ver_initial = 0x0,
    ioat_dma_dca_reqid_offset_initial = 0x0,
    ioat_dma_csi_capability_initial = 0x0,
    ioat_dma_pcie_capability_initial = 0x0,
    ioat_dma_csi_cap_enable_initial = 0x0,
    ioat_dma_pcie_cap_enable_initial = 0x0,
    ioat_dma_apicid_tag_map_initial = 0x0,
    ioat_dma_dca_reqid0_initial = 0x0,
    ioat_dma_dca_reqid1_initial = 0x0,
    ioat_dma_msgaddr_lo_initial = 0x0,
    ioat_dma_msgaddr_hi_initial = 0x0,
    ioat_dma_msgdata_initial = 0x0,
    ioat_dma_vecctrl_initial = 0x0,
    ioat_dma_pendingbits_initial = 0x0
};

/*
 * Device Initialization function
 */
static inline void ioat_dma_initialize(__DN(t) *_dev, mackerel_addr_t cfg_base, mackerel_addr_t bar) __attribute__ ((always_inline));
static inline void ioat_dma_initialize(__DN(t) *_dev, mackerel_addr_t cfg_base, mackerel_addr_t bar)
{
    _dev->cfg_base = cfg_base;
    _dev->bar = bar;
}

/*
 * Register vid: Vendor Identification Number (0x8086)
 * Type: ioat_dma.uint16 (primitive type)
 */
static inline uint16_t ioat_dma_vid_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_vid_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x0));
}

static inline uint16_t ioat_dma_vid_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_vid_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x0));
}

static inline void ioat_dma_vid_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_vid_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x0, _regval);
}

// Register vid is not writeable
static inline int ioat_dma_vid_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_vid_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x0);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register vid (Vendor Identification Number (0x8086)): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register did: Device Identification Number
 * Type: ioat_dma.did (Implicit type of Device Identification Number register)
 *   function	(size 8, offset 0, init 0):	RO	Function number: 0-7
 *   devid	(size 8, offset 8, init 0):	RO	Device ID always 0x0E
 */
static inline ioat_dma_did_t ioat_dma_did_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_did_t ioat_dma_did_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x2));
}

static inline ioat_dma_did_t ioat_dma_did_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_did_t ioat_dma_did_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x2));
}

static inline void ioat_dma_did_rawwr(__DN(t) *_dev, ioat_dma_did_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_did_rawwr(__DN(t) *_dev, ioat_dma_did_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x2, _regval);
}

// Register did is not writeable
static inline int ioat_dma_did_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_did_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_did_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x2);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register did (Device Identification Number): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " function =\t%" PRIx8 "\t(Function number: 0-7)\n", ioat_dma_did_function_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " devid =\t%" PRIx8 "\t(Device ID always 0x0E)\n", ioat_dma_did_devid_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_did_function_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_did_function_rdf(__DN(t) *_dev)
{
    ioat_dma_did_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x2);
    return(ioat_dma_did_function_extract(_regval));
}

static inline uint8_t ioat_dma_did_devid_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_did_devid_rdf(__DN(t) *_dev)
{
    ioat_dma_did_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x2);
    return(ioat_dma_did_devid_extract(_regval));
}

/*
 * Register pcicmd: PCI Command Register
 * Type: ioat_dma.pcicmd (Implicit type of PCI Command Register register)
 *   iose	(size 1, offset 0, init 0):	RO	
 *   mse	(size 1, offset 1, init 0):	RW	
 *   bme	(size 1, offset 2, init 0):	RW	
 *   sce	(size 1, offset 3, init 0):	RO	
 *   mwie	(size 1, offset 4, init 0):	RO	
 *   _anon5	(size 1, offset 5, init 0):	RSVD	_
 *   perre	(size 1, offset 6, init 0):	RO	
 *   _anon7	(size 1, offset 7, init 0):	RSVD	_
 *   serre	(size 1, offset 8, init 0):	RO	
 *   _anon9	(size 1, offset 9, init 0):	RSVD	_
 *   intx_disable	(size 1, offset 10, init 0):	RW	
 *   _anon11	(size 5, offset 11, init 0):	RSVD	_
 */
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x4));
}

static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pcicmd_t ioat_dma_pcicmd_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x4));
}

static inline void ioat_dma_pcicmd_rawwr(__DN(t) *_dev, ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pcicmd_rawwr(__DN(t) *_dev, ioat_dma_pcicmd_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x4, _regval);
}

static inline void ioat_dma_pcicmd_wr(__DN(t) *_dev, ioat_dma_pcicmd_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pcicmd_wr(__DN(t) *_dev, ioat_dma_pcicmd_t _regval)
{
    _regval = (_regval & 0x55f);
    // No MB1 fields present
    _regval = (_regval | (0xfaa0 & mackerel_read_addr_16(_dev->cfg_base, 0x4)));
    mackerel_write_addr_16(_dev->cfg_base, 0x4, _regval);
}

static inline int ioat_dma_pcicmd_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_pcicmd_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_pcicmd_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x4);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register pcicmd (PCI Command Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " iose =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_iose_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mse =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_mse_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bme =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_bme_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " sce =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_sce_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mwie =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_mwie_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon5 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " perre =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_perre_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon7 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " serre =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_serre_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon9 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intx_disable =\t%" PRIx8 "\t()\n", ioat_dma_pcicmd_intx_disable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon11 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_pcicmd_iose_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_iose_rdf(__DN(t) *_dev)
{
    ioat_dma_pcicmd_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x4);
    return(ioat_dma_pcicmd_iose_extract(_regval));
}

static inline uint8_t ioat_dma_pcicmd_mse_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_mse_rdf(__DN(t) *_dev)
{
    ioat_dma_pcicmd_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x4);
    return(ioat_dma_pcicmd_mse_extract(_regval));
}

static inline uint8_t ioat_dma_pcicmd_bme_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_bme_rdf(__DN(t) *_dev)
{
    ioat_dma_pcicmd_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x4);
    return(ioat_dma_pcicmd_bme_extract(_regval));
}

static inline uint8_t ioat_dma_pcicmd_sce_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_sce_rdf(__DN(t) *_dev)
{
    ioat_dma_pcicmd_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x4);
    return(ioat_dma_pcicmd_sce_extract(_regval));
}

static inline uint8_t ioat_dma_pcicmd_mwie_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_mwie_rdf(__DN(t) *_dev)
{
    ioat_dma_pcicmd_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x4);
    return(ioat_dma_pcicmd_mwie_extract(_regval));
}

static inline uint8_t ioat_dma_pcicmd_perre_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_perre_rdf(__DN(t) *_dev)
{
    ioat_dma_pcicmd_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x4);
    return(ioat_dma_pcicmd_perre_extract(_regval));
}

static inline uint8_t ioat_dma_pcicmd_serre_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_serre_rdf(__DN(t) *_dev)
{
    ioat_dma_pcicmd_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x4);
    return(ioat_dma_pcicmd_serre_extract(_regval));
}

static inline uint8_t ioat_dma_pcicmd_intx_disable_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcicmd_intx_disable_rdf(__DN(t) *_dev)
{
    ioat_dma_pcicmd_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x4);
    return(ioat_dma_pcicmd_intx_disable_extract(_regval));
}

static inline void ioat_dma_pcicmd_mse_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_pcicmd_mse_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_pcicmd_t _regval = 0x2 & (((ioat_dma_pcicmd_t )(_fieldval)) << 1);
    _regval = (_regval | (0xfea4 & mackerel_read_addr_16(_dev->cfg_base, 0x4)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x4, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_pcicmd_bme_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_pcicmd_bme_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_pcicmd_t _regval = 0x4 & (((ioat_dma_pcicmd_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfea2 & mackerel_read_addr_16(_dev->cfg_base, 0x4)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x4, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_pcicmd_intx_disable_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_pcicmd_intx_disable_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_pcicmd_t _regval = 0x400 & (((ioat_dma_pcicmd_t )(_fieldval)) << 10);
    _regval = (_regval | (0xfaa6 & mackerel_read_addr_16(_dev->cfg_base, 0x4)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x4, _regval);
    // No shadow register to write to
}

/*
 * Register pcists: PCI Status Register
 * Type: ioat_dma.pcists (Implicit type of PCI Status Register register)
 *   _anon0	(size 3, offset 0, init 0):	RSVD	_
 *   intxsts	(size 1, offset 3, init 0):	RO	
 *   caplist	(size 1, offset 4, init 0):	RO	indicates the presence of a capabilities list structure
 *   _anon5	(size 3, offset 5, init 0):	RSVD	_
 *   mdpe	(size 1, offset 8, init 0):	RWC	
 *   _anon9	(size 2, offset 9, init 0):	RSVD	_
 *   sta	(size 1, offset 11, init 0):	RWC	
 *   rta	(size 1, offset 12, init 0):	RO	
 *   rma	(size 1, offset 13, init 0):	RO	
 *   sse	(size 1, offset 14, init 0):	RO	
 *   dpe	(size 1, offset 15, init 0):	RWC	
 */
static inline ioat_dma_pcists_t ioat_dma_pcists_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pcists_t ioat_dma_pcists_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x6));
}

static inline ioat_dma_pcists_t ioat_dma_pcists_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pcists_t ioat_dma_pcists_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x6));
}

static inline void ioat_dma_pcists_rawwr(__DN(t) *_dev, ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pcists_rawwr(__DN(t) *_dev, ioat_dma_pcists_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x6, _regval);
}

static inline void ioat_dma_pcists_wr(__DN(t) *_dev, ioat_dma_pcists_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pcists_wr(__DN(t) *_dev, ioat_dma_pcists_t _regval)
{
    _regval = (_regval & 0xf918);
    // No MB1 fields present
    _regval = (_regval | (0x6e7 & mackerel_read_addr_16(_dev->cfg_base, 0x6)));
    mackerel_write_addr_16(_dev->cfg_base, 0x6, _regval);
}

static inline int ioat_dma_pcists_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_pcists_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_pcists_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x6);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register pcists (PCI Status Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon0 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intxsts =\t%" PRIx8 "\t()\n", ioat_dma_pcists_intxsts_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " caplist =\t%" PRIx8 "\t(indicates the presence of a capabilities list structure)\n", ioat_dma_pcists_caplist_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon5 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mdpe =\t%" PRIx8 "\t()\n", ioat_dma_pcists_mdpe_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon9 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " sta =\t%" PRIx8 "\t()\n", ioat_dma_pcists_sta_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rta =\t%" PRIx8 "\t()\n", ioat_dma_pcists_rta_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rma =\t%" PRIx8 "\t()\n", ioat_dma_pcists_rma_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " sse =\t%" PRIx8 "\t()\n", ioat_dma_pcists_sse_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dpe =\t%" PRIx8 "\t()\n", ioat_dma_pcists_dpe_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_pcists_intxsts_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_intxsts_rdf(__DN(t) *_dev)
{
    ioat_dma_pcists_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x6);
    return(ioat_dma_pcists_intxsts_extract(_regval));
}

static inline uint8_t ioat_dma_pcists_caplist_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_caplist_rdf(__DN(t) *_dev)
{
    ioat_dma_pcists_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x6);
    return(ioat_dma_pcists_caplist_extract(_regval));
}

static inline uint8_t ioat_dma_pcists_mdpe_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_mdpe_rdf(__DN(t) *_dev)
{
    ioat_dma_pcists_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x6);
    return(ioat_dma_pcists_mdpe_extract(_regval));
}

static inline uint8_t ioat_dma_pcists_sta_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_sta_rdf(__DN(t) *_dev)
{
    ioat_dma_pcists_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x6);
    return(ioat_dma_pcists_sta_extract(_regval));
}

static inline uint8_t ioat_dma_pcists_rta_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_rta_rdf(__DN(t) *_dev)
{
    ioat_dma_pcists_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x6);
    return(ioat_dma_pcists_rta_extract(_regval));
}

static inline uint8_t ioat_dma_pcists_rma_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_rma_rdf(__DN(t) *_dev)
{
    ioat_dma_pcists_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x6);
    return(ioat_dma_pcists_rma_extract(_regval));
}

static inline uint8_t ioat_dma_pcists_sse_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_sse_rdf(__DN(t) *_dev)
{
    ioat_dma_pcists_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x6);
    return(ioat_dma_pcists_sse_extract(_regval));
}

static inline uint8_t ioat_dma_pcists_dpe_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcists_dpe_rdf(__DN(t) *_dev)
{
    ioat_dma_pcists_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x6);
    return(ioat_dma_pcists_dpe_extract(_regval));
}

static inline void ioat_dma_pcists_mdpe_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_pcists_mdpe_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_pcists_t _regval = 0x100 & (((ioat_dma_pcists_t )(_fieldval)) << 8);
    _regval = (_regval | (0x6e7 & mackerel_read_addr_16(_dev->cfg_base, 0x6)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x6, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_pcists_sta_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_pcists_sta_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_pcists_t _regval = 0x800 & (((ioat_dma_pcists_t )(_fieldval)) << 11);
    _regval = (_regval | (0x6e7 & mackerel_read_addr_16(_dev->cfg_base, 0x6)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x6, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_pcists_dpe_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_pcists_dpe_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_pcists_t _regval = 0x8000 & (((ioat_dma_pcists_t )(_fieldval)) << 15);
    _regval = (_regval | (0x6e7 & mackerel_read_addr_16(_dev->cfg_base, 0x6)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x6, _regval);
    // No shadow register to write to
}

/*
 * Register rid_ccr: Revision ID and PCI Class
 * Type: ioat_dma.rid_ccr (Implicit type of Revision ID and PCI Class register)
 *   rid	(size 8, offset 0, init 0):	RO	Revision ID
 *   rlpi	(size 8, offset 8, init 0):	RO	Register level programming interface (set to 00)
 *   subclass	(size 8, offset 16, init 0):	RO	Sub class: Generic device
 *   class	(size 8, offset 24, init 0):	RO	Base class: Generic device
 */
static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x8));
}

static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_rid_ccr_t ioat_dma_rid_ccr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x8));
}

static inline void ioat_dma_rid_ccr_rawwr(__DN(t) *_dev, ioat_dma_rid_ccr_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_rid_ccr_rawwr(__DN(t) *_dev, ioat_dma_rid_ccr_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0x8, _regval);
}

// Register rid_ccr is not writeable
static inline int ioat_dma_rid_ccr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_rid_ccr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_rid_ccr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x8);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register rid_ccr (Revision ID and PCI Class): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rid =\t%" PRIx8 "\t(Revision ID)\n", ioat_dma_rid_ccr_rid_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rlpi =\t%" PRIx8 "\t(Register level programming interface (set to 00))\n", ioat_dma_rid_ccr_rlpi_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " subclass =\t%" PRIx8 "\t(Sub class: Generic device)\n", ioat_dma_rid_ccr_subclass_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " class =\t%" PRIx8 "\t(Base class: Generic device)\n", ioat_dma_rid_ccr_class_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_rid_ccr_rid_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_rid_ccr_rid_rdf(__DN(t) *_dev)
{
    ioat_dma_rid_ccr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x8);
    return(ioat_dma_rid_ccr_rid_extract(_regval));
}

static inline uint8_t ioat_dma_rid_ccr_rlpi_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_rid_ccr_rlpi_rdf(__DN(t) *_dev)
{
    ioat_dma_rid_ccr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x8);
    return(ioat_dma_rid_ccr_rlpi_extract(_regval));
}

static inline uint8_t ioat_dma_rid_ccr_subclass_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_rid_ccr_subclass_rdf(__DN(t) *_dev)
{
    ioat_dma_rid_ccr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x8);
    return(ioat_dma_rid_ccr_subclass_extract(_regval));
}

static inline uint8_t ioat_dma_rid_ccr_class_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_rid_ccr_class_rdf(__DN(t) *_dev)
{
    ioat_dma_rid_ccr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x8);
    return(ioat_dma_rid_ccr_class_extract(_regval));
}

/*
 * Register clsr: Cache Line Size (always 64b)
 * Type: ioat_dma.uint8 (primitive type)
 */
static inline uint8_t ioat_dma_clsr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_clsr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0xc));
}

static inline uint8_t ioat_dma_clsr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_clsr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0xc));
}

static inline void ioat_dma_clsr_rawwr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_clsr_rawwr(__DN(t) *_dev, uint8_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0xc, _regval);
}

// Register clsr is not writeable
static inline int ioat_dma_clsr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_clsr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint8_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0xc);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register clsr (Cache Line Size (always 64b)): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx8 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register hdr: PCI Header Register
 * Type: ioat_dma.hdr (Implicit type of PCI Header Register register)
 *   _anon0	(size 6, offset 0, init 0):	RSVD	_
 *   cfglayout	(size 1, offset 6, init 0):	RO	Configuration layout (always 0, endpoint)
 *   mfd	(size 1, offset 7, init 0):	RO	Multifunction device (always 1)
 */
static inline ioat_dma_hdr_t ioat_dma_hdr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_hdr_t ioat_dma_hdr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0xe));
}

static inline ioat_dma_hdr_t ioat_dma_hdr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_hdr_t ioat_dma_hdr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0xe));
}

static inline void ioat_dma_hdr_rawwr(__DN(t) *_dev, ioat_dma_hdr_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_hdr_rawwr(__DN(t) *_dev, ioat_dma_hdr_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0xe, _regval);
}

// Register hdr is not writeable
static inline int ioat_dma_hdr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_hdr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_hdr_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0xe);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register hdr (PCI Header Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon0 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cfglayout =\t%" PRIx8 "\t(Configuration layout (always 0, endpoint))\n", ioat_dma_hdr_cfglayout_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mfd =\t%" PRIx8 "\t(Multifunction device (always 1))\n", ioat_dma_hdr_mfd_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_hdr_cfglayout_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_hdr_cfglayout_rdf(__DN(t) *_dev)
{
    ioat_dma_hdr_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0xe);
    return(ioat_dma_hdr_cfglayout_extract(_regval));
}

static inline uint8_t ioat_dma_hdr_mfd_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_hdr_mfd_rdf(__DN(t) *_dev)
{
    ioat_dma_hdr_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0xe);
    return(ioat_dma_hdr_mfd_extract(_regval));
}

/*
 * Register cb_bar: Crystal Beach Base Address Register
 * Type: ioat_dma.cb_bar (Implicit type of Crystal Beach Base Address Register register)
 *   memspace	(size 1, offset 0, init 0):	RO	This Base Address Register indicates memory space.
 *   bartype	(size 2, offset 1, init 0):	RO	The DMA registers is 64-bit address space
 *   prefetch	(size 1, offset 3, init 0):	RO	DMA registers are non-prefetchable (always 0)
 *   _anon4	(size 10, offset 4, init 0):	RSVD	_
 *   bar	(size 50, offset 14, init 0):	RW	16 KB aligned 64-bit base address for MMIO regs
 */
static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_64(_dev->cfg_base, 0x10));
}

static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_cb_bar_t ioat_dma_cb_bar_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_64(_dev->cfg_base, 0x10));
}

static inline void ioat_dma_cb_bar_rawwr(__DN(t) *_dev, ioat_dma_cb_bar_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_cb_bar_rawwr(__DN(t) *_dev, ioat_dma_cb_bar_t _regval)
{
    mackerel_write_addr_64(_dev->cfg_base, 0x10, _regval);
}

static inline void ioat_dma_cb_bar_wr(__DN(t) *_dev, ioat_dma_cb_bar_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_cb_bar_wr(__DN(t) *_dev, ioat_dma_cb_bar_t _regval)
{
    _regval = (_regval & 0xffffffffffffc00f);
    // No MB1 fields present
    _regval = (_regval | (0x3ff0 & mackerel_read_addr_64(_dev->cfg_base, 0x10)));
    mackerel_write_addr_64(_dev->cfg_base, 0x10, _regval);
}

static inline int ioat_dma_cb_bar_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_cb_bar_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_cb_bar_t _regval = mackerel_read_addr_64(_dev->cfg_base, 0x10);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register cb_bar (Crystal Beach Base Address Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " memspace =\t%" PRIx8 "\t(This Base Address Register indicates memory space.)\n", ioat_dma_cb_bar_memspace_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bartype =\t%" PRIx8 "\t(The DMA registers is 64-bit address space)\n", ioat_dma_cb_bar_bartype_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " prefetch =\t%" PRIx8 "\t(DMA registers are non-prefetchable (always 0))\n", ioat_dma_cb_bar_prefetch_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon4 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bar =\t%" PRIx64 "\t(16 KB aligned 64-bit base address for MMIO regs)\n", ioat_dma_cb_bar_bar_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_cb_bar_memspace_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cb_bar_memspace_rdf(__DN(t) *_dev)
{
    ioat_dma_cb_bar_t _regval = mackerel_read_addr_64(_dev->cfg_base, 0x10);
    return(ioat_dma_cb_bar_memspace_extract(_regval));
}

static inline uint8_t ioat_dma_cb_bar_bartype_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cb_bar_bartype_rdf(__DN(t) *_dev)
{
    ioat_dma_cb_bar_t _regval = mackerel_read_addr_64(_dev->cfg_base, 0x10);
    return(ioat_dma_cb_bar_bartype_extract(_regval));
}

static inline uint8_t ioat_dma_cb_bar_prefetch_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cb_bar_prefetch_rdf(__DN(t) *_dev)
{
    ioat_dma_cb_bar_t _regval = mackerel_read_addr_64(_dev->cfg_base, 0x10);
    return(ioat_dma_cb_bar_prefetch_extract(_regval));
}

static inline uint64_t ioat_dma_cb_bar_bar_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint64_t ioat_dma_cb_bar_bar_rdf(__DN(t) *_dev)
{
    ioat_dma_cb_bar_t _regval = mackerel_read_addr_64(_dev->cfg_base, 0x10);
    return(ioat_dma_cb_bar_bar_extract(_regval));
}

static inline void ioat_dma_cb_bar_bar_wrf(__DN(t) *_dev, uint64_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_cb_bar_bar_wrf(__DN(t) *_dev, uint64_t _fieldval)
{
    ioat_dma_cb_bar_t _regval = 0xffffffffffffc000 & (((ioat_dma_cb_bar_t )(_fieldval)) << 14);
    _regval = (_regval | (0x3ff0 & mackerel_read_addr_64(_dev->cfg_base, 0x10)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_64(_dev->cfg_base, 0x10, _regval);
    // No shadow register to write to
}

/*
 * Register svid: Vendor Identification Number (0x8086)
 * Type: ioat_dma.uint16 (primitive type)
 */
static inline uint16_t ioat_dma_svid_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_svid_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x2c));
}

static inline uint16_t ioat_dma_svid_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_svid_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x2c));
}

static inline void ioat_dma_svid_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_svid_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x2c, _regval);
}

// Register svid is not writeable
static inline int ioat_dma_svid_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_svid_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x2c);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register svid (Vendor Identification Number (0x8086)): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register sdid: Subsystem Identification Number
 * Type: ioat_dma.uint16 (primitive type)
 */
static inline uint16_t ioat_dma_sdid_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_sdid_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x2e));
}

static inline uint16_t ioat_dma_sdid_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_sdid_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x2e));
}

static inline void ioat_dma_sdid_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_sdid_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x2e, _regval);
}

// Register sdid is not writeable
static inline int ioat_dma_sdid_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_sdid_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x2e);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register sdid (Subsystem Identification Number): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register capptr: Capability Pointer (first cap structure)
 * Type: ioat_dma.uint8 (primitive type)
 */
static inline uint8_t ioat_dma_capptr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_capptr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x34));
}

static inline uint8_t ioat_dma_capptr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_capptr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x34));
}

static inline void ioat_dma_capptr_rawwr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_capptr_rawwr(__DN(t) *_dev, uint8_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0x34, _regval);
}

// Register capptr is not writeable
static inline int ioat_dma_capptr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_capptr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint8_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x34);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register capptr (Capability Pointer (first cap structure)): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx8 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register intl: Interrupt Line (N/A)
 * Type: ioat_dma.uint8 (primitive type)
 */
static inline uint8_t ioat_dma_intl_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intl_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x3c));
}

static inline uint8_t ioat_dma_intl_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intl_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x3c));
}

static inline void ioat_dma_intl_rawwr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_intl_rawwr(__DN(t) *_dev, uint8_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0x3c, _regval);
}

static inline void ioat_dma_intl_wr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_intl_wr(__DN(t) *_dev, uint8_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_8(_dev->cfg_base, 0x3c, _regval);
}

static inline int ioat_dma_intl_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_intl_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint8_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x3c);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register intl (Interrupt Line (N/A)): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx8 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register intpin: Interrupt pin (Function dependent)
 * Type: ioat_dma.uint8 (primitive type)
 */
static inline uint8_t ioat_dma_intpin_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intpin_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x3d));
}

static inline uint8_t ioat_dma_intpin_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intpin_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x3d));
}

static inline void ioat_dma_intpin_rawwr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_intpin_rawwr(__DN(t) *_dev, uint8_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0x3d, _regval);
}

static inline void ioat_dma_intpin_wr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_intpin_wr(__DN(t) *_dev, uint8_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_8(_dev->cfg_base, 0x3d, _regval);
}

static inline int ioat_dma_intpin_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_intpin_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint8_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x3d);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register intpin (Interrupt pin (Function dependent)): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx8 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register devcfg: Device Configuration Register
 * Type: ioat_dma.devcfg (Implicit type of Device Configuration Register register)
 *   numrfo	(size 4, offset 0, init 0):	RW	Number of outstanding RFOs
 *   numrd	(size 4, offset 4, init 0):	RW	Number of outstanding requests
 *   _anon8	(size 1, offset 8, init 0):	RSVD	_
 *   no_snoop	(size 1, offset 9, init 0):	RW	Disable snooping (not recommendend)
 *   f0extop	(size 1, offset 10, init 0):	RW	switches in the Function 0 Device ID
 *   f1extop	(size 1, offset 11, init 0):	RW	switches in the Function 1 Device ID
 *   numrd_xor	(size 4, offset 12, init 0):	RW	Number of outstanding requests (set to 0 for max)
 */
static inline ioat_dma_devcfg_t ioat_dma_devcfg_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devcfg_t ioat_dma_devcfg_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x60));
}

static inline ioat_dma_devcfg_t ioat_dma_devcfg_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devcfg_t ioat_dma_devcfg_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x60));
}

static inline void ioat_dma_devcfg_rawwr(__DN(t) *_dev, ioat_dma_devcfg_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_devcfg_rawwr(__DN(t) *_dev, ioat_dma_devcfg_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x60, _regval);
}

static inline void ioat_dma_devcfg_wr(__DN(t) *_dev, ioat_dma_devcfg_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_devcfg_wr(__DN(t) *_dev, ioat_dma_devcfg_t _regval)
{
    _regval = (_regval & 0xfeff);
    // No MB1 fields present
    _regval = (_regval | (0x100 & mackerel_read_addr_16(_dev->cfg_base, 0x60)));
    mackerel_write_addr_16(_dev->cfg_base, 0x60, _regval);
}

static inline int ioat_dma_devcfg_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_devcfg_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_devcfg_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x60);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register devcfg (Device Configuration Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " numrfo =\t%" PRIx8 "\t(Number of outstanding RFOs)\n", ioat_dma_devcfg_numrfo_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " numrd =\t%" PRIx8 "\t(Number of outstanding requests)\n", ioat_dma_devcfg_numrd_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon8 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " no_snoop =\t%" PRIx8 "\t(Disable snooping (not recommendend))\n", ioat_dma_devcfg_no_snoop_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " f0extop =\t%" PRIx8 "\t(switches in the Function 0 Device ID)\n", ioat_dma_devcfg_f0extop_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " f1extop =\t%" PRIx8 "\t(switches in the Function 1 Device ID)\n", ioat_dma_devcfg_f1extop_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " numrd_xor =\t%" PRIx8 "\t(Number of outstanding requests (set to 0 for max))\n", ioat_dma_devcfg_numrd_xor_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_devcfg_numrfo_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_numrfo_rdf(__DN(t) *_dev)
{
    ioat_dma_devcfg_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x60);
    return(ioat_dma_devcfg_numrfo_extract(_regval));
}

static inline uint8_t ioat_dma_devcfg_numrd_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_numrd_rdf(__DN(t) *_dev)
{
    ioat_dma_devcfg_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x60);
    return(ioat_dma_devcfg_numrd_extract(_regval));
}

static inline uint8_t ioat_dma_devcfg_no_snoop_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_no_snoop_rdf(__DN(t) *_dev)
{
    ioat_dma_devcfg_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x60);
    return(ioat_dma_devcfg_no_snoop_extract(_regval));
}

static inline uint8_t ioat_dma_devcfg_f0extop_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_f0extop_rdf(__DN(t) *_dev)
{
    ioat_dma_devcfg_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x60);
    return(ioat_dma_devcfg_f0extop_extract(_regval));
}

static inline uint8_t ioat_dma_devcfg_f1extop_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_f1extop_rdf(__DN(t) *_dev)
{
    ioat_dma_devcfg_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x60);
    return(ioat_dma_devcfg_f1extop_extract(_regval));
}

static inline uint8_t ioat_dma_devcfg_numrd_xor_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcfg_numrd_xor_rdf(__DN(t) *_dev)
{
    ioat_dma_devcfg_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x60);
    return(ioat_dma_devcfg_numrd_xor_extract(_regval));
}

static inline void ioat_dma_devcfg_numrfo_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_devcfg_numrfo_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_devcfg_t _regval = 0xf & (((ioat_dma_devcfg_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfff0 & mackerel_read_addr_16(_dev->cfg_base, 0x60)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x60, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_devcfg_numrd_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_devcfg_numrd_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_devcfg_t _regval = 0xf0 & (((ioat_dma_devcfg_t )(_fieldval)) << 4);
    _regval = (_regval | (0xff0f & mackerel_read_addr_16(_dev->cfg_base, 0x60)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x60, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_devcfg_no_snoop_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_devcfg_no_snoop_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_devcfg_t _regval = 0x200 & (((ioat_dma_devcfg_t )(_fieldval)) << 9);
    _regval = (_regval | (0xfdff & mackerel_read_addr_16(_dev->cfg_base, 0x60)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x60, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_devcfg_f0extop_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_devcfg_f0extop_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_devcfg_t _regval = 0x400 & (((ioat_dma_devcfg_t )(_fieldval)) << 10);
    _regval = (_regval | (0xfbff & mackerel_read_addr_16(_dev->cfg_base, 0x60)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x60, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_devcfg_f1extop_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_devcfg_f1extop_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_devcfg_t _regval = 0x800 & (((ioat_dma_devcfg_t )(_fieldval)) << 11);
    _regval = (_regval | (0xf7ff & mackerel_read_addr_16(_dev->cfg_base, 0x60)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x60, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_devcfg_numrd_xor_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_devcfg_numrd_xor_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_devcfg_t _regval = 0xf000 & (((ioat_dma_devcfg_t )(_fieldval)) << 12);
    _regval = (_regval | (0xfff & mackerel_read_addr_16(_dev->cfg_base, 0x60)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x60, _regval);
    // No shadow register to write to
}

/*
 * Register msixcapid: MSI-X Capability ID
 * Type: ioat_dma.uint8 (primitive type)
 */
static inline uint8_t ioat_dma_msixcapid_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_msixcapid_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x80));
}

static inline uint8_t ioat_dma_msixcapid_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_msixcapid_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x80));
}

static inline void ioat_dma_msixcapid_rawwr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_msixcapid_rawwr(__DN(t) *_dev, uint8_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0x80, _regval);
}

// Register msixcapid is not writeable
static inline int ioat_dma_msixcapid_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_msixcapid_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint8_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x80);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register msixcapid (MSI-X Capability ID): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx8 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register msixnxtptr: MSI-X Next Pointer
 * Type: ioat_dma.uint8 (primitive type)
 */
static inline uint8_t ioat_dma_msixnxtptr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_msixnxtptr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x81));
}

static inline uint8_t ioat_dma_msixnxtptr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_msixnxtptr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x81));
}

static inline void ioat_dma_msixnxtptr_rawwr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_msixnxtptr_rawwr(__DN(t) *_dev, uint8_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0x81, _regval);
}

// Register msixnxtptr is not writeable
static inline int ioat_dma_msixnxtptr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_msixnxtptr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint8_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x81);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register msixnxtptr (MSI-X Next Pointer): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx8 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register msixmsgctl: MSI-X Message Control
 * Type: ioat_dma.msixmsgctl (Implicit type of MSI-X Message Control register)
 *   table_size	(size 11, offset 0, init 0):	RO	Table size of MSI-X
 *   _anon11	(size 3, offset 11, init 0):	RSVD	_
 *   function_mask	(size 1, offset 14, init 0):	RW	Vector mask control
 *   msi_x_en	(size 1, offset 15, init 0):	RW	Select MSI-X instead of INTx method
 */
static inline ioat_dma_msixmsgctl_t ioat_dma_msixmsgctl_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_msixmsgctl_t ioat_dma_msixmsgctl_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x82));
}

static inline ioat_dma_msixmsgctl_t ioat_dma_msixmsgctl_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_msixmsgctl_t ioat_dma_msixmsgctl_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x82));
}

static inline void ioat_dma_msixmsgctl_rawwr(__DN(t) *_dev, ioat_dma_msixmsgctl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_msixmsgctl_rawwr(__DN(t) *_dev, ioat_dma_msixmsgctl_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x82, _regval);
}

static inline void ioat_dma_msixmsgctl_wr(__DN(t) *_dev, ioat_dma_msixmsgctl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_msixmsgctl_wr(__DN(t) *_dev, ioat_dma_msixmsgctl_t _regval)
{
    _regval = (_regval & 0xc7ff);
    // No MB1 fields present
    _regval = (_regval | (0x3800 & mackerel_read_addr_16(_dev->cfg_base, 0x82)));
    mackerel_write_addr_16(_dev->cfg_base, 0x82, _regval);
}

static inline int ioat_dma_msixmsgctl_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_msixmsgctl_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_msixmsgctl_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x82);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register msixmsgctl (MSI-X Message Control): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " table_size =\t%" PRIx16 "\t(Table size of MSI-X)\n", ioat_dma_msixmsgctl_table_size_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon11 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " function_mask =\t%" PRIx8 "\t(Vector mask control)\n", ioat_dma_msixmsgctl_function_mask_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " msi_x_en =\t%" PRIx8 "\t(Select MSI-X instead of INTx method)\n", ioat_dma_msixmsgctl_msi_x_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint16_t ioat_dma_msixmsgctl_table_size_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_msixmsgctl_table_size_rdf(__DN(t) *_dev)
{
    ioat_dma_msixmsgctl_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x82);
    return(ioat_dma_msixmsgctl_table_size_extract(_regval));
}

static inline uint8_t ioat_dma_msixmsgctl_function_mask_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_msixmsgctl_function_mask_rdf(__DN(t) *_dev)
{
    ioat_dma_msixmsgctl_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x82);
    return(ioat_dma_msixmsgctl_function_mask_extract(_regval));
}

static inline uint8_t ioat_dma_msixmsgctl_msi_x_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_msixmsgctl_msi_x_en_rdf(__DN(t) *_dev)
{
    ioat_dma_msixmsgctl_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x82);
    return(ioat_dma_msixmsgctl_msi_x_en_extract(_regval));
}

static inline void ioat_dma_msixmsgctl_function_mask_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_msixmsgctl_function_mask_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_msixmsgctl_t _regval = 0x4000 & (((ioat_dma_msixmsgctl_t )(_fieldval)) << 14);
    _regval = (_regval | (0xb800 & mackerel_read_addr_16(_dev->cfg_base, 0x82)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x82, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_msixmsgctl_msi_x_en_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_msixmsgctl_msi_x_en_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_msixmsgctl_t _regval = 0x8000 & (((ioat_dma_msixmsgctl_t )(_fieldval)) << 15);
    _regval = (_regval | (0x7800 & mackerel_read_addr_16(_dev->cfg_base, 0x82)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x82, _regval);
    // No shadow register to write to
}

/*
 * Register tableoff_bir: MSI-X Table Offset and BAR Indicator
 * Type: ioat_dma.tableoff_bir (Implicit type of MSI-X Table Offset and BAR Indicator register)
 *   bir	(size 3, offset 0, init 0):	RO	Offset of the CB BAR in the Config Space
 *   offset	(size 29, offset 3, init 0):	RO	Offset of the MSI-X structure from the CB_BAR base
 */
static inline ioat_dma_tableoff_bir_t ioat_dma_tableoff_bir_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_tableoff_bir_t ioat_dma_tableoff_bir_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x84));
}

static inline ioat_dma_tableoff_bir_t ioat_dma_tableoff_bir_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_tableoff_bir_t ioat_dma_tableoff_bir_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x84));
}

static inline void ioat_dma_tableoff_bir_rawwr(__DN(t) *_dev, ioat_dma_tableoff_bir_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_tableoff_bir_rawwr(__DN(t) *_dev, ioat_dma_tableoff_bir_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0x84, _regval);
}

// Register tableoff_bir is not writeable
static inline int ioat_dma_tableoff_bir_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_tableoff_bir_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_tableoff_bir_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x84);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register tableoff_bir (MSI-X Table Offset and BAR Indicator): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bir =\t%" PRIx8 "\t(Offset of the CB BAR in the Config Space)\n", ioat_dma_tableoff_bir_bir_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " offset =\t%" PRIx32 "\t(Offset of the MSI-X structure from the CB_BAR base)\n", ioat_dma_tableoff_bir_offset_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_tableoff_bir_bir_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_tableoff_bir_bir_rdf(__DN(t) *_dev)
{
    ioat_dma_tableoff_bir_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x84);
    return(ioat_dma_tableoff_bir_bir_extract(_regval));
}

static inline uint32_t ioat_dma_tableoff_bir_offset_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_tableoff_bir_offset_rdf(__DN(t) *_dev)
{
    ioat_dma_tableoff_bir_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x84);
    return(ioat_dma_tableoff_bir_offset_extract(_regval));
}

/*
 * Register pbaoff_bir: MSI-X PBA Offset
 * Type: ioat_dma.pbaoff_bir (Implicit type of MSI-X PBA Offset register)
 *   bir	(size 3, offset 0, init 0):	RO	Offset of the CB BAR in the Config Space
 *   offset	(size 29, offset 3, init 0):	RO	Offset of the MSI-X PBA structure from the CB_BAR base
 */
static inline ioat_dma_pbaoff_bir_t ioat_dma_pbaoff_bir_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pbaoff_bir_t ioat_dma_pbaoff_bir_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x88));
}

static inline ioat_dma_pbaoff_bir_t ioat_dma_pbaoff_bir_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pbaoff_bir_t ioat_dma_pbaoff_bir_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x88));
}

static inline void ioat_dma_pbaoff_bir_rawwr(__DN(t) *_dev, ioat_dma_pbaoff_bir_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pbaoff_bir_rawwr(__DN(t) *_dev, ioat_dma_pbaoff_bir_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0x88, _regval);
}

// Register pbaoff_bir is not writeable
static inline int ioat_dma_pbaoff_bir_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_pbaoff_bir_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_pbaoff_bir_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x88);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register pbaoff_bir (MSI-X PBA Offset): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bir =\t%" PRIx8 "\t(Offset of the CB BAR in the Config Space)\n", ioat_dma_pbaoff_bir_bir_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " offset =\t%" PRIx32 "\t(Offset of the MSI-X PBA structure from the CB_BAR base)\n", ioat_dma_pbaoff_bir_offset_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_pbaoff_bir_bir_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pbaoff_bir_bir_rdf(__DN(t) *_dev)
{
    ioat_dma_pbaoff_bir_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x88);
    return(ioat_dma_pbaoff_bir_bir_extract(_regval));
}

static inline uint32_t ioat_dma_pbaoff_bir_offset_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_pbaoff_bir_offset_rdf(__DN(t) *_dev)
{
    ioat_dma_pbaoff_bir_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x88);
    return(ioat_dma_pbaoff_bir_offset_extract(_regval));
}

/*
 * Register capid: Capability ID
 * Type: ioat_dma.uint8 (primitive type)
 */
static inline uint8_t ioat_dma_capid_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_capid_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x90));
}

static inline uint8_t ioat_dma_capid_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_capid_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x90));
}

static inline void ioat_dma_capid_rawwr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_capid_rawwr(__DN(t) *_dev, uint8_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0x90, _regval);
}

// Register capid is not writeable
static inline int ioat_dma_capid_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_capid_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint8_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x90);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register capid (Capability ID): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx8 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register nextptr: Capability Next Pointer
 * Type: ioat_dma.uint8 (primitive type)
 */
static inline uint8_t ioat_dma_nextptr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_nextptr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x91));
}

static inline uint8_t ioat_dma_nextptr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_nextptr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x91));
}

static inline void ioat_dma_nextptr_rawwr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_nextptr_rawwr(__DN(t) *_dev, uint8_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0x91, _regval);
}

static inline void ioat_dma_nextptr_wr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_nextptr_wr(__DN(t) *_dev, uint8_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_8(_dev->cfg_base, 0x91, _regval);
}

static inline int ioat_dma_nextptr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_nextptr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint8_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x91);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register nextptr (Capability Next Pointer): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx8 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register expcap: PCI Express Device Type
 * Type: ioat_dma.expcap (Implicit type of PCI Express Device Type register)
 *   version	(size 4, offset 0, init 0):	RO	Version of the PCI Express capability structure
 *   port_type	(size 4, offset 4, init 0):	RO	Type of the Device
 *   slot_impl	(size 1, offset 8, init 0):	RO	N/A
 *   irq_msg_num	(size 5, offset 9, init 0):	RO	N/A
 *   _anon14	(size 2, offset 14, init 0):	RSVD	_
 */
static inline ioat_dma_expcap_t ioat_dma_expcap_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_expcap_t ioat_dma_expcap_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x92));
}

static inline ioat_dma_expcap_t ioat_dma_expcap_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_expcap_t ioat_dma_expcap_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x92));
}

static inline void ioat_dma_expcap_rawwr(__DN(t) *_dev, ioat_dma_expcap_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_expcap_rawwr(__DN(t) *_dev, ioat_dma_expcap_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x92, _regval);
}

// Register expcap is not writeable
static inline int ioat_dma_expcap_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_expcap_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_expcap_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x92);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register expcap (PCI Express Device Type): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " version =\t%" PRIx8 "\t(Version of the PCI Express capability structure)\n", ioat_dma_expcap_version_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " port_type =\t%" PRIx8 "\t(Type of the Device)\n", ioat_dma_expcap_port_type_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " slot_impl =\t%" PRIx8 "\t(N/A)\n", ioat_dma_expcap_slot_impl_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " irq_msg_num =\t%" PRIx8 "\t(N/A)\n", ioat_dma_expcap_irq_msg_num_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon14 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_expcap_version_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_expcap_version_rdf(__DN(t) *_dev)
{
    ioat_dma_expcap_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x92);
    return(ioat_dma_expcap_version_extract(_regval));
}

static inline uint8_t ioat_dma_expcap_port_type_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_expcap_port_type_rdf(__DN(t) *_dev)
{
    ioat_dma_expcap_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x92);
    return(ioat_dma_expcap_port_type_extract(_regval));
}

static inline uint8_t ioat_dma_expcap_slot_impl_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_expcap_slot_impl_rdf(__DN(t) *_dev)
{
    ioat_dma_expcap_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x92);
    return(ioat_dma_expcap_slot_impl_extract(_regval));
}

static inline uint8_t ioat_dma_expcap_irq_msg_num_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_expcap_irq_msg_num_rdf(__DN(t) *_dev)
{
    ioat_dma_expcap_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x92);
    return(ioat_dma_expcap_irq_msg_num_extract(_regval));
}

/*
 * Register devcap: PCI Express Device Capability Register
 * Type: ioat_dma.devcap (Implicit type of PCI Express Device Capability Register register)
 *   max_payload	(size 3, offset 0, init 0):	RO	Maximum PCIe payload size
 *   phantom	(size 2, offset 3, init 0):	RO	Phantom functions supported
 *   ext_tag	(size 1, offset 5, init 0):	RO	Extended tag supported
 *   ep_latency_0	(size 3, offset 6, init 0):	RO	Endpoint L0 acceptable latency
 *   ep_latency_1	(size 3, offset 9, init 0):	RO	Endpoint L1 acceptable latency
 *   att_btn	(size 1, offset 12, init 0):	RO	Attention button present on device
 *   att_ind	(size 1, offset 13, init 0):	RO	Attention indicator present on device
 *   pwr_ind	(size 1, offset 14, init 0):	RO	Power indicator present on device
 *   err_rep	(size 1, offset 15, init 0):	RO	Role based error reporting
 *   _anon16	(size 2, offset 16, init 0):	RSVD	_
 *   pwr_limit	(size 8, offset 18, init 0):	RO	Captured slot power limit value
 *   pwr_scale	(size 2, offset 26, init 0):	RO	Captured slot power limit scale
 *   flr	(size 1, offset 28, init 0):	RO	FLR supported
 *   _anon29	(size 3, offset 29, init 0):	RSVD	_
 */
static inline ioat_dma_devcap_t ioat_dma_devcap_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x94));
}

static inline ioat_dma_devcap_t ioat_dma_devcap_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devcap_t ioat_dma_devcap_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x94));
}

static inline void ioat_dma_devcap_rawwr(__DN(t) *_dev, ioat_dma_devcap_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_devcap_rawwr(__DN(t) *_dev, ioat_dma_devcap_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0x94, _regval);
}

// Register devcap is not writeable
static inline int ioat_dma_devcap_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_devcap_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register devcap (PCI Express Device Capability Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " max_payload =\t%" PRIx8 "\t(Maximum PCIe payload size)\n", ioat_dma_devcap_max_payload_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " phantom =\t%" PRIx8 "\t(Phantom functions supported)\n", ioat_dma_devcap_phantom_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ext_tag =\t%" PRIx8 "\t(Extended tag supported)\n", ioat_dma_devcap_ext_tag_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ep_latency_0 =\t%" PRIx8 "\t(Endpoint L0 acceptable latency)\n", ioat_dma_devcap_ep_latency_0_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ep_latency_1 =\t%" PRIx8 "\t(Endpoint L1 acceptable latency)\n", ioat_dma_devcap_ep_latency_1_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " att_btn =\t%" PRIx8 "\t(Attention button present on device)\n", ioat_dma_devcap_att_btn_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " att_ind =\t%" PRIx8 "\t(Attention indicator present on device)\n", ioat_dma_devcap_att_ind_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pwr_ind =\t%" PRIx8 "\t(Power indicator present on device)\n", ioat_dma_devcap_pwr_ind_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " err_rep =\t%" PRIx8 "\t(Role based error reporting)\n", ioat_dma_devcap_err_rep_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon16 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pwr_limit =\t%" PRIx8 "\t(Captured slot power limit value)\n", ioat_dma_devcap_pwr_limit_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pwr_scale =\t%" PRIx8 "\t(Captured slot power limit scale)\n", ioat_dma_devcap_pwr_scale_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " flr =\t%" PRIx8 "\t(FLR supported)\n", ioat_dma_devcap_flr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon29 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_devcap_max_payload_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_max_payload_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_max_payload_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_phantom_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_phantom_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_phantom_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_ext_tag_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_ext_tag_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_ext_tag_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_ep_latency_0_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_ep_latency_0_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_ep_latency_0_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_ep_latency_1_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_ep_latency_1_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_ep_latency_1_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_att_btn_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_att_btn_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_att_btn_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_att_ind_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_att_ind_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_att_ind_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_pwr_ind_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_pwr_ind_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_pwr_ind_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_err_rep_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_err_rep_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_err_rep_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_pwr_limit_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_pwr_limit_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_pwr_limit_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_pwr_scale_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_pwr_scale_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_pwr_scale_extract(_regval));
}

static inline uint8_t ioat_dma_devcap_flr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap_flr_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x94);
    return(ioat_dma_devcap_flr_extract(_regval));
}

/*
 * Register devcon: The PCI Express Device Control register
 * Type: ioat_dma.devcon (Implicit type of The PCI Express Device Control register register)
 *   corr_err	(size 1, offset 0, init 0):	RO	Enable correctable error reporting
 *   non_fat_err	(size 1, offset 1, init 0):	RO	Enable non-fatal error reporting
 *   fatal_err	(size 1, offset 2, init 0):	RO	Enable fatal error reporting
 *   unsup_rep	(size 1, offset 3, init 0):	RO	Enable unsupported request reporting
 *   relaxed_ord	(size 1, offset 4, init 0):	RW	Enable Relaxed ordering
 *   max_palyoad	(size 3, offset 5, init 0):	RO	Maximum payload size
 *   ext_tag_en	(size 1, offset 8, init 0):	RO	Enable extended tab field
 *   phantom_en	(size 1, offset 9, init 0):	RO	Enable phantom functions
 *   aux_pwr_en	(size 1, offset 10, init 0):	RO	Enable Auxiliary power managmenet
 *   no_snoop	(size 1, offset 11, init 0):	RW	Enable the no-snoop functionality
 *   max_rd_sz	(size 3, offset 12, init 0):	RO	Maximum read request size
 *   flr	(size 1, offset 15, init 0):	RW	Initiate FLR: reset only per FLR ECN
 */
static inline ioat_dma_devcon_t ioat_dma_devcon_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x98));
}

static inline ioat_dma_devcon_t ioat_dma_devcon_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devcon_t ioat_dma_devcon_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x98));
}

static inline void ioat_dma_devcon_rawwr(__DN(t) *_dev, ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_devcon_rawwr(__DN(t) *_dev, ioat_dma_devcon_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x98, _regval);
}

static inline void ioat_dma_devcon_wr(__DN(t) *_dev, ioat_dma_devcon_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_devcon_wr(__DN(t) *_dev, ioat_dma_devcon_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_16(_dev->cfg_base, 0x98, _regval);
}

static inline int ioat_dma_devcon_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_devcon_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register devcon (The PCI Express Device Control register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " corr_err =\t%" PRIx8 "\t(Enable correctable error reporting)\n", ioat_dma_devcon_corr_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " non_fat_err =\t%" PRIx8 "\t(Enable non-fatal error reporting)\n", ioat_dma_devcon_non_fat_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " fatal_err =\t%" PRIx8 "\t(Enable fatal error reporting)\n", ioat_dma_devcon_fatal_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unsup_rep =\t%" PRIx8 "\t(Enable unsupported request reporting)\n", ioat_dma_devcon_unsup_rep_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " relaxed_ord =\t%" PRIx8 "\t(Enable Relaxed ordering)\n", ioat_dma_devcon_relaxed_ord_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " max_palyoad =\t%" PRIx8 "\t(Maximum payload size)\n", ioat_dma_devcon_max_palyoad_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ext_tag_en =\t%" PRIx8 "\t(Enable extended tab field)\n", ioat_dma_devcon_ext_tag_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " phantom_en =\t%" PRIx8 "\t(Enable phantom functions)\n", ioat_dma_devcon_phantom_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " aux_pwr_en =\t%" PRIx8 "\t(Enable Auxiliary power managmenet)\n", ioat_dma_devcon_aux_pwr_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " no_snoop =\t%" PRIx8 "\t(Enable the no-snoop functionality)\n", ioat_dma_devcon_no_snoop_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " max_rd_sz =\t%" PRIx8 "\t(Maximum read request size)\n", ioat_dma_devcon_max_rd_sz_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " flr =\t%" PRIx8 "\t(Initiate FLR: reset only per FLR ECN)\n", ioat_dma_devcon_flr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_devcon_corr_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_corr_err_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_corr_err_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_non_fat_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_non_fat_err_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_non_fat_err_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_fatal_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_fatal_err_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_fatal_err_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_unsup_rep_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_unsup_rep_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_unsup_rep_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_relaxed_ord_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_relaxed_ord_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_relaxed_ord_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_max_palyoad_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_max_palyoad_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_max_palyoad_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_ext_tag_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_ext_tag_en_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_ext_tag_en_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_phantom_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_phantom_en_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_phantom_en_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_aux_pwr_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_aux_pwr_en_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_aux_pwr_en_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_no_snoop_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_no_snoop_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_no_snoop_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_max_rd_sz_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_max_rd_sz_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_max_rd_sz_extract(_regval));
}

static inline uint8_t ioat_dma_devcon_flr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon_flr_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x98);
    return(ioat_dma_devcon_flr_extract(_regval));
}

static inline void ioat_dma_devcon_relaxed_ord_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_devcon_relaxed_ord_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_devcon_t _regval = 0x10 & (((ioat_dma_devcon_t )(_fieldval)) << 4);
    _regval = (_regval | (0x8800 & mackerel_read_addr_16(_dev->cfg_base, 0x98)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x98, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_devcon_no_snoop_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_devcon_no_snoop_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_devcon_t _regval = 0x800 & (((ioat_dma_devcon_t )(_fieldval)) << 11);
    _regval = (_regval | (0x8010 & mackerel_read_addr_16(_dev->cfg_base, 0x98)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x98, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_devcon_flr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_devcon_flr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_devcon_t _regval = 0x8000 & (((ioat_dma_devcon_t )(_fieldval)) << 15);
    _regval = (_regval | (0x810 & mackerel_read_addr_16(_dev->cfg_base, 0x98)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0x98, _regval);
    // No shadow register to write to
}

/*
 * Register devsts: Device Status Register
 * Type: ioat_dma.devsts (Implicit type of Device Status Register register)
 *   corr_err	(size 1, offset 0, init 0):	RO	correctable error detected
 *   non_fat_err	(size 1, offset 1, init 0):	RO	non-fatal error detected
 *   fatal_err	(size 1, offset 2, init 0):	RO	fatal error detected
 *   unsup_req	(size 1, offset 3, init 0):	RO	Unsupported request detected
 *   aux_power	(size 1, offset 4, init 0):	RO	Auxiliary power detected
 *   tr_pending	(size 1, offset 5, init 0):	RO	Transaction pending
 *   _anon6	(size 10, offset 6, init 0):	RSVD	_
 */
static inline ioat_dma_devsts_t ioat_dma_devsts_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devsts_t ioat_dma_devsts_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x9a));
}

static inline ioat_dma_devsts_t ioat_dma_devsts_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devsts_t ioat_dma_devsts_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0x9a));
}

static inline void ioat_dma_devsts_rawwr(__DN(t) *_dev, ioat_dma_devsts_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_devsts_rawwr(__DN(t) *_dev, ioat_dma_devsts_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0x9a, _regval);
}

// Register devsts is not writeable
static inline int ioat_dma_devsts_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_devsts_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_devsts_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x9a);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register devsts (Device Status Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " corr_err =\t%" PRIx8 "\t(correctable error detected)\n", ioat_dma_devsts_corr_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " non_fat_err =\t%" PRIx8 "\t(non-fatal error detected)\n", ioat_dma_devsts_non_fat_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " fatal_err =\t%" PRIx8 "\t(fatal error detected)\n", ioat_dma_devsts_fatal_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unsup_req =\t%" PRIx8 "\t(Unsupported request detected)\n", ioat_dma_devsts_unsup_req_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " aux_power =\t%" PRIx8 "\t(Auxiliary power detected)\n", ioat_dma_devsts_aux_power_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tr_pending =\t%" PRIx8 "\t(Transaction pending)\n", ioat_dma_devsts_tr_pending_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon6 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_devsts_corr_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_corr_err_rdf(__DN(t) *_dev)
{
    ioat_dma_devsts_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x9a);
    return(ioat_dma_devsts_corr_err_extract(_regval));
}

static inline uint8_t ioat_dma_devsts_non_fat_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_non_fat_err_rdf(__DN(t) *_dev)
{
    ioat_dma_devsts_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x9a);
    return(ioat_dma_devsts_non_fat_err_extract(_regval));
}

static inline uint8_t ioat_dma_devsts_fatal_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_fatal_err_rdf(__DN(t) *_dev)
{
    ioat_dma_devsts_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x9a);
    return(ioat_dma_devsts_fatal_err_extract(_regval));
}

static inline uint8_t ioat_dma_devsts_unsup_req_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_unsup_req_rdf(__DN(t) *_dev)
{
    ioat_dma_devsts_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x9a);
    return(ioat_dma_devsts_unsup_req_extract(_regval));
}

static inline uint8_t ioat_dma_devsts_aux_power_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_aux_power_rdf(__DN(t) *_dev)
{
    ioat_dma_devsts_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x9a);
    return(ioat_dma_devsts_aux_power_extract(_regval));
}

static inline uint8_t ioat_dma_devsts_tr_pending_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devsts_tr_pending_rdf(__DN(t) *_dev)
{
    ioat_dma_devsts_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0x9a);
    return(ioat_dma_devsts_tr_pending_extract(_regval));
}

/*
 * Register devcap2: Device Capability Register 2
 * Type: ioat_dma.devcap2 (Implicit type of Device Capability Register 2 register)
 *   compl_timeout_values	(size 4, offset 0, init 0):	RO	Completion timeout values supported
 *   compl_timeout_disable	(size 1, offset 4, init 0):	RO	Completion timeout disable supported
 *   _anon5	(size 27, offset 5, init 0):	RSVD	_
 */
static inline ioat_dma_devcap2_t ioat_dma_devcap2_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devcap2_t ioat_dma_devcap2_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0xb4));
}

static inline ioat_dma_devcap2_t ioat_dma_devcap2_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devcap2_t ioat_dma_devcap2_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0xb4));
}

static inline void ioat_dma_devcap2_rawwr(__DN(t) *_dev, ioat_dma_devcap2_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_devcap2_rawwr(__DN(t) *_dev, ioat_dma_devcap2_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0xb4, _regval);
}

// Register devcap2 is not writeable
static inline int ioat_dma_devcap2_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_devcap2_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_devcap2_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xb4);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register devcap2 (Device Capability Register 2): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_timeout_values =\t%" PRIx8 "\t(Completion timeout values supported)\n", ioat_dma_devcap2_compl_timeout_values_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_timeout_disable =\t%" PRIx8 "\t(Completion timeout disable supported)\n", ioat_dma_devcap2_compl_timeout_disable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon5 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_devcap2_compl_timeout_values_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap2_compl_timeout_values_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap2_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xb4);
    return(ioat_dma_devcap2_compl_timeout_values_extract(_regval));
}

static inline uint8_t ioat_dma_devcap2_compl_timeout_disable_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcap2_compl_timeout_disable_rdf(__DN(t) *_dev)
{
    ioat_dma_devcap2_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xb4);
    return(ioat_dma_devcap2_compl_timeout_disable_extract(_regval));
}

/*
 * Register devcon2: Device Configuration Register 2
 * Type: ioat_dma.devcon2 (Implicit type of Device Configuration Register 2 register)
 *   compl_timeout_values	(size 4, offset 0, init 0):	RO	Completion timeout values
 *   compl_timeout_disable	(size 1, offset 4, init 0):	RW	Completion timeout disable
 *   _anon5	(size 11, offset 5, init 0):	RSVD	_
 */
static inline ioat_dma_devcon2_t ioat_dma_devcon2_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devcon2_t ioat_dma_devcon2_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0xb8));
}

static inline ioat_dma_devcon2_t ioat_dma_devcon2_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_devcon2_t ioat_dma_devcon2_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->cfg_base, 0xb8));
}

static inline void ioat_dma_devcon2_rawwr(__DN(t) *_dev, ioat_dma_devcon2_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_devcon2_rawwr(__DN(t) *_dev, ioat_dma_devcon2_t _regval)
{
    mackerel_write_addr_16(_dev->cfg_base, 0xb8, _regval);
}

static inline void ioat_dma_devcon2_wr(__DN(t) *_dev, ioat_dma_devcon2_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_devcon2_wr(__DN(t) *_dev, ioat_dma_devcon2_t _regval)
{
    _regval = (_regval & 0x1f);
    // No MB1 fields present
    _regval = (_regval | (0xffe0 & mackerel_read_addr_16(_dev->cfg_base, 0xb8)));
    mackerel_write_addr_16(_dev->cfg_base, 0xb8, _regval);
}

static inline int ioat_dma_devcon2_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_devcon2_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_devcon2_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0xb8);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register devcon2 (Device Configuration Register 2): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_timeout_values =\t%" PRIx8 "\t(Completion timeout values)\n", ioat_dma_devcon2_compl_timeout_values_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_timeout_disable =\t%" PRIx8 "\t(Completion timeout disable)\n", ioat_dma_devcon2_compl_timeout_disable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon5 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_devcon2_compl_timeout_values_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon2_compl_timeout_values_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon2_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0xb8);
    return(ioat_dma_devcon2_compl_timeout_values_extract(_regval));
}

static inline uint8_t ioat_dma_devcon2_compl_timeout_disable_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_devcon2_compl_timeout_disable_rdf(__DN(t) *_dev)
{
    ioat_dma_devcon2_t _regval = mackerel_read_addr_16(_dev->cfg_base, 0xb8);
    return(ioat_dma_devcon2_compl_timeout_disable_extract(_regval));
}

static inline void ioat_dma_devcon2_compl_timeout_disable_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_devcon2_compl_timeout_disable_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_devcon2_t _regval = 0x10 & (((ioat_dma_devcon2_t )(_fieldval)) << 4);
    _regval = (_regval | (0xffe0 & mackerel_read_addr_16(_dev->cfg_base, 0xb8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->cfg_base, 0xb8, _regval);
    // No shadow register to write to
}

/*
 * Register pmcap: Power Management Capability
 * Type: ioat_dma.pmcap (Implicit type of Power Management Capability register)
 *   capid	(size 8, offset 0, init 0):	RO	Capability ID (PM cap ID)
 *   next	(size 8, offset 8, init 0):	RO	Pointer to the next capability field
 *   version	(size 3, offset 16, init 0):	RO	Power management version
 *   pme_clock	(size 1, offset 19, init 0):	RO	Power management clock
 *   _anon20	(size 1, offset 20, init 0):	RSVD	_
 *   dev_init	(size 1, offset 21, init 0):	RO	Device specific initialization
 *   aux_current	(size 3, offset 22, init 0):	RO	Auxiliary current
 *   d1_sup	(size 1, offset 25, init 0):	RO	D2 om state supported
 *   d2_sup	(size 1, offset 26, init 0):	RO	D2 om state supported
 *   _anon27	(size 5, offset 27, init 0):	RSVD	_
 */
static inline ioat_dma_pmcap_t ioat_dma_pmcap_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pmcap_t ioat_dma_pmcap_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0xe0));
}

static inline ioat_dma_pmcap_t ioat_dma_pmcap_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pmcap_t ioat_dma_pmcap_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0xe0));
}

static inline void ioat_dma_pmcap_rawwr(__DN(t) *_dev, ioat_dma_pmcap_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pmcap_rawwr(__DN(t) *_dev, ioat_dma_pmcap_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0xe0, _regval);
}

// Register pmcap is not writeable
static inline int ioat_dma_pmcap_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_pmcap_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_pmcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe0);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register pmcap (Power Management Capability): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " capid =\t%" PRIx8 "\t(Capability ID (PM cap ID))\n", ioat_dma_pmcap_capid_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " next =\t%" PRIx8 "\t(Pointer to the next capability field)\n", ioat_dma_pmcap_next_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " version =\t%" PRIx8 "\t(Power management version)\n", ioat_dma_pmcap_version_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pme_clock =\t%" PRIx8 "\t(Power management clock)\n", ioat_dma_pmcap_pme_clock_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon20 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dev_init =\t%" PRIx8 "\t(Device specific initialization)\n", ioat_dma_pmcap_dev_init_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " aux_current =\t%" PRIx8 "\t(Auxiliary current)\n", ioat_dma_pmcap_aux_current_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " d1_sup =\t%" PRIx8 "\t(D2 om state supported)\n", ioat_dma_pmcap_d1_sup_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " d2_sup =\t%" PRIx8 "\t(D2 om state supported)\n", ioat_dma_pmcap_d2_sup_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon27 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_pmcap_capid_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_capid_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe0);
    return(ioat_dma_pmcap_capid_extract(_regval));
}

static inline uint8_t ioat_dma_pmcap_next_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_next_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe0);
    return(ioat_dma_pmcap_next_extract(_regval));
}

static inline uint8_t ioat_dma_pmcap_version_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_version_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe0);
    return(ioat_dma_pmcap_version_extract(_regval));
}

static inline uint8_t ioat_dma_pmcap_pme_clock_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_pme_clock_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe0);
    return(ioat_dma_pmcap_pme_clock_extract(_regval));
}

static inline uint8_t ioat_dma_pmcap_dev_init_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_dev_init_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe0);
    return(ioat_dma_pmcap_dev_init_extract(_regval));
}

static inline uint8_t ioat_dma_pmcap_aux_current_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_aux_current_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe0);
    return(ioat_dma_pmcap_aux_current_extract(_regval));
}

static inline uint8_t ioat_dma_pmcap_d1_sup_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_d1_sup_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe0);
    return(ioat_dma_pmcap_d1_sup_extract(_regval));
}

static inline uint8_t ioat_dma_pmcap_d2_sup_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcap_d2_sup_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcap_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe0);
    return(ioat_dma_pmcap_d2_sup_extract(_regval));
}

/*
 * Register pmcsr: Power Management Control and Status.
 * Type: ioat_dma.pmcsr (Implicit type of Power Management Control and Status. register)
 *   pwr_state	(size 2, offset 0, init 0):	RW	Powerstate to set
 *   _anon2	(size 1, offset 2, init 0):	RSVD	_
 *   no_soft_rst	(size 1, offset 3, init 0):	RO	No Softreset
 *   _anon4	(size 4, offset 4, init 0):	RSVD	_
 *   pme_en	(size 1, offset 8, init 0):	RO	Power Management Enabled
 *   data_select	(size 4, offset 9, init 0):	RO	Data Select
 *   data_scale	(size 2, offset 13, init 0):	RO	Data Scale
 *   pme_status	(size 1, offset 15, init 0):	RO	PME Status
 *   _anon16	(size 6, offset 16, init 0):	RSVD	_
 *   b2_b3_sup	(size 1, offset 22, init 0):	RO	B2-B3 Support
 *   clk_ctrl_en	(size 1, offset 23, init 0):	RO	Bus power clock control enabled
 *   data	(size 8, offset 24, init 0):	RO	Data field
 */
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0xe4));
}

static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pmcsr_t ioat_dma_pmcsr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0xe4));
}

static inline void ioat_dma_pmcsr_rawwr(__DN(t) *_dev, ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pmcsr_rawwr(__DN(t) *_dev, ioat_dma_pmcsr_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0xe4, _regval);
}

static inline void ioat_dma_pmcsr_wr(__DN(t) *_dev, ioat_dma_pmcsr_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pmcsr_wr(__DN(t) *_dev, ioat_dma_pmcsr_t _regval)
{
    _regval = (_regval & 0xffc0ff0b);
    // No MB1 fields present
    _regval = (_regval | (0x3f00f4 & mackerel_read_addr_32(_dev->cfg_base, 0xe4)));
    mackerel_write_addr_32(_dev->cfg_base, 0xe4, _regval);
}

static inline int ioat_dma_pmcsr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_pmcsr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_pmcsr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe4);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register pmcsr (Power Management Control and Status.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pwr_state =\t%" PRIx8 "\t(Powerstate to set)\n", ioat_dma_pmcsr_pwr_state_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon2 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " no_soft_rst =\t%" PRIx8 "\t(No Softreset)\n", ioat_dma_pmcsr_no_soft_rst_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon4 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pme_en =\t%" PRIx8 "\t(Power Management Enabled)\n", ioat_dma_pmcsr_pme_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " data_select =\t%" PRIx8 "\t(Data Select)\n", ioat_dma_pmcsr_data_select_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " data_scale =\t%" PRIx8 "\t(Data Scale)\n", ioat_dma_pmcsr_data_scale_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pme_status =\t%" PRIx8 "\t(PME Status)\n", ioat_dma_pmcsr_pme_status_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon16 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " b2_b3_sup =\t%" PRIx8 "\t(B2-B3 Support)\n", ioat_dma_pmcsr_b2_b3_sup_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " clk_ctrl_en =\t%" PRIx8 "\t(Bus power clock control enabled)\n", ioat_dma_pmcsr_clk_ctrl_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " data =\t%" PRIx8 "\t(Data field)\n", ioat_dma_pmcsr_data_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_pmcsr_pwr_state_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_pwr_state_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcsr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe4);
    return(ioat_dma_pmcsr_pwr_state_extract(_regval));
}

static inline uint8_t ioat_dma_pmcsr_no_soft_rst_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_no_soft_rst_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcsr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe4);
    return(ioat_dma_pmcsr_no_soft_rst_extract(_regval));
}

static inline uint8_t ioat_dma_pmcsr_pme_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_pme_en_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcsr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe4);
    return(ioat_dma_pmcsr_pme_en_extract(_regval));
}

static inline uint8_t ioat_dma_pmcsr_data_select_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_data_select_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcsr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe4);
    return(ioat_dma_pmcsr_data_select_extract(_regval));
}

static inline uint8_t ioat_dma_pmcsr_data_scale_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_data_scale_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcsr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe4);
    return(ioat_dma_pmcsr_data_scale_extract(_regval));
}

static inline uint8_t ioat_dma_pmcsr_pme_status_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_pme_status_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcsr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe4);
    return(ioat_dma_pmcsr_pme_status_extract(_regval));
}

static inline uint8_t ioat_dma_pmcsr_b2_b3_sup_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_b2_b3_sup_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcsr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe4);
    return(ioat_dma_pmcsr_b2_b3_sup_extract(_regval));
}

static inline uint8_t ioat_dma_pmcsr_clk_ctrl_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_clk_ctrl_en_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcsr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe4);
    return(ioat_dma_pmcsr_clk_ctrl_en_extract(_regval));
}

static inline uint8_t ioat_dma_pmcsr_data_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pmcsr_data_rdf(__DN(t) *_dev)
{
    ioat_dma_pmcsr_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0xe4);
    return(ioat_dma_pmcsr_data_extract(_regval));
}

static inline void ioat_dma_pmcsr_pwr_state_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_pmcsr_pwr_state_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_pmcsr_t _regval = 0x3 & (((ioat_dma_pmcsr_t )(_fieldval)) << 0);
    _regval = (_regval | (0x3f00f4 & mackerel_read_addr_32(_dev->cfg_base, 0xe4)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0xe4, _regval);
    // No shadow register to write to
}

/*
 * Register dmauncerrsts: DMA Cluster Uncorrectable Error Status
 * Type: ioat_dma.dmauncerrsts (Implicit type of DMA Cluster Uncorrectable Error Status register)
 *   _anon0	(size 2, offset 0, init 0):	RSVD	_
 *   dp_status	(size 1, offset 2, init 0):	RWCS	Received poisoned data from dp status
 *   hw_parity	(size 1, offset 3, init 0):	RWCS	DMA internal HW parity error
 *   _anon4	(size 3, offset 4, init 0):	RSVD	_
 *   compl_hdr	(size 1, offset 7, init 0):	RWCS	Read completion error staturs
 *   _anon8	(size 2, offset 8, init 0):	RSVD	_
 *   addr_dec	(size 1, offset 10, init 0):	RWCS	Read address decode error statuts
 *   _anon11	(size 1, offset 11, init 0):	RSVD	_
 *   syndrome	(size 1, offset 12, init 0):	RWCS	Syndrome multiple errors
 *   _anon13	(size 19, offset 13, init 0):	RSVD	_
 */
static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x148));
}

static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsts_t ioat_dma_dmauncerrsts_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x148));
}

static inline void ioat_dma_dmauncerrsts_rawwr(__DN(t) *_dev, ioat_dma_dmauncerrsts_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsts_rawwr(__DN(t) *_dev, ioat_dma_dmauncerrsts_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0x148, _regval);
}

static inline void ioat_dma_dmauncerrsts_wr(__DN(t) *_dev, ioat_dma_dmauncerrsts_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsts_wr(__DN(t) *_dev, ioat_dma_dmauncerrsts_t _regval)
{
    _regval = (_regval & 0x148c);
    // No MB1 fields present
    _regval = (_regval | (0xffffeb73 & mackerel_read_addr_32(_dev->cfg_base, 0x148)));
    mackerel_write_addr_32(_dev->cfg_base, 0x148, _regval);
}

static inline int ioat_dma_dmauncerrsts_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dmauncerrsts_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dmauncerrsts_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x148);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dmauncerrsts (DMA Cluster Uncorrectable Error Status): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon0 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dp_status =\t%" PRIx8 "\t(Received poisoned data from dp status)\n", ioat_dma_dmauncerrsts_dp_status_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " hw_parity =\t%" PRIx8 "\t(DMA internal HW parity error)\n", ioat_dma_dmauncerrsts_hw_parity_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon4 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_hdr =\t%" PRIx8 "\t(Read completion error staturs)\n", ioat_dma_dmauncerrsts_compl_hdr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon8 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " addr_dec =\t%" PRIx8 "\t(Read address decode error statuts)\n", ioat_dma_dmauncerrsts_addr_dec_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon11 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " syndrome =\t%" PRIx8 "\t(Syndrome multiple errors)\n", ioat_dma_dmauncerrsts_syndrome_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon13 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_dmauncerrsts_dp_status_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsts_dp_status_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrsts_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x148);
    return(ioat_dma_dmauncerrsts_dp_status_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrsts_hw_parity_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsts_hw_parity_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrsts_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x148);
    return(ioat_dma_dmauncerrsts_hw_parity_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrsts_compl_hdr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsts_compl_hdr_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrsts_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x148);
    return(ioat_dma_dmauncerrsts_compl_hdr_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrsts_addr_dec_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsts_addr_dec_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrsts_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x148);
    return(ioat_dma_dmauncerrsts_addr_dec_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrsts_syndrome_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsts_syndrome_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrsts_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x148);
    return(ioat_dma_dmauncerrsts_syndrome_extract(_regval));
}

static inline void ioat_dma_dmauncerrsts_dp_status_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsts_dp_status_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrsts_t _regval = 0x4 & (((ioat_dma_dmauncerrsts_t )(_fieldval)) << 2);
    _regval = (_regval | (0xffffeb73 & mackerel_read_addr_32(_dev->cfg_base, 0x148)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x148, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrsts_hw_parity_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsts_hw_parity_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrsts_t _regval = 0x8 & (((ioat_dma_dmauncerrsts_t )(_fieldval)) << 3);
    _regval = (_regval | (0xffffeb73 & mackerel_read_addr_32(_dev->cfg_base, 0x148)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x148, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrsts_compl_hdr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsts_compl_hdr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrsts_t _regval = 0x80 & (((ioat_dma_dmauncerrsts_t )(_fieldval)) << 7);
    _regval = (_regval | (0xffffeb73 & mackerel_read_addr_32(_dev->cfg_base, 0x148)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x148, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrsts_addr_dec_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsts_addr_dec_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrsts_t _regval = 0x400 & (((ioat_dma_dmauncerrsts_t )(_fieldval)) << 10);
    _regval = (_regval | (0xffffeb73 & mackerel_read_addr_32(_dev->cfg_base, 0x148)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x148, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrsts_syndrome_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsts_syndrome_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrsts_t _regval = 0x1000 & (((ioat_dma_dmauncerrsts_t )(_fieldval)) << 12);
    _regval = (_regval | (0xffffeb73 & mackerel_read_addr_32(_dev->cfg_base, 0x148)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x148, _regval);
    // No shadow register to write to
}

/*
 * Register dmauncerrmsk: DMA Cluster Uncorrectable Error Mask
 * Type: ioat_dma.dmauncerrmsk (Implicit type of DMA Cluster Uncorrectable Error Mask register)
 *   _anon0	(size 2, offset 0, init 0):	RSVD	_
 *   dp_status	(size 1, offset 2, init 0):	RW	Received poisoned data from dp status
 *   hw_parity	(size 1, offset 3, init 0):	RW	DMA internal HW parity error
 *   _anon4	(size 3, offset 4, init 0):	RSVD	_
 *   compl_hdr	(size 1, offset 7, init 0):	RW	Read completion error staturs
 *   _anon8	(size 2, offset 8, init 0):	RSVD	_
 *   addr_dec	(size 1, offset 10, init 0):	RW	Read address decode error statuts
 *   _anon11	(size 1, offset 11, init 0):	RSVD	_
 *   syndrome	(size 1, offset 12, init 0):	RW	Syndrome multiple errors
 *   _anon13	(size 19, offset 13, init 0):	RSVD	_
 */
static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x14c));
}

static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrmsk_t ioat_dma_dmauncerrmsk_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x14c));
}

static inline void ioat_dma_dmauncerrmsk_rawwr(__DN(t) *_dev, ioat_dma_dmauncerrmsk_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrmsk_rawwr(__DN(t) *_dev, ioat_dma_dmauncerrmsk_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0x14c, _regval);
}

static inline void ioat_dma_dmauncerrmsk_wr(__DN(t) *_dev, ioat_dma_dmauncerrmsk_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrmsk_wr(__DN(t) *_dev, ioat_dma_dmauncerrmsk_t _regval)
{
    _regval = (_regval & 0x148c);
    // No MB1 fields present
    _regval = (_regval | (0xffffeb73 & mackerel_read_addr_32(_dev->cfg_base, 0x14c)));
    mackerel_write_addr_32(_dev->cfg_base, 0x14c, _regval);
}

static inline int ioat_dma_dmauncerrmsk_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dmauncerrmsk_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dmauncerrmsk_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x14c);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dmauncerrmsk (DMA Cluster Uncorrectable Error Mask): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon0 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dp_status =\t%" PRIx8 "\t(Received poisoned data from dp status)\n", ioat_dma_dmauncerrmsk_dp_status_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " hw_parity =\t%" PRIx8 "\t(DMA internal HW parity error)\n", ioat_dma_dmauncerrmsk_hw_parity_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon4 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_hdr =\t%" PRIx8 "\t(Read completion error staturs)\n", ioat_dma_dmauncerrmsk_compl_hdr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon8 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " addr_dec =\t%" PRIx8 "\t(Read address decode error statuts)\n", ioat_dma_dmauncerrmsk_addr_dec_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon11 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " syndrome =\t%" PRIx8 "\t(Syndrome multiple errors)\n", ioat_dma_dmauncerrmsk_syndrome_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon13 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_dmauncerrmsk_dp_status_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrmsk_dp_status_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrmsk_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x14c);
    return(ioat_dma_dmauncerrmsk_dp_status_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrmsk_hw_parity_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrmsk_hw_parity_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrmsk_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x14c);
    return(ioat_dma_dmauncerrmsk_hw_parity_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrmsk_compl_hdr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrmsk_compl_hdr_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrmsk_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x14c);
    return(ioat_dma_dmauncerrmsk_compl_hdr_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrmsk_addr_dec_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrmsk_addr_dec_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrmsk_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x14c);
    return(ioat_dma_dmauncerrmsk_addr_dec_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrmsk_syndrome_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrmsk_syndrome_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrmsk_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x14c);
    return(ioat_dma_dmauncerrmsk_syndrome_extract(_regval));
}

static inline void ioat_dma_dmauncerrmsk_dp_status_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrmsk_dp_status_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrmsk_t _regval = 0x4 & (((ioat_dma_dmauncerrmsk_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfffffffb & mackerel_read_addr_32(_dev->cfg_base, 0x14c)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x14c, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrmsk_hw_parity_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrmsk_hw_parity_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrmsk_t _regval = 0x8 & (((ioat_dma_dmauncerrmsk_t )(_fieldval)) << 3);
    _regval = (_regval | (0xfffffff7 & mackerel_read_addr_32(_dev->cfg_base, 0x14c)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x14c, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrmsk_compl_hdr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrmsk_compl_hdr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrmsk_t _regval = 0x80 & (((ioat_dma_dmauncerrmsk_t )(_fieldval)) << 7);
    _regval = (_regval | (0xffffff7f & mackerel_read_addr_32(_dev->cfg_base, 0x14c)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x14c, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrmsk_addr_dec_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrmsk_addr_dec_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrmsk_t _regval = 0x400 & (((ioat_dma_dmauncerrmsk_t )(_fieldval)) << 10);
    _regval = (_regval | (0xfffffbff & mackerel_read_addr_32(_dev->cfg_base, 0x14c)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x14c, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrmsk_syndrome_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrmsk_syndrome_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrmsk_t _regval = 0x1000 & (((ioat_dma_dmauncerrmsk_t )(_fieldval)) << 12);
    _regval = (_regval | (0xffffefff & mackerel_read_addr_32(_dev->cfg_base, 0x14c)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x14c, _regval);
    // No shadow register to write to
}

/*
 * Register dmauncerrsev: DMA Cluster Uncorrectable Error Severity.
 * Type: ioat_dma.dmauncerrsev (Implicit type of DMA Cluster Uncorrectable Error Severity. register)
 *   _anon0	(size 2, offset 0, init 0):	RSVD	_
 *   dp_status	(size 1, offset 2, init 0):	RW	Received poisoned data from dp status
 *   hw_parity	(size 1, offset 3, init 0):	RW	DMA internal HW parity error
 *   _anon4	(size 3, offset 4, init 0):	RSVD	_
 *   compl_hdr	(size 1, offset 7, init 0):	RW	Read completion error staturs
 *   _anon8	(size 2, offset 8, init 0):	RSVD	_
 *   addr_dec	(size 1, offset 10, init 0):	RW	Read address decode error statuts
 *   _anon11	(size 1, offset 11, init 0):	RSVD	_
 *   syndrome	(size 1, offset 12, init 0):	RW	Syndrome multiple errors
 *   _anon13	(size 19, offset 13, init 0):	RSVD	_
 */
static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x150));
}

static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrsev_t ioat_dma_dmauncerrsev_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x150));
}

static inline void ioat_dma_dmauncerrsev_rawwr(__DN(t) *_dev, ioat_dma_dmauncerrsev_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsev_rawwr(__DN(t) *_dev, ioat_dma_dmauncerrsev_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0x150, _regval);
}

static inline void ioat_dma_dmauncerrsev_wr(__DN(t) *_dev, ioat_dma_dmauncerrsev_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsev_wr(__DN(t) *_dev, ioat_dma_dmauncerrsev_t _regval)
{
    _regval = (_regval & 0x148c);
    // No MB1 fields present
    _regval = (_regval | (0xffffeb73 & mackerel_read_addr_32(_dev->cfg_base, 0x150)));
    mackerel_write_addr_32(_dev->cfg_base, 0x150, _regval);
}

static inline int ioat_dma_dmauncerrsev_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dmauncerrsev_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dmauncerrsev_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x150);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dmauncerrsev (DMA Cluster Uncorrectable Error Severity.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon0 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dp_status =\t%" PRIx8 "\t(Received poisoned data from dp status)\n", ioat_dma_dmauncerrsev_dp_status_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " hw_parity =\t%" PRIx8 "\t(DMA internal HW parity error)\n", ioat_dma_dmauncerrsev_hw_parity_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon4 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " compl_hdr =\t%" PRIx8 "\t(Read completion error staturs)\n", ioat_dma_dmauncerrsev_compl_hdr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon8 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " addr_dec =\t%" PRIx8 "\t(Read address decode error statuts)\n", ioat_dma_dmauncerrsev_addr_dec_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon11 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " syndrome =\t%" PRIx8 "\t(Syndrome multiple errors)\n", ioat_dma_dmauncerrsev_syndrome_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon13 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_dmauncerrsev_dp_status_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsev_dp_status_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrsev_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x150);
    return(ioat_dma_dmauncerrsev_dp_status_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrsev_hw_parity_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsev_hw_parity_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrsev_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x150);
    return(ioat_dma_dmauncerrsev_hw_parity_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrsev_compl_hdr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsev_compl_hdr_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrsev_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x150);
    return(ioat_dma_dmauncerrsev_compl_hdr_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrsev_addr_dec_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsev_addr_dec_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrsev_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x150);
    return(ioat_dma_dmauncerrsev_addr_dec_extract(_regval));
}

static inline uint8_t ioat_dma_dmauncerrsev_syndrome_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrsev_syndrome_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrsev_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x150);
    return(ioat_dma_dmauncerrsev_syndrome_extract(_regval));
}

static inline void ioat_dma_dmauncerrsev_dp_status_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsev_dp_status_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrsev_t _regval = 0x4 & (((ioat_dma_dmauncerrsev_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfffffffb & mackerel_read_addr_32(_dev->cfg_base, 0x150)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x150, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrsev_hw_parity_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsev_hw_parity_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrsev_t _regval = 0x8 & (((ioat_dma_dmauncerrsev_t )(_fieldval)) << 3);
    _regval = (_regval | (0xfffffff7 & mackerel_read_addr_32(_dev->cfg_base, 0x150)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x150, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrsev_compl_hdr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsev_compl_hdr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrsev_t _regval = 0x80 & (((ioat_dma_dmauncerrsev_t )(_fieldval)) << 7);
    _regval = (_regval | (0xffffff7f & mackerel_read_addr_32(_dev->cfg_base, 0x150)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x150, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrsev_addr_dec_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsev_addr_dec_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrsev_t _regval = 0x400 & (((ioat_dma_dmauncerrsev_t )(_fieldval)) << 10);
    _regval = (_regval | (0xfffffbff & mackerel_read_addr_32(_dev->cfg_base, 0x150)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x150, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dmauncerrsev_syndrome_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrsev_syndrome_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmauncerrsev_t _regval = 0x1000 & (((ioat_dma_dmauncerrsev_t )(_fieldval)) << 12);
    _regval = (_regval | (0xffffefff & mackerel_read_addr_32(_dev->cfg_base, 0x150)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x150, _regval);
    // No shadow register to write to
}

/*
 * Register dmauncerrptr: DMA Cluster Uncorrectable Error Pointer
 * Type: ioat_dma.dmauncerrptr (Implicit type of DMA Cluster Uncorrectable Error Pointer register)
 *   uncerrptr	(size 5, offset 0, init 0):	RO	oints to the first uncorrectable error logged in the DMAUNCERRSTS register.
 *   _anon5	(size 3, offset 5, init 0):	RSVD	_
 */
static inline ioat_dma_dmauncerrptr_t ioat_dma_dmauncerrptr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrptr_t ioat_dma_dmauncerrptr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x154));
}

static inline ioat_dma_dmauncerrptr_t ioat_dma_dmauncerrptr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmauncerrptr_t ioat_dma_dmauncerrptr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x154));
}

static inline void ioat_dma_dmauncerrptr_rawwr(__DN(t) *_dev, ioat_dma_dmauncerrptr_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmauncerrptr_rawwr(__DN(t) *_dev, ioat_dma_dmauncerrptr_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0x154, _regval);
}

// Register dmauncerrptr is not writeable
static inline int ioat_dma_dmauncerrptr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dmauncerrptr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dmauncerrptr_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x154);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dmauncerrptr (DMA Cluster Uncorrectable Error Pointer): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " uncerrptr =\t%" PRIx8 "\t(oints to the first uncorrectable error logged in the DMAUNCERRSTS register.)\n", ioat_dma_dmauncerrptr_uncerrptr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon5 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_dmauncerrptr_uncerrptr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmauncerrptr_uncerrptr_rdf(__DN(t) *_dev)
{
    ioat_dma_dmauncerrptr_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x154);
    return(ioat_dma_dmauncerrptr_uncerrptr_extract(_regval));
}

/*
 * Register dmaglberrptr: DMA Cluster Global Error Pointer
 * Type: ioat_dma.dmaglberrptr (Implicit type of DMA Cluster Global Error Pointer register)
 *   glbl_err	(size 4, offset 0, init 0):	RW	Points to 8 possible sources of uncorrectable rrors
 *   _anon4	(size 4, offset 4, init 0):	RSVD	_
 */
static inline ioat_dma_dmaglberrptr_t ioat_dma_dmaglberrptr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmaglberrptr_t ioat_dma_dmaglberrptr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x160));
}

static inline ioat_dma_dmaglberrptr_t ioat_dma_dmaglberrptr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmaglberrptr_t ioat_dma_dmaglberrptr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x160));
}

static inline void ioat_dma_dmaglberrptr_rawwr(__DN(t) *_dev, ioat_dma_dmaglberrptr_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmaglberrptr_rawwr(__DN(t) *_dev, ioat_dma_dmaglberrptr_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0x160, _regval);
}

static inline void ioat_dma_dmaglberrptr_wr(__DN(t) *_dev, ioat_dma_dmaglberrptr_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmaglberrptr_wr(__DN(t) *_dev, ioat_dma_dmaglberrptr_t _regval)
{
    _regval = (_regval & 0xf);
    // No MB1 fields present
    _regval = (_regval | (0xf0 & mackerel_read_addr_8(_dev->cfg_base, 0x160)));
    mackerel_write_addr_8(_dev->cfg_base, 0x160, _regval);
}

static inline int ioat_dma_dmaglberrptr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dmaglberrptr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dmaglberrptr_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x160);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dmaglberrptr (DMA Cluster Global Error Pointer): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " glbl_err =\t%" PRIx8 "\t(Points to 8 possible sources of uncorrectable rrors)\n", ioat_dma_dmaglberrptr_glbl_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon4 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_dmaglberrptr_glbl_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmaglberrptr_glbl_err_rdf(__DN(t) *_dev)
{
    ioat_dma_dmaglberrptr_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x160);
    return(ioat_dma_dmaglberrptr_glbl_err_extract(_regval));
}

static inline void ioat_dma_dmaglberrptr_glbl_err_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmaglberrptr_glbl_err_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmaglberrptr_t _regval = 0xf & (((ioat_dma_dmaglberrptr_t )(_fieldval)) << 0);
    _regval = (_regval | (0xf0 & mackerel_read_addr_8(_dev->cfg_base, 0x160)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_8(_dev->cfg_base, 0x160, _regval);
    // No shadow register to write to
}

/*
 * Register chanerr_int: Internal DMA Channel Error Status Registers.
 * Type: ioat_dma.chanerr_int (Implicit type of Internal DMA Channel Error Status Registers. register)
 *   dmatranserr	(size 1, offset 0, init 0):	RWCS	DMA Transfer Source address error
 *   dmaxfererr	(size 1, offset 1, init 0):	RWCS	DMA Transfer Destination address error
 *   nxtdescerr	(size 1, offset 2, init 0):	RWCS	Next Descriptor Address error
 *   descerr	(size 1, offset 3, init 0):	RWCS	Descriptor error
 *   chanaddr	(size 1, offset 4, init 0):	RWCS	Channel address value error
 *   chancmderr	(size 1, offset 5, init 0):	RWCS	Channel command error
 *   cdataerr	(size 1, offset 6, init 0):	RWCS	Data parity error
 *   dmadataerr	(size 1, offset 7, init 0):	RWCS	DMA Data Parity error
 *   rddataerr	(size 1, offset 8, init 0):	RWCS	Read Data error
 *   wrdataerr	(size 1, offset 9, init 0):	RWCS	Write data error
 *   descctrlerr	(size 1, offset 10, init 0):	RWCS	Description control  error
 *   desclenerr	(size 1, offset 11, init 0):	RWCS	Description length error
 *   cmpaddrerr	(size 1, offset 12, init 0):	RWCS	Completion Address error
 *   intcfgerr	(size 1, offset 13, init 0):	RWCS	Interrupt confiuguratio error
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   unaffilerr	(size 1, offset 15, init 0):	RO	Unaffiliated Error
 *   crc_err	(size 1, offset 16, init 0):	RWCS	CRC test failed
 *   xorqerr	(size 1, offset 17, init 0):	RWCS	Xor error
 *   desccnterr	(size 1, offset 18, init 0):	RWCS	Descriptor Count error
 *   _anon19	(size 13, offset 19, init 0):	RSVD	_
 */
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x180));
}

static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_int_t ioat_dma_chanerr_int_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x180));
}

static inline void ioat_dma_chanerr_int_rawwr(__DN(t) *_dev, ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_rawwr(__DN(t) *_dev, ioat_dma_chanerr_int_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
}

static inline void ioat_dma_chanerr_int_wr(__DN(t) *_dev, ioat_dma_chanerr_int_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_wr(__DN(t) *_dev, ioat_dma_chanerr_int_t _regval)
{
    _regval = (_regval & 0x7bfff);
    // No MB1 fields present
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
}

static inline int ioat_dma_chanerr_int_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chanerr_int_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chanerr_int (Internal DMA Channel Error Status Registers.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmatranserr =\t%" PRIx8 "\t(DMA Transfer Source address error)\n", ioat_dma_chanerr_int_dmatranserr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmaxfererr =\t%" PRIx8 "\t(DMA Transfer Destination address error)\n", ioat_dma_chanerr_int_dmaxfererr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " nxtdescerr =\t%" PRIx8 "\t(Next Descriptor Address error)\n", ioat_dma_chanerr_int_nxtdescerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descerr =\t%" PRIx8 "\t(Descriptor error)\n", ioat_dma_chanerr_int_descerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanaddr =\t%" PRIx8 "\t(Channel address value error)\n", ioat_dma_chanerr_int_chanaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chancmderr =\t%" PRIx8 "\t(Channel command error)\n", ioat_dma_chanerr_int_chancmderr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cdataerr =\t%" PRIx8 "\t(Data parity error)\n", ioat_dma_chanerr_int_cdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmadataerr =\t%" PRIx8 "\t(DMA Data Parity error)\n", ioat_dma_chanerr_int_dmadataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rddataerr =\t%" PRIx8 "\t(Read Data error)\n", ioat_dma_chanerr_int_rddataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " wrdataerr =\t%" PRIx8 "\t(Write data error)\n", ioat_dma_chanerr_int_wrdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descctrlerr =\t%" PRIx8 "\t(Description control  error)\n", ioat_dma_chanerr_int_descctrlerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desclenerr =\t%" PRIx8 "\t(Description length error)\n", ioat_dma_chanerr_int_desclenerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpaddrerr =\t%" PRIx8 "\t(Completion Address error)\n", ioat_dma_chanerr_int_cmpaddrerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intcfgerr =\t%" PRIx8 "\t(Interrupt confiuguratio error)\n", ioat_dma_chanerr_int_intcfgerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon14 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unaffilerr =\t%" PRIx8 "\t(Unaffiliated Error)\n", ioat_dma_chanerr_int_unaffilerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc_err =\t%" PRIx8 "\t(CRC test failed)\n", ioat_dma_chanerr_int_crc_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xorqerr =\t%" PRIx8 "\t(Xor error)\n", ioat_dma_chanerr_int_xorqerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desccnterr =\t%" PRIx8 "\t(Descriptor Count error)\n", ioat_dma_chanerr_int_desccnterr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon19 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_chanerr_int_dmatranserr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_dmatranserr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_dmatranserr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_dmaxfererr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_dmaxfererr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_dmaxfererr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_nxtdescerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_nxtdescerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_nxtdescerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_descerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_descerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_descerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_chanaddr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_chanaddr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_chanaddr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_chancmderr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_chancmderr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_chancmderr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_cdataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_cdataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_cdataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_dmadataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_dmadataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_dmadataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_rddataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_rddataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_rddataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_wrdataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_wrdataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_wrdataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_descctrlerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_descctrlerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_descctrlerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_desclenerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_desclenerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_desclenerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_cmpaddrerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_cmpaddrerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_cmpaddrerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_intcfgerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_intcfgerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_intcfgerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_unaffilerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_unaffilerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_unaffilerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_crc_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_crc_err_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_crc_err_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_xorqerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_xorqerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_xorqerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_int_desccnterr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_int_desccnterr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x180);
    return(ioat_dma_chanerr_int_desccnterr_extract(_regval));
}

static inline void ioat_dma_chanerr_int_dmatranserr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_dmatranserr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x1 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_dmaxfererr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_dmaxfererr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x2 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 1);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_nxtdescerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_nxtdescerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x4 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_descerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_descerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x8 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 3);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_chanaddr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_chanaddr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x10 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 4);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_chancmderr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_chancmderr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x20 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 5);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_cdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_cdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x40 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 6);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_dmadataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_dmadataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x80 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 7);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_rddataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_rddataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x100 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 8);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_wrdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_wrdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x200 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 9);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_descctrlerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_descctrlerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x400 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 10);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_desclenerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_desclenerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x800 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 11);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_cmpaddrerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_cmpaddrerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x1000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 12);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_intcfgerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_intcfgerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x2000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 13);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_crc_err_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_crc_err_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x10000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 16);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_xorqerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_xorqerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x20000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 17);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_int_desccnterr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_int_desccnterr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_int_t _regval = 0x40000 & (((ioat_dma_chanerr_int_t )(_fieldval)) << 18);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x180, _regval);
    // No shadow register to write to
}

/*
 * Register chanerrmsk_int: Internal DMA Channel Error Mask Registers.
 * Type: ioat_dma.chanerrmsk_int (Implicit type of Internal DMA Channel Error Mask Registers. register)
 *   dmatranserr	(size 1, offset 0, init 0):	RWCS	DMA Transfer Source address error
 *   dmaxfererr	(size 1, offset 1, init 0):	RWCS	DMA Transfer Destination address error
 *   nxtdescerr	(size 1, offset 2, init 0):	RWCS	Next Descriptor Address error
 *   descerr	(size 1, offset 3, init 0):	RWCS	Descriptor error
 *   chanaddr	(size 1, offset 4, init 0):	RWCS	Channel address value error
 *   chancmderr	(size 1, offset 5, init 0):	RWCS	Channel command error
 *   cdataerr	(size 1, offset 6, init 0):	RWCS	Data parity error
 *   dmadataerr	(size 1, offset 7, init 0):	RWCS	DMA Data Parity error
 *   rddataerr	(size 1, offset 8, init 0):	RWCS	Read Data error
 *   wrdataerr	(size 1, offset 9, init 0):	RWCS	Write data error
 *   descctrlerr	(size 1, offset 10, init 0):	RWCS	Description control  error
 *   desclenerr	(size 1, offset 11, init 0):	RWCS	Description length error
 *   cmpaddrerr	(size 1, offset 12, init 0):	RWCS	Completion Address error
 *   intcfgerr	(size 1, offset 13, init 0):	RWCS	Interrupt confiuguratio error
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   unaffilerr	(size 1, offset 15, init 0):	RO	Unaffiliated Error
 *   crc_err	(size 1, offset 16, init 0):	RWCS	CRC test failed
 *   xorqerr	(size 1, offset 17, init 0):	RWCS	Xor error
 *   desccnterr	(size 1, offset 18, init 0):	RWCS	Descriptor Count error
 *   _anon19	(size 13, offset 19, init 0):	RSVD	_
 */
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x184));
}

static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_int_t ioat_dma_chanerrmsk_int_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x184));
}

static inline void ioat_dma_chanerrmsk_int_rawwr(__DN(t) *_dev, ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_rawwr(__DN(t) *_dev, ioat_dma_chanerrmsk_int_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
}

static inline void ioat_dma_chanerrmsk_int_wr(__DN(t) *_dev, ioat_dma_chanerrmsk_int_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_wr(__DN(t) *_dev, ioat_dma_chanerrmsk_int_t _regval)
{
    _regval = (_regval & 0x7bfff);
    // No MB1 fields present
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
}

static inline int ioat_dma_chanerrmsk_int_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chanerrmsk_int_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chanerrmsk_int (Internal DMA Channel Error Mask Registers.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmatranserr =\t%" PRIx8 "\t(DMA Transfer Source address error)\n", ioat_dma_chanerrmsk_int_dmatranserr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmaxfererr =\t%" PRIx8 "\t(DMA Transfer Destination address error)\n", ioat_dma_chanerrmsk_int_dmaxfererr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " nxtdescerr =\t%" PRIx8 "\t(Next Descriptor Address error)\n", ioat_dma_chanerrmsk_int_nxtdescerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descerr =\t%" PRIx8 "\t(Descriptor error)\n", ioat_dma_chanerrmsk_int_descerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanaddr =\t%" PRIx8 "\t(Channel address value error)\n", ioat_dma_chanerrmsk_int_chanaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chancmderr =\t%" PRIx8 "\t(Channel command error)\n", ioat_dma_chanerrmsk_int_chancmderr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cdataerr =\t%" PRIx8 "\t(Data parity error)\n", ioat_dma_chanerrmsk_int_cdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmadataerr =\t%" PRIx8 "\t(DMA Data Parity error)\n", ioat_dma_chanerrmsk_int_dmadataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rddataerr =\t%" PRIx8 "\t(Read Data error)\n", ioat_dma_chanerrmsk_int_rddataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " wrdataerr =\t%" PRIx8 "\t(Write data error)\n", ioat_dma_chanerrmsk_int_wrdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descctrlerr =\t%" PRIx8 "\t(Description control  error)\n", ioat_dma_chanerrmsk_int_descctrlerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desclenerr =\t%" PRIx8 "\t(Description length error)\n", ioat_dma_chanerrmsk_int_desclenerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpaddrerr =\t%" PRIx8 "\t(Completion Address error)\n", ioat_dma_chanerrmsk_int_cmpaddrerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intcfgerr =\t%" PRIx8 "\t(Interrupt confiuguratio error)\n", ioat_dma_chanerrmsk_int_intcfgerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon14 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unaffilerr =\t%" PRIx8 "\t(Unaffiliated Error)\n", ioat_dma_chanerrmsk_int_unaffilerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc_err =\t%" PRIx8 "\t(CRC test failed)\n", ioat_dma_chanerrmsk_int_crc_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xorqerr =\t%" PRIx8 "\t(Xor error)\n", ioat_dma_chanerrmsk_int_xorqerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desccnterr =\t%" PRIx8 "\t(Descriptor Count error)\n", ioat_dma_chanerrmsk_int_desccnterr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon19 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_chanerrmsk_int_dmatranserr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_dmatranserr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_dmatranserr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_dmaxfererr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_dmaxfererr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_dmaxfererr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_nxtdescerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_nxtdescerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_nxtdescerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_descerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_descerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_descerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_chanaddr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_chanaddr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_chanaddr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_chancmderr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_chancmderr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_chancmderr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_cdataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_cdataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_cdataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_dmadataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_dmadataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_dmadataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_rddataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_rddataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_rddataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_wrdataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_wrdataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_wrdataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_descctrlerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_descctrlerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_descctrlerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_desclenerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_desclenerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_desclenerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_cmpaddrerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_cmpaddrerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_cmpaddrerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_intcfgerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_intcfgerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_intcfgerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_unaffilerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_unaffilerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_unaffilerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_crc_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_crc_err_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_crc_err_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_xorqerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_xorqerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_xorqerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_int_desccnterr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_int_desccnterr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x184);
    return(ioat_dma_chanerrmsk_int_desccnterr_extract(_regval));
}

static inline void ioat_dma_chanerrmsk_int_dmatranserr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_dmatranserr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x1 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_dmaxfererr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_dmaxfererr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x2 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 1);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_nxtdescerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_nxtdescerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x4 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_descerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_descerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x8 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 3);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_chanaddr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_chanaddr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x10 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 4);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_chancmderr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_chancmderr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x20 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 5);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_cdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_cdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x40 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 6);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_dmadataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_dmadataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x80 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 7);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_rddataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_rddataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x100 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 8);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_wrdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_wrdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x200 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 9);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_descctrlerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_descctrlerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x400 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 10);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_desclenerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_desclenerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x800 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 11);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_cmpaddrerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_cmpaddrerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x1000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 12);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_intcfgerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_intcfgerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x2000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 13);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_crc_err_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_crc_err_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x10000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 16);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_xorqerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_xorqerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x20000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 17);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_int_desccnterr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_int_desccnterr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_int_t _regval = 0x40000 & (((ioat_dma_chanerrmsk_int_t )(_fieldval)) << 18);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x184, _regval);
    // No shadow register to write to
}

/*
 * Register chanerrsev_int: Internal DMA Channel Error Severity Registers.
 * Type: ioat_dma.chanerrsev_int (Implicit type of Internal DMA Channel Error Severity Registers. register)
 *   dmatranserr	(size 1, offset 0, init 0):	RWCS	DMA Transfer Source address error
 *   dmaxfererr	(size 1, offset 1, init 0):	RWCS	DMA Transfer Destination address error
 *   nxtdescerr	(size 1, offset 2, init 0):	RWCS	Next Descriptor Address error
 *   descerr	(size 1, offset 3, init 0):	RWCS	Descriptor error
 *   chanaddr	(size 1, offset 4, init 0):	RWCS	Channel address value error
 *   chancmderr	(size 1, offset 5, init 0):	RWCS	Channel command error
 *   cdataerr	(size 1, offset 6, init 0):	RWCS	Data parity error
 *   dmadataerr	(size 1, offset 7, init 0):	RWCS	DMA Data Parity error
 *   rddataerr	(size 1, offset 8, init 0):	RWCS	Read Data error
 *   wrdataerr	(size 1, offset 9, init 0):	RWCS	Write data error
 *   descctrlerr	(size 1, offset 10, init 0):	RWCS	Description control  error
 *   desclenerr	(size 1, offset 11, init 0):	RWCS	Description length error
 *   cmpaddrerr	(size 1, offset 12, init 0):	RWCS	Completion Address error
 *   intcfgerr	(size 1, offset 13, init 0):	RWCS	Interrupt confiuguratio error
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   unaffilerr	(size 1, offset 15, init 0):	RO	Unaffiliated Error
 *   crc_err	(size 1, offset 16, init 0):	RWCS	CRC test failed
 *   xorqerr	(size 1, offset 17, init 0):	RWCS	Xor error
 *   desccnterr	(size 1, offset 18, init 0):	RWCS	Descriptor Count error
 *   _anon19	(size 13, offset 19, init 0):	RSVD	_
 */
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x188));
}

static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerrsev_int_t ioat_dma_chanerrsev_int_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->cfg_base, 0x188));
}

static inline void ioat_dma_chanerrsev_int_rawwr(__DN(t) *_dev, ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_rawwr(__DN(t) *_dev, ioat_dma_chanerrsev_int_t _regval)
{
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
}

static inline void ioat_dma_chanerrsev_int_wr(__DN(t) *_dev, ioat_dma_chanerrsev_int_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_wr(__DN(t) *_dev, ioat_dma_chanerrsev_int_t _regval)
{
    _regval = (_regval & 0x7bfff);
    // No MB1 fields present
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
}

static inline int ioat_dma_chanerrsev_int_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chanerrsev_int_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chanerrsev_int (Internal DMA Channel Error Severity Registers.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmatranserr =\t%" PRIx8 "\t(DMA Transfer Source address error)\n", ioat_dma_chanerrsev_int_dmatranserr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmaxfererr =\t%" PRIx8 "\t(DMA Transfer Destination address error)\n", ioat_dma_chanerrsev_int_dmaxfererr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " nxtdescerr =\t%" PRIx8 "\t(Next Descriptor Address error)\n", ioat_dma_chanerrsev_int_nxtdescerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descerr =\t%" PRIx8 "\t(Descriptor error)\n", ioat_dma_chanerrsev_int_descerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanaddr =\t%" PRIx8 "\t(Channel address value error)\n", ioat_dma_chanerrsev_int_chanaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chancmderr =\t%" PRIx8 "\t(Channel command error)\n", ioat_dma_chanerrsev_int_chancmderr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cdataerr =\t%" PRIx8 "\t(Data parity error)\n", ioat_dma_chanerrsev_int_cdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmadataerr =\t%" PRIx8 "\t(DMA Data Parity error)\n", ioat_dma_chanerrsev_int_dmadataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rddataerr =\t%" PRIx8 "\t(Read Data error)\n", ioat_dma_chanerrsev_int_rddataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " wrdataerr =\t%" PRIx8 "\t(Write data error)\n", ioat_dma_chanerrsev_int_wrdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descctrlerr =\t%" PRIx8 "\t(Description control  error)\n", ioat_dma_chanerrsev_int_descctrlerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desclenerr =\t%" PRIx8 "\t(Description length error)\n", ioat_dma_chanerrsev_int_desclenerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpaddrerr =\t%" PRIx8 "\t(Completion Address error)\n", ioat_dma_chanerrsev_int_cmpaddrerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intcfgerr =\t%" PRIx8 "\t(Interrupt confiuguratio error)\n", ioat_dma_chanerrsev_int_intcfgerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon14 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unaffilerr =\t%" PRIx8 "\t(Unaffiliated Error)\n", ioat_dma_chanerrsev_int_unaffilerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc_err =\t%" PRIx8 "\t(CRC test failed)\n", ioat_dma_chanerrsev_int_crc_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xorqerr =\t%" PRIx8 "\t(Xor error)\n", ioat_dma_chanerrsev_int_xorqerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desccnterr =\t%" PRIx8 "\t(Descriptor Count error)\n", ioat_dma_chanerrsev_int_desccnterr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon19 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_chanerrsev_int_dmatranserr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_dmatranserr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_dmatranserr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_dmaxfererr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_dmaxfererr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_dmaxfererr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_nxtdescerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_nxtdescerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_nxtdescerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_descerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_descerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_descerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_chanaddr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_chanaddr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_chanaddr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_chancmderr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_chancmderr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_chancmderr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_cdataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_cdataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_cdataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_dmadataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_dmadataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_dmadataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_rddataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_rddataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_rddataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_wrdataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_wrdataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_wrdataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_descctrlerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_descctrlerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_descctrlerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_desclenerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_desclenerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_desclenerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_cmpaddrerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_cmpaddrerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_cmpaddrerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_intcfgerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_intcfgerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_intcfgerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_unaffilerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_unaffilerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_unaffilerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_crc_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_crc_err_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_crc_err_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_xorqerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_xorqerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_xorqerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrsev_int_desccnterr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrsev_int_desccnterr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrsev_int_t _regval = mackerel_read_addr_32(_dev->cfg_base, 0x188);
    return(ioat_dma_chanerrsev_int_desccnterr_extract(_regval));
}

static inline void ioat_dma_chanerrsev_int_dmatranserr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_dmatranserr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x1 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_dmaxfererr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_dmaxfererr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x2 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 1);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_nxtdescerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_nxtdescerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x4 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_descerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_descerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x8 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 3);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_chanaddr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_chanaddr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x10 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 4);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_chancmderr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_chancmderr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x20 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 5);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_cdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_cdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x40 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 6);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_dmadataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_dmadataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x80 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 7);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_rddataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_rddataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x100 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 8);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_wrdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_wrdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x200 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 9);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_descctrlerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_descctrlerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x400 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 10);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_desclenerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_desclenerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x800 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 11);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_cmpaddrerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_cmpaddrerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x1000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 12);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_intcfgerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_intcfgerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x2000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 13);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_crc_err_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_crc_err_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x10000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 16);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_xorqerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_xorqerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x20000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 17);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrsev_int_desccnterr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrsev_int_desccnterr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrsev_int_t _regval = 0x40000 & (((ioat_dma_chanerrsev_int_t )(_fieldval)) << 18);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->cfg_base, 0x188)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->cfg_base, 0x188, _regval);
    // No shadow register to write to
}

/*
 * Register chanerrptr: DMA Channel Error Pointer.
 * Type: ioat_dma.chanerrptr (Implicit type of DMA Channel Error Pointer. register)
 *   chan_err_ptr	(size 5, offset 0, init 0):	RO	DMA Channel error pointer
 *   _anon5	(size 3, offset 5, init 0):	RSVD	_
 */
static inline ioat_dma_chanerrptr_t ioat_dma_chanerrptr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerrptr_t ioat_dma_chanerrptr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x18c));
}

static inline ioat_dma_chanerrptr_t ioat_dma_chanerrptr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerrptr_t ioat_dma_chanerrptr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->cfg_base, 0x18c));
}

static inline void ioat_dma_chanerrptr_rawwr(__DN(t) *_dev, ioat_dma_chanerrptr_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrptr_rawwr(__DN(t) *_dev, ioat_dma_chanerrptr_t _regval)
{
    mackerel_write_addr_8(_dev->cfg_base, 0x18c, _regval);
}

// Register chanerrptr is not writeable
static inline int ioat_dma_chanerrptr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chanerrptr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chanerrptr_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x18c);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chanerrptr (DMA Channel Error Pointer.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chan_err_ptr =\t%" PRIx8 "\t(DMA Channel error pointer)\n", ioat_dma_chanerrptr_chan_err_ptr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon5 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_chanerrptr_chan_err_ptr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrptr_chan_err_ptr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrptr_t _regval = mackerel_read_addr_8(_dev->cfg_base, 0x18c);
    return(ioat_dma_chanerrptr_chan_err_ptr_extract(_regval));
}

/*
 * Register chancnt: Channel Count
 * Type: ioat_dma.chancnt (Implicit type of Channel Count register)
 *   num	(size 5, offset 0, init 0):	RO	Number of channels present
 *   _anon5	(size 3, offset 5, init 0):	RSVD	_
 */
static inline ioat_dma_chancnt_t ioat_dma_chancnt_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chancnt_t ioat_dma_chancnt_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x0));
}

static inline ioat_dma_chancnt_t ioat_dma_chancnt_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chancnt_t ioat_dma_chancnt_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x0));
}

static inline void ioat_dma_chancnt_rawwr(__DN(t) *_dev, ioat_dma_chancnt_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chancnt_rawwr(__DN(t) *_dev, ioat_dma_chancnt_t _regval)
{
    mackerel_write_addr_8(_dev->bar, 0x0, _regval);
}

// Register chancnt is not writeable
static inline int ioat_dma_chancnt_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chancnt_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chancnt_t _regval = mackerel_read_addr_8(_dev->bar, 0x0);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chancnt (Channel Count): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " num =\t%" PRIx8 "\t(Number of channels present)\n", ioat_dma_chancnt_num_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon5 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_chancnt_num_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancnt_num_rdf(__DN(t) *_dev)
{
    ioat_dma_chancnt_t _regval = mackerel_read_addr_8(_dev->bar, 0x0);
    return(ioat_dma_chancnt_num_extract(_regval));
}

/*
 * Register xfercap: Transfer Capacity
 * Type: ioat_dma.xfercap (Implicit type of Transfer Capacity register)
 *   max	(size 5, offset 0, init 0):	RO	Maximum transfer capability
 *   _anon5	(size 3, offset 5, init 0):	RSVD	_
 */
static inline ioat_dma_xfercap_t ioat_dma_xfercap_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_xfercap_t ioat_dma_xfercap_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x1));
}

static inline ioat_dma_xfercap_t ioat_dma_xfercap_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_xfercap_t ioat_dma_xfercap_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x1));
}

static inline void ioat_dma_xfercap_rawwr(__DN(t) *_dev, ioat_dma_xfercap_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_xfercap_rawwr(__DN(t) *_dev, ioat_dma_xfercap_t _regval)
{
    mackerel_write_addr_8(_dev->bar, 0x1, _regval);
}

// Register xfercap is not writeable
static inline int ioat_dma_xfercap_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_xfercap_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_xfercap_t _regval = mackerel_read_addr_8(_dev->bar, 0x1);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register xfercap (Transfer Capacity): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " max =\t%" PRIx8 "\t(Maximum transfer capability)\n", ioat_dma_xfercap_max_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon5 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_xfercap_max_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_xfercap_max_rdf(__DN(t) *_dev)
{
    ioat_dma_xfercap_t _regval = mackerel_read_addr_8(_dev->bar, 0x1);
    return(ioat_dma_xfercap_max_extract(_regval));
}

/*
 * Register genctrl: DMA General Control
 * Type: ioat_dma.genctrl (Implicit type of DMA General Control register)
 *   dbgen	(size 1, offset 0, init 0):	RW	DB Generation
 *   _anon1	(size 7, offset 1, init 0):	RSVD	_
 */
static inline ioat_dma_genctrl_t ioat_dma_genctrl_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_genctrl_t ioat_dma_genctrl_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x2));
}

static inline ioat_dma_genctrl_t ioat_dma_genctrl_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_genctrl_t ioat_dma_genctrl_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x2));
}

static inline void ioat_dma_genctrl_rawwr(__DN(t) *_dev, ioat_dma_genctrl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_genctrl_rawwr(__DN(t) *_dev, ioat_dma_genctrl_t _regval)
{
    mackerel_write_addr_8(_dev->bar, 0x2, _regval);
}

static inline void ioat_dma_genctrl_wr(__DN(t) *_dev, ioat_dma_genctrl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_genctrl_wr(__DN(t) *_dev, ioat_dma_genctrl_t _regval)
{
    _regval = (_regval & 0x1);
    // No MB1 fields present
    _regval = (_regval | (0xfe & mackerel_read_addr_8(_dev->bar, 0x2)));
    mackerel_write_addr_8(_dev->bar, 0x2, _regval);
}

static inline int ioat_dma_genctrl_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_genctrl_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_genctrl_t _regval = mackerel_read_addr_8(_dev->bar, 0x2);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register genctrl (DMA General Control): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dbgen =\t%" PRIx8 "\t(DB Generation)\n", ioat_dma_genctrl_dbgen_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon1 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_genctrl_dbgen_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_genctrl_dbgen_rdf(__DN(t) *_dev)
{
    ioat_dma_genctrl_t _regval = mackerel_read_addr_8(_dev->bar, 0x2);
    return(ioat_dma_genctrl_dbgen_extract(_regval));
}

static inline void ioat_dma_genctrl_dbgen_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_genctrl_dbgen_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_genctrl_t _regval = 0x1 & (((ioat_dma_genctrl_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfe & mackerel_read_addr_8(_dev->bar, 0x2)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_8(_dev->bar, 0x2, _regval);
    // No shadow register to write to
}

/*
 * Register intrctrl: Interrupt Control Register
 * Type: ioat_dma.intrctrl (Implicit type of Interrupt Control Register register)
 *   intp_en	(size 1, offset 0, init 0):	RW	Master interrupt enable bit. (not used in MSI-X model)
 *   intp_sts	(size 1, offset 1, init 0):	RO	Interrupt status. (not used in MSI-X model)
 *   intp	(size 1, offset 2, init 0):	RO	Interrupt. Set when status bit in attention is set
 *   msix_vec	(size 1, offset 3, init 0):	RW	MSI-X Vector Control. (Ignored by CB)
 *   _anon4	(size 4, offset 4, init 0):	RSVD	_
 */
static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x3));
}

static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_intrctrl_t ioat_dma_intrctrl_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x3));
}

static inline void ioat_dma_intrctrl_rawwr(__DN(t) *_dev, ioat_dma_intrctrl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_intrctrl_rawwr(__DN(t) *_dev, ioat_dma_intrctrl_t _regval)
{
    mackerel_write_addr_8(_dev->bar, 0x3, _regval);
}

static inline void ioat_dma_intrctrl_wr(__DN(t) *_dev, ioat_dma_intrctrl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_intrctrl_wr(__DN(t) *_dev, ioat_dma_intrctrl_t _regval)
{
    _regval = (_regval & 0xf);
    // No MB1 fields present
    _regval = (_regval | (0xf0 & mackerel_read_addr_8(_dev->bar, 0x3)));
    mackerel_write_addr_8(_dev->bar, 0x3, _regval);
}

static inline int ioat_dma_intrctrl_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_intrctrl_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_intrctrl_t _regval = mackerel_read_addr_8(_dev->bar, 0x3);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register intrctrl (Interrupt Control Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intp_en =\t%" PRIx8 "\t(Master interrupt enable bit. (not used in MSI-X model))\n", ioat_dma_intrctrl_intp_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intp_sts =\t%" PRIx8 "\t(Interrupt status. (not used in MSI-X model))\n", ioat_dma_intrctrl_intp_sts_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intp =\t%" PRIx8 "\t(Interrupt. Set when status bit in attention is set)\n", ioat_dma_intrctrl_intp_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " msix_vec =\t%" PRIx8 "\t(MSI-X Vector Control. (Ignored by CB))\n", ioat_dma_intrctrl_msix_vec_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon4 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_intrctrl_intp_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intrctrl_intp_en_rdf(__DN(t) *_dev)
{
    ioat_dma_intrctrl_t _regval = mackerel_read_addr_8(_dev->bar, 0x3);
    return(ioat_dma_intrctrl_intp_en_extract(_regval));
}

static inline uint8_t ioat_dma_intrctrl_intp_sts_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intrctrl_intp_sts_rdf(__DN(t) *_dev)
{
    ioat_dma_intrctrl_t _regval = mackerel_read_addr_8(_dev->bar, 0x3);
    return(ioat_dma_intrctrl_intp_sts_extract(_regval));
}

static inline uint8_t ioat_dma_intrctrl_intp_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intrctrl_intp_rdf(__DN(t) *_dev)
{
    ioat_dma_intrctrl_t _regval = mackerel_read_addr_8(_dev->bar, 0x3);
    return(ioat_dma_intrctrl_intp_extract(_regval));
}

static inline uint8_t ioat_dma_intrctrl_msix_vec_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intrctrl_msix_vec_rdf(__DN(t) *_dev)
{
    ioat_dma_intrctrl_t _regval = mackerel_read_addr_8(_dev->bar, 0x3);
    return(ioat_dma_intrctrl_msix_vec_extract(_regval));
}

static inline void ioat_dma_intrctrl_intp_en_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_intrctrl_intp_en_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_intrctrl_t _regval = 0x1 & (((ioat_dma_intrctrl_t )(_fieldval)) << 0);
    _regval = (_regval | (0xf8 & mackerel_read_addr_8(_dev->bar, 0x3)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_8(_dev->bar, 0x3, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_intrctrl_msix_vec_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_intrctrl_msix_vec_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_intrctrl_t _regval = 0x8 & (((ioat_dma_intrctrl_t )(_fieldval)) << 3);
    _regval = (_regval | (0xf1 & mackerel_read_addr_8(_dev->bar, 0x3)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_8(_dev->bar, 0x3, _regval);
    // No shadow register to write to
}

/*
 * Register attnstatus: Attention Status Register
 * Type: ioat_dma.attnstatus (Implicit type of Attention Status Register register)
 *   chanattn	(size 1, offset 0, init 0):	RO	Channel Attention. Represents the interrupt status
 *   _anon1	(size 31, offset 1, init 0):	RSVD	_
 */
static inline ioat_dma_attnstatus_t ioat_dma_attnstatus_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_attnstatus_t ioat_dma_attnstatus_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x4));
}

static inline ioat_dma_attnstatus_t ioat_dma_attnstatus_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_attnstatus_t ioat_dma_attnstatus_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x4));
}

static inline void ioat_dma_attnstatus_rawwr(__DN(t) *_dev, ioat_dma_attnstatus_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_attnstatus_rawwr(__DN(t) *_dev, ioat_dma_attnstatus_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x4, _regval);
}

// Register attnstatus is not writeable
static inline int ioat_dma_attnstatus_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_attnstatus_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_attnstatus_t _regval = mackerel_read_addr_32(_dev->bar, 0x4);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register attnstatus (Attention Status Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanattn =\t%" PRIx8 "\t(Channel Attention. Represents the interrupt status)\n", ioat_dma_attnstatus_chanattn_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon1 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_attnstatus_chanattn_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_attnstatus_chanattn_rdf(__DN(t) *_dev)
{
    ioat_dma_attnstatus_t _regval = mackerel_read_addr_32(_dev->bar, 0x4);
    return(ioat_dma_attnstatus_chanattn_extract(_regval));
}

/*
 * Register cbver: Crystal Beach Version Number
 * Type: ioat_dma.cbver (Implicit type of Crystal Beach Version Number register)
 *   minor	(size 4, offset 0, init 0):	RO	Minor Version Number
 *   major	(size 4, offset 4, init 0):	RO	Major Version Number
 */
static inline ioat_dma_cbver_t ioat_dma_cbver_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_cbver_t ioat_dma_cbver_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x8));
}

static inline ioat_dma_cbver_t ioat_dma_cbver_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_cbver_t ioat_dma_cbver_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x8));
}

static inline void ioat_dma_cbver_rawwr(__DN(t) *_dev, ioat_dma_cbver_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_cbver_rawwr(__DN(t) *_dev, ioat_dma_cbver_t _regval)
{
    mackerel_write_addr_8(_dev->bar, 0x8, _regval);
}

// Register cbver is not writeable
static inline int ioat_dma_cbver_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_cbver_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_cbver_t _regval = mackerel_read_addr_8(_dev->bar, 0x8);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register cbver (Crystal Beach Version Number): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " minor =\t%" PRIx8 "\t(Minor Version Number)\n", ioat_dma_cbver_minor_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " major =\t%" PRIx8 "\t(Major Version Number)\n", ioat_dma_cbver_major_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_cbver_minor_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cbver_minor_rdf(__DN(t) *_dev)
{
    ioat_dma_cbver_t _regval = mackerel_read_addr_8(_dev->bar, 0x8);
    return(ioat_dma_cbver_minor_extract(_regval));
}

static inline uint8_t ioat_dma_cbver_major_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cbver_major_rdf(__DN(t) *_dev)
{
    ioat_dma_cbver_t _regval = mackerel_read_addr_8(_dev->bar, 0x8);
    return(ioat_dma_cbver_major_extract(_regval));
}

/*
 * Register intrdelay: Interrupt Delay Register
 * Type: ioat_dma.intrdelay (Implicit type of Interrupt Delay Register register)
 *   delay_us	(size 14, offset 0, init 0):	RW	Interrupt delay time in micro seconds
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   coalesc	(size 1, offset 15, init 0):	RO	Interrupt Coalescing is supported
 */
static inline ioat_dma_intrdelay_t ioat_dma_intrdelay_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_intrdelay_t ioat_dma_intrdelay_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0xc));
}

static inline ioat_dma_intrdelay_t ioat_dma_intrdelay_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_intrdelay_t ioat_dma_intrdelay_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0xc));
}

static inline void ioat_dma_intrdelay_rawwr(__DN(t) *_dev, ioat_dma_intrdelay_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_intrdelay_rawwr(__DN(t) *_dev, ioat_dma_intrdelay_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0xc, _regval);
}

static inline void ioat_dma_intrdelay_wr(__DN(t) *_dev, ioat_dma_intrdelay_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_intrdelay_wr(__DN(t) *_dev, ioat_dma_intrdelay_t _regval)
{
    _regval = (_regval & 0xbfff);
    // No MB1 fields present
    _regval = (_regval | (0x4000 & mackerel_read_addr_16(_dev->bar, 0xc)));
    mackerel_write_addr_16(_dev->bar, 0xc, _regval);
}

static inline int ioat_dma_intrdelay_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_intrdelay_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_intrdelay_t _regval = mackerel_read_addr_16(_dev->bar, 0xc);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register intrdelay (Interrupt Delay Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " delay_us =\t%" PRIx16 "\t(Interrupt delay time in micro seconds)\n", ioat_dma_intrdelay_delay_us_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon14 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " coalesc =\t%" PRIx8 "\t(Interrupt Coalescing is supported)\n", ioat_dma_intrdelay_coalesc_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint16_t ioat_dma_intrdelay_delay_us_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_intrdelay_delay_us_rdf(__DN(t) *_dev)
{
    ioat_dma_intrdelay_t _regval = mackerel_read_addr_16(_dev->bar, 0xc);
    return(ioat_dma_intrdelay_delay_us_extract(_regval));
}

static inline uint8_t ioat_dma_intrdelay_coalesc_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_intrdelay_coalesc_rdf(__DN(t) *_dev)
{
    ioat_dma_intrdelay_t _regval = mackerel_read_addr_16(_dev->bar, 0xc);
    return(ioat_dma_intrdelay_coalesc_extract(_regval));
}

static inline void ioat_dma_intrdelay_delay_us_wrf(__DN(t) *_dev, uint16_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_intrdelay_delay_us_wrf(__DN(t) *_dev, uint16_t _fieldval)
{
    ioat_dma_intrdelay_t _regval = 0x3fff & (((ioat_dma_intrdelay_t )(_fieldval)) << 0);
    _regval = (_regval | (0x4000 & mackerel_read_addr_16(_dev->bar, 0xc)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->bar, 0xc, _regval);
    // No shadow register to write to
}

/*
 * Register cs_status: Chipset Status Register
 * Type: ioat_dma.cs_status (Implicit type of Chipset Status Register register)
 *   _anon0	(size 1, offset 0, init 0):	RSVD	_
 *   mmio_restrict	(size 1, offset 1, init 0):	RO	MMIO Restriction
 *   mem_bypass	(size 1, offset 2, init 0):	RO	Memory bypass
 *   addr_remap	(size 1, offset 3, init 0):	RO	Address Remapping: reflects the TE bit of VT-d
 *   _anon4	(size 12, offset 4, init 0):	RSVD	_
 */
static inline ioat_dma_cs_status_t ioat_dma_cs_status_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_cs_status_t ioat_dma_cs_status_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0xe));
}

static inline ioat_dma_cs_status_t ioat_dma_cs_status_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_cs_status_t ioat_dma_cs_status_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0xe));
}

static inline void ioat_dma_cs_status_rawwr(__DN(t) *_dev, ioat_dma_cs_status_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_cs_status_rawwr(__DN(t) *_dev, ioat_dma_cs_status_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0xe, _regval);
}

// Register cs_status is not writeable
static inline int ioat_dma_cs_status_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_cs_status_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_cs_status_t _regval = mackerel_read_addr_16(_dev->bar, 0xe);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register cs_status (Chipset Status Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon0 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mmio_restrict =\t%" PRIx8 "\t(MMIO Restriction)\n", ioat_dma_cs_status_mmio_restrict_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " mem_bypass =\t%" PRIx8 "\t(Memory bypass)\n", ioat_dma_cs_status_mem_bypass_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " addr_remap =\t%" PRIx8 "\t(Address Remapping: reflects the TE bit of VT-d)\n", ioat_dma_cs_status_addr_remap_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon4 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_cs_status_mmio_restrict_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cs_status_mmio_restrict_rdf(__DN(t) *_dev)
{
    ioat_dma_cs_status_t _regval = mackerel_read_addr_16(_dev->bar, 0xe);
    return(ioat_dma_cs_status_mmio_restrict_extract(_regval));
}

static inline uint8_t ioat_dma_cs_status_mem_bypass_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cs_status_mem_bypass_rdf(__DN(t) *_dev)
{
    ioat_dma_cs_status_t _regval = mackerel_read_addr_16(_dev->bar, 0xe);
    return(ioat_dma_cs_status_mem_bypass_extract(_regval));
}

static inline uint8_t ioat_dma_cs_status_addr_remap_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cs_status_addr_remap_rdf(__DN(t) *_dev)
{
    ioat_dma_cs_status_t _regval = mackerel_read_addr_16(_dev->bar, 0xe);
    return(ioat_dma_cs_status_addr_remap_extract(_regval));
}

/*
 * Register dmacapability: DMA Capability Register
 * Type: ioat_dma.dmacapability (Implicit type of DMA Capability Register register)
 *   pagebreak	(size 1, offset 0, init 0):	RO	Transfers crossing physical pages supported
 *   crc	(size 1, offset 1, init 0):	RO	CRC generation supported
 *   markerskip	(size 1, offset 2, init 0):	RO	Marker skipping is supported
 *   _anon3	(size 1, offset 3, init 0):	RSVD	_
 *   dca	(size 1, offset 4, init 0):	RW	Direct Cache Access is supported
 *   move_crc	(size 1, offset 5, init 0):	RO	Move and CRC op codes are supported
 *   block_fill	(size 1, offset 6, init 0):	RO	Block fill OP code is supported
 *   ext_apic_id	(size 1, offset 7, init 0):	RO	32bit APIC IDs are supported (otherwise 8bit APIC)
 *   xor	(size 1, offset 8, init 0):	RO	Only XOR for RAID 5 / 6 supported
 *   pq	(size 1, offset 9, init 0):	RO	Parity and Quotient Opcodes for RAID 5 / 6
 *   _anon10	(size 22, offset 10, init 0):	RSVD	_
 */
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x10));
}

static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dmacapability_t ioat_dma_dmacapability_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x10));
}

static inline void ioat_dma_dmacapability_rawwr(__DN(t) *_dev, ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmacapability_rawwr(__DN(t) *_dev, ioat_dma_dmacapability_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x10, _regval);
}

static inline void ioat_dma_dmacapability_wr(__DN(t) *_dev, ioat_dma_dmacapability_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmacapability_wr(__DN(t) *_dev, ioat_dma_dmacapability_t _regval)
{
    _regval = (_regval & 0x3f7);
    // No MB1 fields present
    _regval = (_regval | (0xfffffc08 & mackerel_read_addr_32(_dev->bar, 0x10)));
    mackerel_write_addr_32(_dev->bar, 0x10, _regval);
}

static inline int ioat_dma_dmacapability_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dmacapability_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dmacapability_t _regval = mackerel_read_addr_32(_dev->bar, 0x10);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dmacapability (DMA Capability Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pagebreak =\t%" PRIx8 "\t(Transfers crossing physical pages supported)\n", ioat_dma_dmacapability_pagebreak_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc =\t%" PRIx8 "\t(CRC generation supported)\n", ioat_dma_dmacapability_crc_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " markerskip =\t%" PRIx8 "\t(Marker skipping is supported)\n", ioat_dma_dmacapability_markerskip_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon3 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dca =\t%" PRIx8 "\t(Direct Cache Access is supported)\n", ioat_dma_dmacapability_dca_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " move_crc =\t%" PRIx8 "\t(Move and CRC op codes are supported)\n", ioat_dma_dmacapability_move_crc_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " block_fill =\t%" PRIx8 "\t(Block fill OP code is supported)\n", ioat_dma_dmacapability_block_fill_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ext_apic_id =\t%" PRIx8 "\t(32bit APIC IDs are supported (otherwise 8bit APIC))\n", ioat_dma_dmacapability_ext_apic_id_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xor =\t%" PRIx8 "\t(Only XOR for RAID 5 / 6 supported)\n", ioat_dma_dmacapability_xor_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " pq =\t%" PRIx8 "\t(Parity and Quotient Opcodes for RAID 5 / 6)\n", ioat_dma_dmacapability_pq_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon10 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_dmacapability_pagebreak_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_pagebreak_rdf(__DN(t) *_dev)
{
    ioat_dma_dmacapability_t _regval = mackerel_read_addr_32(_dev->bar, 0x10);
    return(ioat_dma_dmacapability_pagebreak_extract(_regval));
}

static inline uint8_t ioat_dma_dmacapability_crc_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_crc_rdf(__DN(t) *_dev)
{
    ioat_dma_dmacapability_t _regval = mackerel_read_addr_32(_dev->bar, 0x10);
    return(ioat_dma_dmacapability_crc_extract(_regval));
}

static inline uint8_t ioat_dma_dmacapability_markerskip_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_markerskip_rdf(__DN(t) *_dev)
{
    ioat_dma_dmacapability_t _regval = mackerel_read_addr_32(_dev->bar, 0x10);
    return(ioat_dma_dmacapability_markerskip_extract(_regval));
}

static inline uint8_t ioat_dma_dmacapability_dca_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_dca_rdf(__DN(t) *_dev)
{
    ioat_dma_dmacapability_t _regval = mackerel_read_addr_32(_dev->bar, 0x10);
    return(ioat_dma_dmacapability_dca_extract(_regval));
}

static inline uint8_t ioat_dma_dmacapability_move_crc_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_move_crc_rdf(__DN(t) *_dev)
{
    ioat_dma_dmacapability_t _regval = mackerel_read_addr_32(_dev->bar, 0x10);
    return(ioat_dma_dmacapability_move_crc_extract(_regval));
}

static inline uint8_t ioat_dma_dmacapability_block_fill_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_block_fill_rdf(__DN(t) *_dev)
{
    ioat_dma_dmacapability_t _regval = mackerel_read_addr_32(_dev->bar, 0x10);
    return(ioat_dma_dmacapability_block_fill_extract(_regval));
}

static inline uint8_t ioat_dma_dmacapability_ext_apic_id_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_ext_apic_id_rdf(__DN(t) *_dev)
{
    ioat_dma_dmacapability_t _regval = mackerel_read_addr_32(_dev->bar, 0x10);
    return(ioat_dma_dmacapability_ext_apic_id_extract(_regval));
}

static inline uint8_t ioat_dma_dmacapability_xor_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_xor_rdf(__DN(t) *_dev)
{
    ioat_dma_dmacapability_t _regval = mackerel_read_addr_32(_dev->bar, 0x10);
    return(ioat_dma_dmacapability_xor_extract(_regval));
}

static inline uint8_t ioat_dma_dmacapability_pq_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dmacapability_pq_rdf(__DN(t) *_dev)
{
    ioat_dma_dmacapability_t _regval = mackerel_read_addr_32(_dev->bar, 0x10);
    return(ioat_dma_dmacapability_pq_extract(_regval));
}

static inline void ioat_dma_dmacapability_dca_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dmacapability_dca_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dmacapability_t _regval = 0x10 & (((ioat_dma_dmacapability_t )(_fieldval)) << 4);
    _regval = (_regval | (0xfffffc08 & mackerel_read_addr_32(_dev->bar, 0x10)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x10, _regval);
    // No shadow register to write to
}

/*
 * Register dcaoffset: DCA Offset Register
 * Type: ioat_dma.uint16 (primitive type)
 */
static inline uint16_t ioat_dma_dcaoffset_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_dcaoffset_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x14));
}

static inline uint16_t ioat_dma_dcaoffset_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_dcaoffset_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x14));
}

static inline void ioat_dma_dcaoffset_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dcaoffset_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0x14, _regval);
}

// Register dcaoffset is not writeable
static inline int ioat_dma_dcaoffset_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dcaoffset_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->bar, 0x14);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dcaoffset (DCA Offset Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register cbprio: CB DMA Priority Register
 * Type: ioat_dma.uint8 (primitive type)
 */
static inline uint8_t ioat_dma_cbprio_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cbprio_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x40));
}

static inline uint8_t ioat_dma_cbprio_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_cbprio_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x40));
}

static inline void ioat_dma_cbprio_rawwr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_cbprio_rawwr(__DN(t) *_dev, uint8_t _regval)
{
    mackerel_write_addr_8(_dev->bar, 0x40, _regval);
}

// Register cbprio is not writeable
static inline int ioat_dma_cbprio_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_cbprio_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint8_t _regval = mackerel_read_addr_8(_dev->bar, 0x40);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register cbprio (CB DMA Priority Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx8 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register chanctrl: Channel Control Register
 * Type: ioat_dma.chanctrl (Implicit type of Channel Control Register register)
 *   intp_dis	(size 1, offset 0, init 0):	RWC	Interrupt disable
 *   _anon1	(size 1, offset 1, init 0):	RSVD	_
 *   err_cmp_en	(size 1, offset 2, init 0):	RW	Error Completion Enabled
 *   err_abort	(size 1, offset 3, init 0):	RW	Any Error Abort Enbled
 *   err_int_en	(size 1, offset 4, init 0):	RW	Error Interrupt Enabled
 *   snoop_ctrl	(size 1, offset 5, init 0):	RW	Descriptor address snoop control
 *   _anon6	(size 2, offset 6, init 0):	RSVD	_
 *   in_use	(size 1, offset 8, init 0):	RW	Channel is in use
 *   dca_en	(size 1, offset 9, init 0):	RW	Direct Cache access enabled
 *   _anon10	(size 6, offset 10, init 0):	RSVD	_
 */
static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x80));
}

static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanctrl_t ioat_dma_chanctrl_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x80));
}

static inline void ioat_dma_chanctrl_rawwr(__DN(t) *_dev, ioat_dma_chanctrl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanctrl_rawwr(__DN(t) *_dev, ioat_dma_chanctrl_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0x80, _regval);
}

static inline void ioat_dma_chanctrl_wr(__DN(t) *_dev, ioat_dma_chanctrl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanctrl_wr(__DN(t) *_dev, ioat_dma_chanctrl_t _regval)
{
    _regval = (_regval & 0x33d);
    // No MB1 fields present
    _regval = (_regval | (0xfcc2 & mackerel_read_addr_16(_dev->bar, 0x80)));
    mackerel_write_addr_16(_dev->bar, 0x80, _regval);
}

static inline int ioat_dma_chanctrl_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chanctrl_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chanctrl_t _regval = mackerel_read_addr_16(_dev->bar, 0x80);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chanctrl (Channel Control Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intp_dis =\t%" PRIx8 "\t(Interrupt disable)\n", ioat_dma_chanctrl_intp_dis_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon1 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " err_cmp_en =\t%" PRIx8 "\t(Error Completion Enabled)\n", ioat_dma_chanctrl_err_cmp_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " err_abort =\t%" PRIx8 "\t(Any Error Abort Enbled)\n", ioat_dma_chanctrl_err_abort_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " err_int_en =\t%" PRIx8 "\t(Error Interrupt Enabled)\n", ioat_dma_chanctrl_err_int_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " snoop_ctrl =\t%" PRIx8 "\t(Descriptor address snoop control)\n", ioat_dma_chanctrl_snoop_ctrl_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon6 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " in_use =\t%" PRIx8 "\t(Channel is in use)\n", ioat_dma_chanctrl_in_use_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dca_en =\t%" PRIx8 "\t(Direct Cache access enabled)\n", ioat_dma_chanctrl_dca_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon10 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_chanctrl_intp_dis_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_intp_dis_rdf(__DN(t) *_dev)
{
    ioat_dma_chanctrl_t _regval = mackerel_read_addr_16(_dev->bar, 0x80);
    return(ioat_dma_chanctrl_intp_dis_extract(_regval));
}

static inline uint8_t ioat_dma_chanctrl_err_cmp_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_err_cmp_en_rdf(__DN(t) *_dev)
{
    ioat_dma_chanctrl_t _regval = mackerel_read_addr_16(_dev->bar, 0x80);
    return(ioat_dma_chanctrl_err_cmp_en_extract(_regval));
}

static inline uint8_t ioat_dma_chanctrl_err_abort_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_err_abort_rdf(__DN(t) *_dev)
{
    ioat_dma_chanctrl_t _regval = mackerel_read_addr_16(_dev->bar, 0x80);
    return(ioat_dma_chanctrl_err_abort_extract(_regval));
}

static inline uint8_t ioat_dma_chanctrl_err_int_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_err_int_en_rdf(__DN(t) *_dev)
{
    ioat_dma_chanctrl_t _regval = mackerel_read_addr_16(_dev->bar, 0x80);
    return(ioat_dma_chanctrl_err_int_en_extract(_regval));
}

static inline uint8_t ioat_dma_chanctrl_snoop_ctrl_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_snoop_ctrl_rdf(__DN(t) *_dev)
{
    ioat_dma_chanctrl_t _regval = mackerel_read_addr_16(_dev->bar, 0x80);
    return(ioat_dma_chanctrl_snoop_ctrl_extract(_regval));
}

static inline uint8_t ioat_dma_chanctrl_in_use_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_in_use_rdf(__DN(t) *_dev)
{
    ioat_dma_chanctrl_t _regval = mackerel_read_addr_16(_dev->bar, 0x80);
    return(ioat_dma_chanctrl_in_use_extract(_regval));
}

static inline uint8_t ioat_dma_chanctrl_dca_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanctrl_dca_en_rdf(__DN(t) *_dev)
{
    ioat_dma_chanctrl_t _regval = mackerel_read_addr_16(_dev->bar, 0x80);
    return(ioat_dma_chanctrl_dca_en_extract(_regval));
}

static inline void ioat_dma_chanctrl_intp_dis_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanctrl_intp_dis_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanctrl_t _regval = 0x1 & (((ioat_dma_chanctrl_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfffe & mackerel_read_addr_16(_dev->bar, 0x80)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->bar, 0x80, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanctrl_err_cmp_en_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanctrl_err_cmp_en_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanctrl_t _regval = 0x4 & (((ioat_dma_chanctrl_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfffa & mackerel_read_addr_16(_dev->bar, 0x80)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->bar, 0x80, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanctrl_err_abort_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanctrl_err_abort_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanctrl_t _regval = 0x8 & (((ioat_dma_chanctrl_t )(_fieldval)) << 3);
    _regval = (_regval | (0xfff6 & mackerel_read_addr_16(_dev->bar, 0x80)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->bar, 0x80, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanctrl_err_int_en_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanctrl_err_int_en_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanctrl_t _regval = 0x10 & (((ioat_dma_chanctrl_t )(_fieldval)) << 4);
    _regval = (_regval | (0xffee & mackerel_read_addr_16(_dev->bar, 0x80)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->bar, 0x80, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanctrl_snoop_ctrl_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanctrl_snoop_ctrl_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanctrl_t _regval = 0x20 & (((ioat_dma_chanctrl_t )(_fieldval)) << 5);
    _regval = (_regval | (0xffde & mackerel_read_addr_16(_dev->bar, 0x80)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->bar, 0x80, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanctrl_in_use_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanctrl_in_use_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanctrl_t _regval = 0x100 & (((ioat_dma_chanctrl_t )(_fieldval)) << 8);
    _regval = (_regval | (0xfefe & mackerel_read_addr_16(_dev->bar, 0x80)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->bar, 0x80, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanctrl_dca_en_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanctrl_dca_en_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanctrl_t _regval = 0x200 & (((ioat_dma_chanctrl_t )(_fieldval)) << 9);
    _regval = (_regval | (0xfdfe & mackerel_read_addr_16(_dev->bar, 0x80)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->bar, 0x80, _regval);
    // No shadow register to write to
}

/*
 * Register dma_comp: DMA Compatibility Register
 * Type: ioat_dma.dma_comp (Implicit type of DMA Compatibility Register register)
 *   v1	(size 1, offset 0, init 0):	RO	NOT compatible with CB Version 1
 *   v2	(size 1, offset 1, init 0):	RO	Compatible with CB Version 2
 *   v3	(size 1, offset 2, init 0):	RO	Compatible with CB Version 3
 *   _anon3	(size 13, offset 3, init 0):	RSVD	_
 */
static inline ioat_dma_dma_comp_t ioat_dma_dma_comp_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dma_comp_t ioat_dma_dma_comp_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x82));
}

static inline ioat_dma_dma_comp_t ioat_dma_dma_comp_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dma_comp_t ioat_dma_dma_comp_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x82));
}

static inline void ioat_dma_dma_comp_rawwr(__DN(t) *_dev, ioat_dma_dma_comp_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dma_comp_rawwr(__DN(t) *_dev, ioat_dma_dma_comp_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0x82, _regval);
}

// Register dma_comp is not writeable
static inline int ioat_dma_dma_comp_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dma_comp_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dma_comp_t _regval = mackerel_read_addr_16(_dev->bar, 0x82);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dma_comp (DMA Compatibility Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " v1 =\t%" PRIx8 "\t(NOT compatible with CB Version 1)\n", ioat_dma_dma_comp_v1_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " v2 =\t%" PRIx8 "\t(Compatible with CB Version 2)\n", ioat_dma_dma_comp_v2_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " v3 =\t%" PRIx8 "\t(Compatible with CB Version 3)\n", ioat_dma_dma_comp_v3_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon3 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_dma_comp_v1_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dma_comp_v1_rdf(__DN(t) *_dev)
{
    ioat_dma_dma_comp_t _regval = mackerel_read_addr_16(_dev->bar, 0x82);
    return(ioat_dma_dma_comp_v1_extract(_regval));
}

static inline uint8_t ioat_dma_dma_comp_v2_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dma_comp_v2_rdf(__DN(t) *_dev)
{
    ioat_dma_dma_comp_t _regval = mackerel_read_addr_16(_dev->bar, 0x82);
    return(ioat_dma_dma_comp_v2_extract(_regval));
}

static inline uint8_t ioat_dma_dma_comp_v3_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dma_comp_v3_rdf(__DN(t) *_dev)
{
    ioat_dma_dma_comp_t _regval = mackerel_read_addr_16(_dev->bar, 0x82);
    return(ioat_dma_dma_comp_v3_extract(_regval));
}

/*
 * Register chancmd: DMA Channel Command Register.
 * Type: ioat_dma.chancmd (Implicit type of DMA Channel Command Register. register)
 *   start	(size 1, offset 0, init 0):	RW	Start
 *   append	(size 1, offset 1, init 0):	RW	Append
 *   susp	(size 1, offset 2, init 0):	RW	Suspend the DMA channel
 *   abort	(size 1, offset 3, init 0):	RW	Abort
 *   resume	(size 1, offset 4, init 0):	RW	resume
 *   reset	(size 1, offset 5, init 0):	RW	Reset DMA channel
 *   _anon6	(size 2, offset 6, init 0):	RSVD	_
 */
static inline ioat_dma_chancmd_t ioat_dma_chancmd_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chancmd_t ioat_dma_chancmd_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x84));
}

static inline ioat_dma_chancmd_t ioat_dma_chancmd_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chancmd_t ioat_dma_chancmd_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x84));
}

static inline void ioat_dma_chancmd_rawwr(__DN(t) *_dev, ioat_dma_chancmd_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmd_rawwr(__DN(t) *_dev, ioat_dma_chancmd_t _regval)
{
    mackerel_write_addr_8(_dev->bar, 0x84, _regval);
}

static inline void ioat_dma_chancmd_wr(__DN(t) *_dev, ioat_dma_chancmd_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmd_wr(__DN(t) *_dev, ioat_dma_chancmd_t _regval)
{
    _regval = (_regval & 0x3f);
    // No MB1 fields present
    _regval = (_regval | (0xc0 & mackerel_read_addr_8(_dev->bar, 0x84)));
    mackerel_write_addr_8(_dev->bar, 0x84, _regval);
}

static inline int ioat_dma_chancmd_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chancmd_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chancmd_t _regval = mackerel_read_addr_8(_dev->bar, 0x84);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chancmd (DMA Channel Command Register.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " start =\t%" PRIx8 "\t(Start)\n", ioat_dma_chancmd_start_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " append =\t%" PRIx8 "\t(Append)\n", ioat_dma_chancmd_append_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " susp =\t%" PRIx8 "\t(Suspend the DMA channel)\n", ioat_dma_chancmd_susp_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " abort =\t%" PRIx8 "\t(Abort)\n", ioat_dma_chancmd_abort_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " resume =\t%" PRIx8 "\t(resume)\n", ioat_dma_chancmd_resume_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " reset =\t%" PRIx8 "\t(Reset DMA channel)\n", ioat_dma_chancmd_reset_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon6 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_chancmd_start_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_start_rdf(__DN(t) *_dev)
{
    ioat_dma_chancmd_t _regval = mackerel_read_addr_8(_dev->bar, 0x84);
    return(ioat_dma_chancmd_start_extract(_regval));
}

static inline uint8_t ioat_dma_chancmd_append_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_append_rdf(__DN(t) *_dev)
{
    ioat_dma_chancmd_t _regval = mackerel_read_addr_8(_dev->bar, 0x84);
    return(ioat_dma_chancmd_append_extract(_regval));
}

static inline uint8_t ioat_dma_chancmd_susp_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_susp_rdf(__DN(t) *_dev)
{
    ioat_dma_chancmd_t _regval = mackerel_read_addr_8(_dev->bar, 0x84);
    return(ioat_dma_chancmd_susp_extract(_regval));
}

static inline uint8_t ioat_dma_chancmd_abort_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_abort_rdf(__DN(t) *_dev)
{
    ioat_dma_chancmd_t _regval = mackerel_read_addr_8(_dev->bar, 0x84);
    return(ioat_dma_chancmd_abort_extract(_regval));
}

static inline uint8_t ioat_dma_chancmd_resume_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_resume_rdf(__DN(t) *_dev)
{
    ioat_dma_chancmd_t _regval = mackerel_read_addr_8(_dev->bar, 0x84);
    return(ioat_dma_chancmd_resume_extract(_regval));
}

static inline uint8_t ioat_dma_chancmd_reset_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chancmd_reset_rdf(__DN(t) *_dev)
{
    ioat_dma_chancmd_t _regval = mackerel_read_addr_8(_dev->bar, 0x84);
    return(ioat_dma_chancmd_reset_extract(_regval));
}

static inline void ioat_dma_chancmd_start_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmd_start_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chancmd_t _regval = 0x1 & (((ioat_dma_chancmd_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfe & mackerel_read_addr_8(_dev->bar, 0x84)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_8(_dev->bar, 0x84, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chancmd_append_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmd_append_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chancmd_t _regval = 0x2 & (((ioat_dma_chancmd_t )(_fieldval)) << 1);
    _regval = (_regval | (0xfd & mackerel_read_addr_8(_dev->bar, 0x84)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_8(_dev->bar, 0x84, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chancmd_susp_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmd_susp_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chancmd_t _regval = 0x4 & (((ioat_dma_chancmd_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfb & mackerel_read_addr_8(_dev->bar, 0x84)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_8(_dev->bar, 0x84, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chancmd_abort_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmd_abort_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chancmd_t _regval = 0x8 & (((ioat_dma_chancmd_t )(_fieldval)) << 3);
    _regval = (_regval | (0xf7 & mackerel_read_addr_8(_dev->bar, 0x84)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_8(_dev->bar, 0x84, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chancmd_resume_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmd_resume_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chancmd_t _regval = 0x10 & (((ioat_dma_chancmd_t )(_fieldval)) << 4);
    _regval = (_regval | (0xef & mackerel_read_addr_8(_dev->bar, 0x84)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_8(_dev->bar, 0x84, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chancmd_reset_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmd_reset_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chancmd_t _regval = 0x20 & (((ioat_dma_chancmd_t )(_fieldval)) << 5);
    _regval = (_regval | (0xdf & mackerel_read_addr_8(_dev->bar, 0x84)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_8(_dev->bar, 0x84, _regval);
    // No shadow register to write to
}

/*
 * Register dmacount: DMA Descriptor Count Register
 * Type: ioat_dma.uint16 (primitive type)
 */
static inline uint16_t ioat_dma_dmacount_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_dmacount_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x86));
}

static inline uint16_t ioat_dma_dmacount_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_dmacount_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x86));
}

static inline void ioat_dma_dmacount_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmacount_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0x86, _regval);
}

static inline void ioat_dma_dmacount_wr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dmacount_wr(__DN(t) *_dev, uint16_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_16(_dev->bar, 0x86, _regval);
}

static inline int ioat_dma_dmacount_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dmacount_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->bar, 0x86);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dmacount (DMA Descriptor Count Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register chansts_lo: Channel Status Lo Register.
 * Type: ioat_dma.chansts_lo (Implicit type of Channel Status Lo Register. register)
 *   dma_trans_state	(size 3, offset 0, init 0):	RO	DMA transfer State
 *   _anon3	(size 3, offset 3, init 0):	RSVD	_
 *   cmpdscaddr	(size 26, offset 6, init 0):	RO	Uppder address of the last descriptor processed
 */
static inline ioat_dma_chansts_lo_t ioat_dma_chansts_lo_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chansts_lo_t ioat_dma_chansts_lo_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x88));
}

static inline ioat_dma_chansts_lo_t ioat_dma_chansts_lo_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chansts_lo_t ioat_dma_chansts_lo_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x88));
}

static inline void ioat_dma_chansts_lo_rawwr(__DN(t) *_dev, ioat_dma_chansts_lo_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chansts_lo_rawwr(__DN(t) *_dev, ioat_dma_chansts_lo_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x88, _regval);
}

// Register chansts_lo is not writeable
static inline int ioat_dma_chansts_lo_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chansts_lo_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chansts_lo_t _regval = mackerel_read_addr_32(_dev->bar, 0x88);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chansts_lo (Channel Status Lo Register.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dma_trans_state =\t%" PRIx8 "\t(DMA transfer State)\n", ioat_dma_chansts_lo_dma_trans_state_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon3 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpdscaddr =\t%" PRIx32 "\t(Uppder address of the last descriptor processed)\n", ioat_dma_chansts_lo_cmpdscaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_chansts_lo_dma_trans_state_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chansts_lo_dma_trans_state_rdf(__DN(t) *_dev)
{
    ioat_dma_chansts_lo_t _regval = mackerel_read_addr_32(_dev->bar, 0x88);
    return(ioat_dma_chansts_lo_dma_trans_state_extract(_regval));
}

static inline uint32_t ioat_dma_chansts_lo_cmpdscaddr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chansts_lo_cmpdscaddr_rdf(__DN(t) *_dev)
{
    ioat_dma_chansts_lo_t _regval = mackerel_read_addr_32(_dev->bar, 0x88);
    return(ioat_dma_chansts_lo_cmpdscaddr_extract(_regval));
}

/*
 * Register chansts_hi: Channel Status Hi Register.
 * Type: ioat_dma.uint32 (primitive type)
 */
static inline uint32_t ioat_dma_chansts_hi_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chansts_hi_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x8c));
}

static inline uint32_t ioat_dma_chansts_hi_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chansts_hi_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x8c));
}

static inline void ioat_dma_chansts_hi_rawwr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chansts_hi_rawwr(__DN(t) *_dev, uint32_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x8c, _regval);
}

// Register chansts_hi is not writeable
static inline int ioat_dma_chansts_hi_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chansts_hi_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint32_t _regval = mackerel_read_addr_32(_dev->bar, 0x8c);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chansts_hi (Channel Status Hi Register.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx32 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register chainaddr_lo: Descriptor Chain Address Lo Register.
 * Type: ioat_dma.chainaddr_lo (Implicit type of Descriptor Chain Address Lo Register. register)
 *   _anon0	(size 6, offset 0, init 0):	MBZ	_
 *   descaddr_lo	(size 26, offset 6, init 0):	RW	Address of the first descriptor
 */
static inline ioat_dma_chainaddr_lo_t ioat_dma_chainaddr_lo_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chainaddr_lo_t ioat_dma_chainaddr_lo_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x90));
}

static inline ioat_dma_chainaddr_lo_t ioat_dma_chainaddr_lo_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chainaddr_lo_t ioat_dma_chainaddr_lo_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x90));
}

static inline void ioat_dma_chainaddr_lo_rawwr(__DN(t) *_dev, ioat_dma_chainaddr_lo_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chainaddr_lo_rawwr(__DN(t) *_dev, ioat_dma_chainaddr_lo_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x90, _regval);
}

static inline void ioat_dma_chainaddr_lo_wr(__DN(t) *_dev, ioat_dma_chainaddr_lo_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chainaddr_lo_wr(__DN(t) *_dev, ioat_dma_chainaddr_lo_t _regval)
{
    _regval = (_regval & 0xffffffc0);
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_32(_dev->bar, 0x90, _regval);
}

static inline int ioat_dma_chainaddr_lo_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chainaddr_lo_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chainaddr_lo_t _regval = mackerel_read_addr_32(_dev->bar, 0x90);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chainaddr_lo (Descriptor Chain Address Lo Register.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon0 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descaddr_lo =\t%" PRIx32 "\t(Address of the first descriptor)\n", ioat_dma_chainaddr_lo_descaddr_lo_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint32_t ioat_dma_chainaddr_lo_descaddr_lo_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chainaddr_lo_descaddr_lo_rdf(__DN(t) *_dev)
{
    ioat_dma_chainaddr_lo_t _regval = mackerel_read_addr_32(_dev->bar, 0x90);
    return(ioat_dma_chainaddr_lo_descaddr_lo_extract(_regval));
}

static inline void ioat_dma_chainaddr_lo_descaddr_lo_wrf(__DN(t) *_dev, uint32_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chainaddr_lo_descaddr_lo_wrf(__DN(t) *_dev, uint32_t _fieldval)
{
    ioat_dma_chainaddr_lo_t _regval = 0xffffffc0 & (((ioat_dma_chainaddr_lo_t )(_fieldval)) << 6);
    // No pre-read of register required
    // No read of register shadow required
    _regval = (_regval & 0xffffffc0);
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x90, _regval);
    // No shadow register to write to
}

/*
 * Register chainaddr_hi: Descriptor Chain Address Hi Register.
 * Type: ioat_dma.uint32 (primitive type)
 */
static inline uint32_t ioat_dma_chainaddr_hi_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chainaddr_hi_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x94));
}

static inline uint32_t ioat_dma_chainaddr_hi_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chainaddr_hi_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x94));
}

static inline void ioat_dma_chainaddr_hi_rawwr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chainaddr_hi_rawwr(__DN(t) *_dev, uint32_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x94, _regval);
}

static inline void ioat_dma_chainaddr_hi_wr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chainaddr_hi_wr(__DN(t) *_dev, uint32_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_32(_dev->bar, 0x94, _regval);
}

static inline int ioat_dma_chainaddr_hi_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chainaddr_hi_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint32_t _regval = mackerel_read_addr_32(_dev->bar, 0x94);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chainaddr_hi (Descriptor Chain Address Hi Register.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx32 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register chancmp_lo: Channel Completion Address Lo Register.
 * Type: ioat_dma.uint32 (primitive type)
 */
static inline uint32_t ioat_dma_chancmp_lo_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chancmp_lo_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x98));
}

static inline uint32_t ioat_dma_chancmp_lo_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chancmp_lo_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x98));
}

static inline void ioat_dma_chancmp_lo_rawwr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmp_lo_rawwr(__DN(t) *_dev, uint32_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x98, _regval);
}

static inline void ioat_dma_chancmp_lo_wr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmp_lo_wr(__DN(t) *_dev, uint32_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_32(_dev->bar, 0x98, _regval);
}

static inline int ioat_dma_chancmp_lo_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chancmp_lo_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint32_t _regval = mackerel_read_addr_32(_dev->bar, 0x98);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chancmp_lo (Channel Completion Address Lo Register.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx32 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register chancmp_hi: Channel Completion Address Hi Register.
 * Type: ioat_dma.uint32 (primitive type)
 */
static inline uint32_t ioat_dma_chancmp_hi_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chancmp_hi_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x9c));
}

static inline uint32_t ioat_dma_chancmp_hi_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_chancmp_hi_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x9c));
}

static inline void ioat_dma_chancmp_hi_rawwr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmp_hi_rawwr(__DN(t) *_dev, uint32_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x9c, _regval);
}

static inline void ioat_dma_chancmp_hi_wr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chancmp_hi_wr(__DN(t) *_dev, uint32_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_32(_dev->bar, 0x9c, _regval);
}

static inline int ioat_dma_chancmp_hi_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chancmp_hi_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint32_t _regval = mackerel_read_addr_32(_dev->bar, 0x9c);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chancmp_hi (Channel Completion Address Hi Register.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx32 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register chanerr: Channel Error Register
 * Type: ioat_dma.chanerr (Implicit type of Channel Error Register register)
 *   dmatranserr	(size 1, offset 0, init 0):	RWCS	DMA Transfer Source address error
 *   dmaxfererr	(size 1, offset 1, init 0):	RWCS	DMA Transfer Destination address error
 *   nxtdescerr	(size 1, offset 2, init 0):	RWCS	Next Descriptor Address error
 *   descerr	(size 1, offset 3, init 0):	RWCS	Descriptor error
 *   chanaddr	(size 1, offset 4, init 0):	RWCS	Channel address value error
 *   chancmderr	(size 1, offset 5, init 0):	RWCS	Channel command error
 *   cdataerr	(size 1, offset 6, init 0):	RWCS	Data parity error
 *   dmadataerr	(size 1, offset 7, init 0):	RWCS	DMA Data Parity error
 *   rddataerr	(size 1, offset 8, init 0):	RWCS	Read Data error
 *   wrdataerr	(size 1, offset 9, init 0):	RWCS	Write data error
 *   descctrlerr	(size 1, offset 10, init 0):	RWCS	Description control  error
 *   desclenerr	(size 1, offset 11, init 0):	RWCS	Description length error
 *   cmpaddrerr	(size 1, offset 12, init 0):	RWCS	Completion Address error
 *   intcfgerr	(size 1, offset 13, init 0):	RWCS	Interrupt confiuguratio error
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   unaffilerr	(size 1, offset 15, init 0):	RO	Unaffiliated Error
 *   crc_err	(size 1, offset 16, init 0):	RWCS	CRC test failed
 *   xorqerr	(size 1, offset 17, init 0):	RWCS	Xor error
 *   desccnterr	(size 1, offset 18, init 0):	RWCS	Descriptor Count error
 *   _anon19	(size 13, offset 19, init 0):	RSVD	_
 */
static inline ioat_dma_chanerr_t ioat_dma_chanerr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0xa8));
}

static inline ioat_dma_chanerr_t ioat_dma_chanerr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerr_t ioat_dma_chanerr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0xa8));
}

static inline void ioat_dma_chanerr_rawwr(__DN(t) *_dev, ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_rawwr(__DN(t) *_dev, ioat_dma_chanerr_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
}

static inline void ioat_dma_chanerr_wr(__DN(t) *_dev, ioat_dma_chanerr_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_wr(__DN(t) *_dev, ioat_dma_chanerr_t _regval)
{
    _regval = (_regval & 0x7bfff);
    // No MB1 fields present
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
}

static inline int ioat_dma_chanerr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chanerr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chanerr (Channel Error Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmatranserr =\t%" PRIx8 "\t(DMA Transfer Source address error)\n", ioat_dma_chanerr_dmatranserr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmaxfererr =\t%" PRIx8 "\t(DMA Transfer Destination address error)\n", ioat_dma_chanerr_dmaxfererr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " nxtdescerr =\t%" PRIx8 "\t(Next Descriptor Address error)\n", ioat_dma_chanerr_nxtdescerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descerr =\t%" PRIx8 "\t(Descriptor error)\n", ioat_dma_chanerr_descerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanaddr =\t%" PRIx8 "\t(Channel address value error)\n", ioat_dma_chanerr_chanaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chancmderr =\t%" PRIx8 "\t(Channel command error)\n", ioat_dma_chanerr_chancmderr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cdataerr =\t%" PRIx8 "\t(Data parity error)\n", ioat_dma_chanerr_cdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmadataerr =\t%" PRIx8 "\t(DMA Data Parity error)\n", ioat_dma_chanerr_dmadataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rddataerr =\t%" PRIx8 "\t(Read Data error)\n", ioat_dma_chanerr_rddataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " wrdataerr =\t%" PRIx8 "\t(Write data error)\n", ioat_dma_chanerr_wrdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descctrlerr =\t%" PRIx8 "\t(Description control  error)\n", ioat_dma_chanerr_descctrlerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desclenerr =\t%" PRIx8 "\t(Description length error)\n", ioat_dma_chanerr_desclenerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpaddrerr =\t%" PRIx8 "\t(Completion Address error)\n", ioat_dma_chanerr_cmpaddrerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intcfgerr =\t%" PRIx8 "\t(Interrupt confiuguratio error)\n", ioat_dma_chanerr_intcfgerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon14 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unaffilerr =\t%" PRIx8 "\t(Unaffiliated Error)\n", ioat_dma_chanerr_unaffilerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc_err =\t%" PRIx8 "\t(CRC test failed)\n", ioat_dma_chanerr_crc_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xorqerr =\t%" PRIx8 "\t(Xor error)\n", ioat_dma_chanerr_xorqerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desccnterr =\t%" PRIx8 "\t(Descriptor Count error)\n", ioat_dma_chanerr_desccnterr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon19 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_chanerr_dmatranserr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_dmatranserr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_dmatranserr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_dmaxfererr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_dmaxfererr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_dmaxfererr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_nxtdescerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_nxtdescerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_nxtdescerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_descerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_descerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_descerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_chanaddr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_chanaddr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_chanaddr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_chancmderr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_chancmderr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_chancmderr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_cdataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_cdataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_cdataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_dmadataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_dmadataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_dmadataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_rddataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_rddataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_rddataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_wrdataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_wrdataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_wrdataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_descctrlerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_descctrlerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_descctrlerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_desclenerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_desclenerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_desclenerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_cmpaddrerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_cmpaddrerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_cmpaddrerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_intcfgerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_intcfgerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_intcfgerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_unaffilerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_unaffilerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_unaffilerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_crc_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_crc_err_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_crc_err_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_xorqerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_xorqerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_xorqerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerr_desccnterr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerr_desccnterr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerr_t _regval = mackerel_read_addr_32(_dev->bar, 0xa8);
    return(ioat_dma_chanerr_desccnterr_extract(_regval));
}

static inline void ioat_dma_chanerr_dmatranserr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_dmatranserr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x1 & (((ioat_dma_chanerr_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_dmaxfererr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_dmaxfererr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x2 & (((ioat_dma_chanerr_t )(_fieldval)) << 1);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_nxtdescerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_nxtdescerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x4 & (((ioat_dma_chanerr_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_descerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_descerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x8 & (((ioat_dma_chanerr_t )(_fieldval)) << 3);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_chanaddr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_chanaddr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x10 & (((ioat_dma_chanerr_t )(_fieldval)) << 4);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_chancmderr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_chancmderr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x20 & (((ioat_dma_chanerr_t )(_fieldval)) << 5);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_cdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_cdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x40 & (((ioat_dma_chanerr_t )(_fieldval)) << 6);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_dmadataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_dmadataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x80 & (((ioat_dma_chanerr_t )(_fieldval)) << 7);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_rddataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_rddataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x100 & (((ioat_dma_chanerr_t )(_fieldval)) << 8);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_wrdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_wrdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x200 & (((ioat_dma_chanerr_t )(_fieldval)) << 9);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_descctrlerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_descctrlerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x400 & (((ioat_dma_chanerr_t )(_fieldval)) << 10);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_desclenerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_desclenerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x800 & (((ioat_dma_chanerr_t )(_fieldval)) << 11);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_cmpaddrerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_cmpaddrerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x1000 & (((ioat_dma_chanerr_t )(_fieldval)) << 12);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_intcfgerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_intcfgerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x2000 & (((ioat_dma_chanerr_t )(_fieldval)) << 13);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_crc_err_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_crc_err_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x10000 & (((ioat_dma_chanerr_t )(_fieldval)) << 16);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_xorqerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_xorqerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x20000 & (((ioat_dma_chanerr_t )(_fieldval)) << 17);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerr_desccnterr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerr_desccnterr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerr_t _regval = 0x40000 & (((ioat_dma_chanerr_t )(_fieldval)) << 18);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xa8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xa8, _regval);
    // No shadow register to write to
}

/*
 * Register chanerrmsk: Channel Error Mask Register.
 * Type: ioat_dma.chanerrmsk (Implicit type of Channel Error Mask Register. register)
 *   dmatranserr	(size 1, offset 0, init 0):	RWCS	DMA Transfer Source address error
 *   dmaxfererr	(size 1, offset 1, init 0):	RWCS	DMA Transfer Destination address error
 *   nxtdescerr	(size 1, offset 2, init 0):	RWCS	Next Descriptor Address error
 *   descerr	(size 1, offset 3, init 0):	RWCS	Descriptor error
 *   chanaddr	(size 1, offset 4, init 0):	RWCS	Channel address value error
 *   chancmderr	(size 1, offset 5, init 0):	RWCS	Channel command error
 *   cdataerr	(size 1, offset 6, init 0):	RWCS	Data parity error
 *   dmadataerr	(size 1, offset 7, init 0):	RWCS	DMA Data Parity error
 *   rddataerr	(size 1, offset 8, init 0):	RWCS	Read Data error
 *   wrdataerr	(size 1, offset 9, init 0):	RWCS	Write data error
 *   descctrlerr	(size 1, offset 10, init 0):	RWCS	Description control  error
 *   desclenerr	(size 1, offset 11, init 0):	RWCS	Description length error
 *   cmpaddrerr	(size 1, offset 12, init 0):	RWCS	Completion Address error
 *   intcfgerr	(size 1, offset 13, init 0):	RWCS	Interrupt confiuguratio error
 *   _anon14	(size 1, offset 14, init 0):	RSVD	_
 *   unaffilerr	(size 1, offset 15, init 0):	RO	Unaffiliated Error
 *   crc_err	(size 1, offset 16, init 0):	RWCS	CRC test failed
 *   xorqerr	(size 1, offset 17, init 0):	RWCS	Xor error
 *   desccnterr	(size 1, offset 18, init 0):	RWCS	Descriptor Count error
 *   _anon19	(size 13, offset 19, init 0):	RSVD	_
 */
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0xac));
}

static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_chanerrmsk_t ioat_dma_chanerrmsk_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0xac));
}

static inline void ioat_dma_chanerrmsk_rawwr(__DN(t) *_dev, ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_rawwr(__DN(t) *_dev, ioat_dma_chanerrmsk_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
}

static inline void ioat_dma_chanerrmsk_wr(__DN(t) *_dev, ioat_dma_chanerrmsk_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_wr(__DN(t) *_dev, ioat_dma_chanerrmsk_t _regval)
{
    _regval = (_regval & 0x7bfff);
    // No MB1 fields present
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
}

static inline int ioat_dma_chanerrmsk_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_chanerrmsk_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register chanerrmsk (Channel Error Mask Register.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmatranserr =\t%" PRIx8 "\t(DMA Transfer Source address error)\n", ioat_dma_chanerrmsk_dmatranserr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmaxfererr =\t%" PRIx8 "\t(DMA Transfer Destination address error)\n", ioat_dma_chanerrmsk_dmaxfererr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " nxtdescerr =\t%" PRIx8 "\t(Next Descriptor Address error)\n", ioat_dma_chanerrmsk_nxtdescerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descerr =\t%" PRIx8 "\t(Descriptor error)\n", ioat_dma_chanerrmsk_descerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chanaddr =\t%" PRIx8 "\t(Channel address value error)\n", ioat_dma_chanerrmsk_chanaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chancmderr =\t%" PRIx8 "\t(Channel command error)\n", ioat_dma_chanerrmsk_chancmderr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cdataerr =\t%" PRIx8 "\t(Data parity error)\n", ioat_dma_chanerrmsk_cdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dmadataerr =\t%" PRIx8 "\t(DMA Data Parity error)\n", ioat_dma_chanerrmsk_dmadataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " rddataerr =\t%" PRIx8 "\t(Read Data error)\n", ioat_dma_chanerrmsk_rddataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " wrdataerr =\t%" PRIx8 "\t(Write data error)\n", ioat_dma_chanerrmsk_wrdataerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " descctrlerr =\t%" PRIx8 "\t(Description control  error)\n", ioat_dma_chanerrmsk_descctrlerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desclenerr =\t%" PRIx8 "\t(Description length error)\n", ioat_dma_chanerrmsk_desclenerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " cmpaddrerr =\t%" PRIx8 "\t(Completion Address error)\n", ioat_dma_chanerrmsk_cmpaddrerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " intcfgerr =\t%" PRIx8 "\t(Interrupt confiuguratio error)\n", ioat_dma_chanerrmsk_intcfgerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon14 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " unaffilerr =\t%" PRIx8 "\t(Unaffiliated Error)\n", ioat_dma_chanerrmsk_unaffilerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " crc_err =\t%" PRIx8 "\t(CRC test failed)\n", ioat_dma_chanerrmsk_crc_err_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " xorqerr =\t%" PRIx8 "\t(Xor error)\n", ioat_dma_chanerrmsk_xorqerr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " desccnterr =\t%" PRIx8 "\t(Descriptor Count error)\n", ioat_dma_chanerrmsk_desccnterr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon19 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_chanerrmsk_dmatranserr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_dmatranserr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_dmatranserr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_dmaxfererr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_dmaxfererr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_dmaxfererr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_nxtdescerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_nxtdescerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_nxtdescerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_descerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_descerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_descerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_chanaddr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_chanaddr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_chanaddr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_chancmderr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_chancmderr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_chancmderr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_cdataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_cdataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_cdataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_dmadataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_dmadataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_dmadataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_rddataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_rddataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_rddataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_wrdataerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_wrdataerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_wrdataerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_descctrlerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_descctrlerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_descctrlerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_desclenerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_desclenerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_desclenerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_cmpaddrerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_cmpaddrerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_cmpaddrerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_intcfgerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_intcfgerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_intcfgerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_unaffilerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_unaffilerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_unaffilerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_crc_err_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_crc_err_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_crc_err_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_xorqerr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_xorqerr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_xorqerr_extract(_regval));
}

static inline uint8_t ioat_dma_chanerrmsk_desccnterr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_chanerrmsk_desccnterr_rdf(__DN(t) *_dev)
{
    ioat_dma_chanerrmsk_t _regval = mackerel_read_addr_32(_dev->bar, 0xac);
    return(ioat_dma_chanerrmsk_desccnterr_extract(_regval));
}

static inline void ioat_dma_chanerrmsk_dmatranserr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_dmatranserr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x1 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_dmaxfererr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_dmaxfererr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x2 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 1);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_nxtdescerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_nxtdescerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x4 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_descerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_descerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x8 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 3);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_chanaddr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_chanaddr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x10 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 4);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_chancmderr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_chancmderr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x20 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 5);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_cdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_cdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x40 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 6);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_dmadataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_dmadataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x80 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 7);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_rddataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_rddataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x100 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 8);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_wrdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_wrdataerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x200 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 9);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_descctrlerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_descctrlerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x400 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 10);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_desclenerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_desclenerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x800 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 11);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_cmpaddrerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_cmpaddrerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x1000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 12);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_intcfgerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_intcfgerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x2000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 13);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_crc_err_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_crc_err_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x10000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 16);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_xorqerr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_xorqerr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x20000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 17);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_chanerrmsk_desccnterr_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_chanerrmsk_desccnterr_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_chanerrmsk_t _regval = 0x40000 & (((ioat_dma_chanerrmsk_t )(_fieldval)) << 18);
    _regval = (_regval | (0xfff84000 & mackerel_read_addr_32(_dev->bar, 0xac)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xac, _regval);
    // No shadow register to write to
}

/*
 * Register dcactrl: DCA Control Register
 * Type: ioat_dma.dcactrl (Implicit type of DCA Control Register register)
 *   target_cpu	(size 16, offset 0, init 0):	RW	Specifies the APCI ID of the target CPU for compl writes
 *   _anon16	(size 16, offset 16, init 0):	RSVD	_
 */
static inline ioat_dma_dcactrl_t ioat_dma_dcactrl_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dcactrl_t ioat_dma_dcactrl_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0xb0));
}

static inline ioat_dma_dcactrl_t ioat_dma_dcactrl_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dcactrl_t ioat_dma_dcactrl_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0xb0));
}

static inline void ioat_dma_dcactrl_rawwr(__DN(t) *_dev, ioat_dma_dcactrl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dcactrl_rawwr(__DN(t) *_dev, ioat_dma_dcactrl_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0xb0, _regval);
}

static inline void ioat_dma_dcactrl_wr(__DN(t) *_dev, ioat_dma_dcactrl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dcactrl_wr(__DN(t) *_dev, ioat_dma_dcactrl_t _regval)
{
    _regval = (_regval & 0xffff);
    // No MB1 fields present
    _regval = (_regval | (0xffff0000 & mackerel_read_addr_32(_dev->bar, 0xb0)));
    mackerel_write_addr_32(_dev->bar, 0xb0, _regval);
}

static inline int ioat_dma_dcactrl_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dcactrl_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dcactrl_t _regval = mackerel_read_addr_32(_dev->bar, 0xb0);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dcactrl (DCA Control Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " target_cpu =\t%" PRIx16 "\t(Specifies the APCI ID of the target CPU for compl writes)\n", ioat_dma_dcactrl_target_cpu_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon16 is anonymous
    return(_r);
}

static inline uint16_t ioat_dma_dcactrl_target_cpu_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_dcactrl_target_cpu_rdf(__DN(t) *_dev)
{
    ioat_dma_dcactrl_t _regval = mackerel_read_addr_32(_dev->bar, 0xb0);
    return(ioat_dma_dcactrl_target_cpu_extract(_regval));
}

static inline void ioat_dma_dcactrl_target_cpu_wrf(__DN(t) *_dev, uint16_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dcactrl_target_cpu_wrf(__DN(t) *_dev, uint16_t _fieldval)
{
    ioat_dma_dcactrl_t _regval = 0xffff & (((ioat_dma_dcactrl_t )(_fieldval)) << 0);
    _regval = (_regval | (0xffff0000 & mackerel_read_addr_32(_dev->bar, 0xb0)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0xb0, _regval);
    // No shadow register to write to
}

/*
 * Register dca_ver: DCA Version Number Register
 * Type: ioat_dma.dca_ver (Implicit type of DCA Version Number Register register)
 *   minor	(size 4, offset 0, init 0):	RO	Major Revision Number
 *   major	(size 4, offset 4, init 0):	RO	Major Revision Number
 */
static inline ioat_dma_dca_ver_t ioat_dma_dca_ver_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dca_ver_t ioat_dma_dca_ver_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x100));
}

static inline ioat_dma_dca_ver_t ioat_dma_dca_ver_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dca_ver_t ioat_dma_dca_ver_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->bar, 0x100));
}

static inline void ioat_dma_dca_ver_rawwr(__DN(t) *_dev, ioat_dma_dca_ver_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_ver_rawwr(__DN(t) *_dev, ioat_dma_dca_ver_t _regval)
{
    mackerel_write_addr_8(_dev->bar, 0x100, _regval);
}

// Register dca_ver is not writeable
static inline int ioat_dma_dca_ver_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dca_ver_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dca_ver_t _regval = mackerel_read_addr_8(_dev->bar, 0x100);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dca_ver (DCA Version Number Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " minor =\t%" PRIx8 "\t(Major Revision Number)\n", ioat_dma_dca_ver_minor_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " major =\t%" PRIx8 "\t(Major Revision Number)\n", ioat_dma_dca_ver_major_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_dca_ver_minor_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_ver_minor_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_ver_t _regval = mackerel_read_addr_8(_dev->bar, 0x100);
    return(ioat_dma_dca_ver_minor_extract(_regval));
}

static inline uint8_t ioat_dma_dca_ver_major_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_ver_major_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_ver_t _regval = mackerel_read_addr_8(_dev->bar, 0x100);
    return(ioat_dma_dca_ver_major_extract(_regval));
}

/*
 * Register dca_reqid_offset: DCA Request ID Offset Register
 * Type: ioat_dma.uint16 (primitive type)
 */
static inline uint16_t ioat_dma_dca_reqid_offset_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_dca_reqid_offset_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x102));
}

static inline uint16_t ioat_dma_dca_reqid_offset_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t ioat_dma_dca_reqid_offset_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x102));
}

static inline void ioat_dma_dca_reqid_offset_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid_offset_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0x102, _regval);
}

// Register dca_reqid_offset is not writeable
static inline int ioat_dma_dca_reqid_offset_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dca_reqid_offset_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->bar, 0x102);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dca_reqid_offset (DCA Request ID Offset Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register csi_capability: Intel QPI Compability Register
 * Type: ioat_dma.csi_capability (Implicit type of Intel QPI Compability Register register)
 *   prefetch_hint	(size 1, offset 0, init 0):	RO	Prefetch hint
 *   _anon1	(size 15, offset 1, init 0):	RSVD	_
 */
static inline ioat_dma_csi_capability_t ioat_dma_csi_capability_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_csi_capability_t ioat_dma_csi_capability_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x108));
}

static inline ioat_dma_csi_capability_t ioat_dma_csi_capability_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_csi_capability_t ioat_dma_csi_capability_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x108));
}

static inline void ioat_dma_csi_capability_rawwr(__DN(t) *_dev, ioat_dma_csi_capability_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_csi_capability_rawwr(__DN(t) *_dev, ioat_dma_csi_capability_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0x108, _regval);
}

// Register csi_capability is not writeable
static inline int ioat_dma_csi_capability_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_csi_capability_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_csi_capability_t _regval = mackerel_read_addr_16(_dev->bar, 0x108);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register csi_capability (Intel QPI Compability Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " prefetch_hint =\t%" PRIx8 "\t(Prefetch hint)\n", ioat_dma_csi_capability_prefetch_hint_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon1 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_csi_capability_prefetch_hint_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_csi_capability_prefetch_hint_rdf(__DN(t) *_dev)
{
    ioat_dma_csi_capability_t _regval = mackerel_read_addr_16(_dev->bar, 0x108);
    return(ioat_dma_csi_capability_prefetch_hint_extract(_regval));
}

/*
 * Register pcie_capability: PCI Express Cabability Register
 * Type: ioat_dma.pcie_capability (Implicit type of PCI Express Cabability Register register)
 *   memwr_en	(size 1, offset 0, init 0):	RO	Enable Memory Writes on PCI Express
 *   _anon1	(size 15, offset 1, init 0):	RSVD	_
 */
static inline ioat_dma_pcie_capability_t ioat_dma_pcie_capability_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pcie_capability_t ioat_dma_pcie_capability_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x10a));
}

static inline ioat_dma_pcie_capability_t ioat_dma_pcie_capability_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pcie_capability_t ioat_dma_pcie_capability_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x10a));
}

static inline void ioat_dma_pcie_capability_rawwr(__DN(t) *_dev, ioat_dma_pcie_capability_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pcie_capability_rawwr(__DN(t) *_dev, ioat_dma_pcie_capability_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0x10a, _regval);
}

// Register pcie_capability is not writeable
static inline int ioat_dma_pcie_capability_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_pcie_capability_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_pcie_capability_t _regval = mackerel_read_addr_16(_dev->bar, 0x10a);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register pcie_capability (PCI Express Cabability Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " memwr_en =\t%" PRIx8 "\t(Enable Memory Writes on PCI Express)\n", ioat_dma_pcie_capability_memwr_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon1 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_pcie_capability_memwr_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcie_capability_memwr_en_rdf(__DN(t) *_dev)
{
    ioat_dma_pcie_capability_t _regval = mackerel_read_addr_16(_dev->bar, 0x10a);
    return(ioat_dma_pcie_capability_memwr_en_extract(_regval));
}

/*
 * Register csi_cap_enable: Intel QPI Compability Enable Register
 * Type: ioat_dma.csi_cap_enable (Implicit type of Intel QPI Compability Enable Register register)
 *   prefetch_hint	(size 1, offset 0, init 0):	RW	Prefetch hint
 *   _anon1	(size 15, offset 1, init 0):	RSVD	_
 */
static inline ioat_dma_csi_cap_enable_t ioat_dma_csi_cap_enable_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_csi_cap_enable_t ioat_dma_csi_cap_enable_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x10c));
}

static inline ioat_dma_csi_cap_enable_t ioat_dma_csi_cap_enable_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_csi_cap_enable_t ioat_dma_csi_cap_enable_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x10c));
}

static inline void ioat_dma_csi_cap_enable_rawwr(__DN(t) *_dev, ioat_dma_csi_cap_enable_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_csi_cap_enable_rawwr(__DN(t) *_dev, ioat_dma_csi_cap_enable_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0x10c, _regval);
}

static inline void ioat_dma_csi_cap_enable_wr(__DN(t) *_dev, ioat_dma_csi_cap_enable_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_csi_cap_enable_wr(__DN(t) *_dev, ioat_dma_csi_cap_enable_t _regval)
{
    _regval = (_regval & 0x1);
    // No MB1 fields present
    _regval = (_regval | (0xfffe & mackerel_read_addr_16(_dev->bar, 0x10c)));
    mackerel_write_addr_16(_dev->bar, 0x10c, _regval);
}

static inline int ioat_dma_csi_cap_enable_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_csi_cap_enable_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_csi_cap_enable_t _regval = mackerel_read_addr_16(_dev->bar, 0x10c);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register csi_cap_enable (Intel QPI Compability Enable Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " prefetch_hint =\t%" PRIx8 "\t(Prefetch hint)\n", ioat_dma_csi_cap_enable_prefetch_hint_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon1 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_csi_cap_enable_prefetch_hint_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_csi_cap_enable_prefetch_hint_rdf(__DN(t) *_dev)
{
    ioat_dma_csi_cap_enable_t _regval = mackerel_read_addr_16(_dev->bar, 0x10c);
    return(ioat_dma_csi_cap_enable_prefetch_hint_extract(_regval));
}

static inline void ioat_dma_csi_cap_enable_prefetch_hint_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_csi_cap_enable_prefetch_hint_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_csi_cap_enable_t _regval = 0x1 & (((ioat_dma_csi_cap_enable_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfffe & mackerel_read_addr_16(_dev->bar, 0x10c)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->bar, 0x10c, _regval);
    // No shadow register to write to
}

/*
 * Register pcie_cap_enable: PCI Express Cabability Enable Register
 * Type: ioat_dma.pcie_cap_enable (Implicit type of PCI Express Cabability Enable Register register)
 *   memwr_en	(size 1, offset 0, init 0):	RW	Enable Memory Writes on PCI Express
 *   _anon1	(size 15, offset 1, init 0):	RSVD	_
 */
static inline ioat_dma_pcie_cap_enable_t ioat_dma_pcie_cap_enable_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pcie_cap_enable_t ioat_dma_pcie_cap_enable_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x10e));
}

static inline ioat_dma_pcie_cap_enable_t ioat_dma_pcie_cap_enable_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pcie_cap_enable_t ioat_dma_pcie_cap_enable_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->bar, 0x10e));
}

static inline void ioat_dma_pcie_cap_enable_rawwr(__DN(t) *_dev, ioat_dma_pcie_cap_enable_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pcie_cap_enable_rawwr(__DN(t) *_dev, ioat_dma_pcie_cap_enable_t _regval)
{
    mackerel_write_addr_16(_dev->bar, 0x10e, _regval);
}

static inline void ioat_dma_pcie_cap_enable_wr(__DN(t) *_dev, ioat_dma_pcie_cap_enable_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pcie_cap_enable_wr(__DN(t) *_dev, ioat_dma_pcie_cap_enable_t _regval)
{
    _regval = (_regval & 0x1);
    // No MB1 fields present
    _regval = (_regval | (0xfffe & mackerel_read_addr_16(_dev->bar, 0x10e)));
    mackerel_write_addr_16(_dev->bar, 0x10e, _regval);
}

static inline int ioat_dma_pcie_cap_enable_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_pcie_cap_enable_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_pcie_cap_enable_t _regval = mackerel_read_addr_16(_dev->bar, 0x10e);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register pcie_cap_enable (PCI Express Cabability Enable Register): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " memwr_en =\t%" PRIx8 "\t(Enable Memory Writes on PCI Express)\n", ioat_dma_pcie_cap_enable_memwr_en_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon1 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_pcie_cap_enable_memwr_en_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pcie_cap_enable_memwr_en_rdf(__DN(t) *_dev)
{
    ioat_dma_pcie_cap_enable_t _regval = mackerel_read_addr_16(_dev->bar, 0x10e);
    return(ioat_dma_pcie_cap_enable_memwr_en_extract(_regval));
}

static inline void ioat_dma_pcie_cap_enable_memwr_en_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_pcie_cap_enable_memwr_en_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_pcie_cap_enable_t _regval = 0x1 & (((ioat_dma_pcie_cap_enable_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfffe & mackerel_read_addr_16(_dev->bar, 0x10e)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->bar, 0x10e, _regval);
    // No shadow register to write to
}

/*
 * Register apicid_tag_map: APICID to Tag Map Register.
 * Type: ioat_dma.apicid_tag_map (Implicit type of APICID to Tag Map Register. register)
 *   tag_map_0	(size 8, offset 0, init 0):	RW	Tag Map 0
 *   tag_map_1	(size 8, offset 8, init 0):	RW	Tag Map 1
 *   tag_map_2	(size 8, offset 16, init 0):	RW	Tag Map 2
 *   tag_map_3	(size 8, offset 24, init 0):	RW	Tag Map 3
 *   tag_map_4	(size 8, offset 32, init 0):	RW	Tag Map 4
 *   _anon40	(size 24, offset 40, init 0):	RSVD	_
 */
static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_64(_dev->bar, 0x110));
}

static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_apicid_tag_map_t ioat_dma_apicid_tag_map_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_64(_dev->bar, 0x110));
}

static inline void ioat_dma_apicid_tag_map_rawwr(__DN(t) *_dev, ioat_dma_apicid_tag_map_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_apicid_tag_map_rawwr(__DN(t) *_dev, ioat_dma_apicid_tag_map_t _regval)
{
    mackerel_write_addr_64(_dev->bar, 0x110, _regval);
}

static inline void ioat_dma_apicid_tag_map_wr(__DN(t) *_dev, ioat_dma_apicid_tag_map_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_apicid_tag_map_wr(__DN(t) *_dev, ioat_dma_apicid_tag_map_t _regval)
{
    _regval = (_regval & 0xffffffffff);
    // No MB1 fields present
    _regval = (_regval | (0xffffff0000000000 & mackerel_read_addr_64(_dev->bar, 0x110)));
    mackerel_write_addr_64(_dev->bar, 0x110, _regval);
}

static inline int ioat_dma_apicid_tag_map_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_apicid_tag_map_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_apicid_tag_map_t _regval = mackerel_read_addr_64(_dev->bar, 0x110);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register apicid_tag_map (APICID to Tag Map Register.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tag_map_0 =\t%" PRIx8 "\t(Tag Map 0)\n", ioat_dma_apicid_tag_map_tag_map_0_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tag_map_1 =\t%" PRIx8 "\t(Tag Map 1)\n", ioat_dma_apicid_tag_map_tag_map_1_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tag_map_2 =\t%" PRIx8 "\t(Tag Map 2)\n", ioat_dma_apicid_tag_map_tag_map_2_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tag_map_3 =\t%" PRIx8 "\t(Tag Map 3)\n", ioat_dma_apicid_tag_map_tag_map_3_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " tag_map_4 =\t%" PRIx8 "\t(Tag Map 4)\n", ioat_dma_apicid_tag_map_tag_map_4_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon40 is anonymous
    return(_r);
}

static inline uint8_t ioat_dma_apicid_tag_map_tag_map_0_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_0_rdf(__DN(t) *_dev)
{
    ioat_dma_apicid_tag_map_t _regval = mackerel_read_addr_64(_dev->bar, 0x110);
    return(ioat_dma_apicid_tag_map_tag_map_0_extract(_regval));
}

static inline uint8_t ioat_dma_apicid_tag_map_tag_map_1_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_1_rdf(__DN(t) *_dev)
{
    ioat_dma_apicid_tag_map_t _regval = mackerel_read_addr_64(_dev->bar, 0x110);
    return(ioat_dma_apicid_tag_map_tag_map_1_extract(_regval));
}

static inline uint8_t ioat_dma_apicid_tag_map_tag_map_2_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_2_rdf(__DN(t) *_dev)
{
    ioat_dma_apicid_tag_map_t _regval = mackerel_read_addr_64(_dev->bar, 0x110);
    return(ioat_dma_apicid_tag_map_tag_map_2_extract(_regval));
}

static inline uint8_t ioat_dma_apicid_tag_map_tag_map_3_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_3_rdf(__DN(t) *_dev)
{
    ioat_dma_apicid_tag_map_t _regval = mackerel_read_addr_64(_dev->bar, 0x110);
    return(ioat_dma_apicid_tag_map_tag_map_3_extract(_regval));
}

static inline uint8_t ioat_dma_apicid_tag_map_tag_map_4_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_apicid_tag_map_tag_map_4_rdf(__DN(t) *_dev)
{
    ioat_dma_apicid_tag_map_t _regval = mackerel_read_addr_64(_dev->bar, 0x110);
    return(ioat_dma_apicid_tag_map_tag_map_4_extract(_regval));
}

static inline void ioat_dma_apicid_tag_map_tag_map_0_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_apicid_tag_map_tag_map_0_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_apicid_tag_map_t _regval = 0xff & (((ioat_dma_apicid_tag_map_t )(_fieldval)) << 0);
    _regval = (_regval | (0xffffffffffffff00 & mackerel_read_addr_64(_dev->bar, 0x110)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_64(_dev->bar, 0x110, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_apicid_tag_map_tag_map_1_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_apicid_tag_map_tag_map_1_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_apicid_tag_map_t _regval = 0xff00 & (((ioat_dma_apicid_tag_map_t )(_fieldval)) << 8);
    _regval = (_regval | (0xffffffffffff00ff & mackerel_read_addr_64(_dev->bar, 0x110)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_64(_dev->bar, 0x110, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_apicid_tag_map_tag_map_2_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_apicid_tag_map_tag_map_2_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_apicid_tag_map_t _regval = 0xff0000 & (((ioat_dma_apicid_tag_map_t )(_fieldval)) << 16);
    _regval = (_regval | (0xffffffffff00ffff & mackerel_read_addr_64(_dev->bar, 0x110)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_64(_dev->bar, 0x110, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_apicid_tag_map_tag_map_3_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_apicid_tag_map_tag_map_3_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_apicid_tag_map_t _regval = 0xff000000 & (((ioat_dma_apicid_tag_map_t )(_fieldval)) << 24);
    _regval = (_regval | (0xffffffff00ffffff & mackerel_read_addr_64(_dev->bar, 0x110)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_64(_dev->bar, 0x110, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_apicid_tag_map_tag_map_4_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_apicid_tag_map_tag_map_4_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_apicid_tag_map_t _regval = 0xff00000000 & (((ioat_dma_apicid_tag_map_t )(_fieldval)) << 32);
    _regval = (_regval | (0xffffff00ffffffff & mackerel_read_addr_64(_dev->bar, 0x110)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_64(_dev->bar, 0x110, _regval);
    // No shadow register to write to
}

/*
 * Register dca_reqid0: Global DCA Requester ID Table Registers.
 * Type: ioat_dma.dca_reqid0 (Implicit type of Global DCA Requester ID Table Registers. register)
 *   fun	(size 3, offset 0, init 0):	RW	PCI Device Function
 *   dev	(size 5, offset 3, init 0):	RW	PCI Device Id
 *   bus	(size 8, offset 8, init 0):	RW	PCI Bus number
 *   _anon16	(size 12, offset 16, init 0):	RSVD	_
 *   ignore	(size 1, offset 28, init 0):	RW	If set, function number is ignore for DCA identification
 *   valid	(size 1, offset 29, init 0):	RW	If set, bits 15:0 are used for DCA identification
 *   _anon30	(size 1, offset 30, init 0):	RSVD	_
 *   last	(size 1, offset 31, init 0):	RO	Last Requested ID register
 */
static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x180));
}

static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid0_t ioat_dma_dca_reqid0_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x180));
}

static inline void ioat_dma_dca_reqid0_rawwr(__DN(t) *_dev, ioat_dma_dca_reqid0_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid0_rawwr(__DN(t) *_dev, ioat_dma_dca_reqid0_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x180, _regval);
}

static inline void ioat_dma_dca_reqid0_wr(__DN(t) *_dev, ioat_dma_dca_reqid0_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid0_wr(__DN(t) *_dev, ioat_dma_dca_reqid0_t _regval)
{
    _regval = (_regval & 0xb000ffff);
    // No MB1 fields present
    _regval = (_regval | (0x4fff0000 & mackerel_read_addr_32(_dev->bar, 0x180)));
    mackerel_write_addr_32(_dev->bar, 0x180, _regval);
}

static inline int ioat_dma_dca_reqid0_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dca_reqid0_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dca_reqid0_t _regval = mackerel_read_addr_32(_dev->bar, 0x180);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dca_reqid0 (Global DCA Requester ID Table Registers.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " fun =\t%" PRIx8 "\t(PCI Device Function)\n", ioat_dma_dca_reqid0_fun_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dev =\t%" PRIx8 "\t(PCI Device Id)\n", ioat_dma_dca_reqid0_dev_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bus =\t%" PRIx8 "\t(PCI Bus number)\n", ioat_dma_dca_reqid0_bus_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon16 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ignore =\t%" PRIx8 "\t(If set, function number is ignore for DCA identification)\n", ioat_dma_dca_reqid0_ignore_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " valid =\t%" PRIx8 "\t(If set, bits 15:0 are used for DCA identification)\n", ioat_dma_dca_reqid0_valid_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon30 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " last =\t%" PRIx8 "\t(Last Requested ID register)\n", ioat_dma_dca_reqid0_last_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_dca_reqid0_fun_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_fun_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid0_t _regval = mackerel_read_addr_32(_dev->bar, 0x180);
    return(ioat_dma_dca_reqid0_fun_extract(_regval));
}

static inline uint8_t ioat_dma_dca_reqid0_dev_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_dev_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid0_t _regval = mackerel_read_addr_32(_dev->bar, 0x180);
    return(ioat_dma_dca_reqid0_dev_extract(_regval));
}

static inline uint8_t ioat_dma_dca_reqid0_bus_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_bus_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid0_t _regval = mackerel_read_addr_32(_dev->bar, 0x180);
    return(ioat_dma_dca_reqid0_bus_extract(_regval));
}

static inline uint8_t ioat_dma_dca_reqid0_ignore_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_ignore_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid0_t _regval = mackerel_read_addr_32(_dev->bar, 0x180);
    return(ioat_dma_dca_reqid0_ignore_extract(_regval));
}

static inline uint8_t ioat_dma_dca_reqid0_valid_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_valid_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid0_t _regval = mackerel_read_addr_32(_dev->bar, 0x180);
    return(ioat_dma_dca_reqid0_valid_extract(_regval));
}

static inline uint8_t ioat_dma_dca_reqid0_last_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid0_last_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid0_t _regval = mackerel_read_addr_32(_dev->bar, 0x180);
    return(ioat_dma_dca_reqid0_last_extract(_regval));
}

static inline void ioat_dma_dca_reqid0_fun_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid0_fun_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dca_reqid0_t _regval = 0x7 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 0);
    _regval = (_regval | (0x7ffffff8 & mackerel_read_addr_32(_dev->bar, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dca_reqid0_dev_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid0_dev_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dca_reqid0_t _regval = 0xf8 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 3);
    _regval = (_regval | (0x7fffff07 & mackerel_read_addr_32(_dev->bar, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dca_reqid0_bus_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid0_bus_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dca_reqid0_t _regval = 0xff00 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 8);
    _regval = (_regval | (0x7fff00ff & mackerel_read_addr_32(_dev->bar, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dca_reqid0_ignore_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid0_ignore_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dca_reqid0_t _regval = 0x10000000 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 28);
    _regval = (_regval | (0x6fffffff & mackerel_read_addr_32(_dev->bar, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x180, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dca_reqid0_valid_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid0_valid_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dca_reqid0_t _regval = 0x20000000 & (((ioat_dma_dca_reqid0_t )(_fieldval)) << 29);
    _regval = (_regval | (0x5fffffff & mackerel_read_addr_32(_dev->bar, 0x180)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x180, _regval);
    // No shadow register to write to
}

/*
 * Register dca_reqid1: Global DCA Requester ID Table Registers.
 * Type: ioat_dma.dca_reqid1 (Implicit type of Global DCA Requester ID Table Registers. register)
 *   fun	(size 3, offset 0, init 0):	RW	PCI Device Function
 *   dev	(size 5, offset 3, init 0):	RW	PCI Device Id
 *   bus	(size 8, offset 8, init 0):	RW	PCI Bus number
 *   _anon16	(size 12, offset 16, init 0):	RSVD	_
 *   ignore	(size 1, offset 28, init 0):	RW	If set, function number is ignore for DCA identification
 *   valid	(size 1, offset 29, init 0):	RW	If set, bits 15:0 are used for DCA identification
 *   _anon30	(size 1, offset 30, init 0):	RSVD	_
 *   last	(size 1, offset 31, init 0):	RO	Last Requested ID register
 */
static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x184));
}

static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_dca_reqid1_t ioat_dma_dca_reqid1_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x184));
}

static inline void ioat_dma_dca_reqid1_rawwr(__DN(t) *_dev, ioat_dma_dca_reqid1_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid1_rawwr(__DN(t) *_dev, ioat_dma_dca_reqid1_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x184, _regval);
}

static inline void ioat_dma_dca_reqid1_wr(__DN(t) *_dev, ioat_dma_dca_reqid1_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid1_wr(__DN(t) *_dev, ioat_dma_dca_reqid1_t _regval)
{
    _regval = (_regval & 0xb000ffff);
    // No MB1 fields present
    _regval = (_regval | (0x4fff0000 & mackerel_read_addr_32(_dev->bar, 0x184)));
    mackerel_write_addr_32(_dev->bar, 0x184, _regval);
}

static inline int ioat_dma_dca_reqid1_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_dca_reqid1_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_dca_reqid1_t _regval = mackerel_read_addr_32(_dev->bar, 0x184);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register dca_reqid1 (Global DCA Requester ID Table Registers.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " fun =\t%" PRIx8 "\t(PCI Device Function)\n", ioat_dma_dca_reqid1_fun_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " dev =\t%" PRIx8 "\t(PCI Device Id)\n", ioat_dma_dca_reqid1_dev_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bus =\t%" PRIx8 "\t(PCI Bus number)\n", ioat_dma_dca_reqid1_bus_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon16 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ignore =\t%" PRIx8 "\t(If set, function number is ignore for DCA identification)\n", ioat_dma_dca_reqid1_ignore_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " valid =\t%" PRIx8 "\t(If set, bits 15:0 are used for DCA identification)\n", ioat_dma_dca_reqid1_valid_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon30 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " last =\t%" PRIx8 "\t(Last Requested ID register)\n", ioat_dma_dca_reqid1_last_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_dca_reqid1_fun_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_fun_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid1_t _regval = mackerel_read_addr_32(_dev->bar, 0x184);
    return(ioat_dma_dca_reqid1_fun_extract(_regval));
}

static inline uint8_t ioat_dma_dca_reqid1_dev_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_dev_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid1_t _regval = mackerel_read_addr_32(_dev->bar, 0x184);
    return(ioat_dma_dca_reqid1_dev_extract(_regval));
}

static inline uint8_t ioat_dma_dca_reqid1_bus_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_bus_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid1_t _regval = mackerel_read_addr_32(_dev->bar, 0x184);
    return(ioat_dma_dca_reqid1_bus_extract(_regval));
}

static inline uint8_t ioat_dma_dca_reqid1_ignore_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_ignore_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid1_t _regval = mackerel_read_addr_32(_dev->bar, 0x184);
    return(ioat_dma_dca_reqid1_ignore_extract(_regval));
}

static inline uint8_t ioat_dma_dca_reqid1_valid_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_valid_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid1_t _regval = mackerel_read_addr_32(_dev->bar, 0x184);
    return(ioat_dma_dca_reqid1_valid_extract(_regval));
}

static inline uint8_t ioat_dma_dca_reqid1_last_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_dca_reqid1_last_rdf(__DN(t) *_dev)
{
    ioat_dma_dca_reqid1_t _regval = mackerel_read_addr_32(_dev->bar, 0x184);
    return(ioat_dma_dca_reqid1_last_extract(_regval));
}

static inline void ioat_dma_dca_reqid1_fun_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid1_fun_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dca_reqid1_t _regval = 0x7 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 0);
    _regval = (_regval | (0x7ffffff8 & mackerel_read_addr_32(_dev->bar, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dca_reqid1_dev_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid1_dev_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dca_reqid1_t _regval = 0xf8 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 3);
    _regval = (_regval | (0x7fffff07 & mackerel_read_addr_32(_dev->bar, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dca_reqid1_bus_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid1_bus_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dca_reqid1_t _regval = 0xff00 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 8);
    _regval = (_regval | (0x7fff00ff & mackerel_read_addr_32(_dev->bar, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dca_reqid1_ignore_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid1_ignore_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dca_reqid1_t _regval = 0x10000000 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 28);
    _regval = (_regval | (0x6fffffff & mackerel_read_addr_32(_dev->bar, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x184, _regval);
    // No shadow register to write to
}

static inline void ioat_dma_dca_reqid1_valid_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_dca_reqid1_valid_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_dca_reqid1_t _regval = 0x20000000 & (((ioat_dma_dca_reqid1_t )(_fieldval)) << 29);
    _regval = (_regval | (0x5fffffff & mackerel_read_addr_32(_dev->bar, 0x184)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x184, _regval);
    // No shadow register to write to
}

/*
 * Register msgaddr_lo: MSI-X Lower Address Registers.
 * Type: ioat_dma.msgaddr_lo (Implicit type of MSI-X Lower Address Registers. register)
 *   chmsgaddr_const	(size 2, offset 0, init 0):	RO	
 *   chmsgaddr	(size 30, offset 2, init 0):	RW	Specifies the local APIC to which this MSI-X interrupt needs to be sent
 */
static inline ioat_dma_msgaddr_lo_t ioat_dma_msgaddr_lo_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_msgaddr_lo_t ioat_dma_msgaddr_lo_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x2000));
}

static inline ioat_dma_msgaddr_lo_t ioat_dma_msgaddr_lo_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_msgaddr_lo_t ioat_dma_msgaddr_lo_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x2000));
}

static inline void ioat_dma_msgaddr_lo_rawwr(__DN(t) *_dev, ioat_dma_msgaddr_lo_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_msgaddr_lo_rawwr(__DN(t) *_dev, ioat_dma_msgaddr_lo_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x2000, _regval);
}

static inline void ioat_dma_msgaddr_lo_wr(__DN(t) *_dev, ioat_dma_msgaddr_lo_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_msgaddr_lo_wr(__DN(t) *_dev, ioat_dma_msgaddr_lo_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_32(_dev->bar, 0x2000, _regval);
}

static inline int ioat_dma_msgaddr_lo_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_msgaddr_lo_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_msgaddr_lo_t _regval = mackerel_read_addr_32(_dev->bar, 0x2000);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register msgaddr_lo (MSI-X Lower Address Registers.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chmsgaddr_const =\t%" PRIx8 "\t()\n", ioat_dma_msgaddr_lo_chmsgaddr_const_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chmsgaddr =\t%" PRIx32 "\t(Specifies the local APIC to which this MSI-X interrupt needs to be sent)\n", ioat_dma_msgaddr_lo_chmsgaddr_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_msgaddr_lo_chmsgaddr_const_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_msgaddr_lo_chmsgaddr_const_rdf(__DN(t) *_dev)
{
    ioat_dma_msgaddr_lo_t _regval = mackerel_read_addr_32(_dev->bar, 0x2000);
    return(ioat_dma_msgaddr_lo_chmsgaddr_const_extract(_regval));
}

static inline uint32_t ioat_dma_msgaddr_lo_chmsgaddr_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_msgaddr_lo_chmsgaddr_rdf(__DN(t) *_dev)
{
    ioat_dma_msgaddr_lo_t _regval = mackerel_read_addr_32(_dev->bar, 0x2000);
    return(ioat_dma_msgaddr_lo_chmsgaddr_extract(_regval));
}

static inline void ioat_dma_msgaddr_lo_chmsgaddr_wrf(__DN(t) *_dev, uint32_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_msgaddr_lo_chmsgaddr_wrf(__DN(t) *_dev, uint32_t _fieldval)
{
    ioat_dma_msgaddr_lo_t _regval = 0xfffffffc & (((ioat_dma_msgaddr_lo_t )(_fieldval)) << 2);
    // No pre-read of register required
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x2000, _regval);
    // No shadow register to write to
}

/*
 * Register msgaddr_hi: MSI-X Upper Address Registers.
 * Type: ioat_dma.uint32 (primitive type)
 */
static inline uint32_t ioat_dma_msgaddr_hi_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_msgaddr_hi_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x2004));
}

static inline uint32_t ioat_dma_msgaddr_hi_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_msgaddr_hi_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x2004));
}

static inline void ioat_dma_msgaddr_hi_rawwr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_msgaddr_hi_rawwr(__DN(t) *_dev, uint32_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x2004, _regval);
}

// Register msgaddr_hi is not writeable
static inline int ioat_dma_msgaddr_hi_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_msgaddr_hi_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint32_t _regval = mackerel_read_addr_32(_dev->bar, 0x2004);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register msgaddr_hi (MSI-X Upper Address Registers.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx32 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register msgdata: MSI-X Data Registers.
 * Type: ioat_dma.uint32 (primitive type)
 */
static inline uint32_t ioat_dma_msgdata_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_msgdata_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x2008));
}

static inline uint32_t ioat_dma_msgdata_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_msgdata_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x2008));
}

static inline void ioat_dma_msgdata_rawwr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_msgdata_rawwr(__DN(t) *_dev, uint32_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x2008, _regval);
}

static inline void ioat_dma_msgdata_wr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_msgdata_wr(__DN(t) *_dev, uint32_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_32(_dev->bar, 0x2008, _regval);
}

static inline int ioat_dma_msgdata_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_msgdata_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint32_t _regval = mackerel_read_addr_32(_dev->bar, 0x2008);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register msgdata (MSI-X Data Registers.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx32 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register vecctrl: MSI-X Vector Control Registers.
 * Type: ioat_dma.vecctrl (Implicit type of MSI-X Vector Control Registers. register)
 *   chmask	(size 1, offset 0, init 0):	RW	When a bit is set, the channel is prohibited from sending a message
 *   chvecctrlcnst	(size 31, offset 1, init 0):	RO	chvecctrlcnst
 */
static inline ioat_dma_vecctrl_t ioat_dma_vecctrl_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_vecctrl_t ioat_dma_vecctrl_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x200c));
}

static inline ioat_dma_vecctrl_t ioat_dma_vecctrl_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_vecctrl_t ioat_dma_vecctrl_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x200c));
}

static inline void ioat_dma_vecctrl_rawwr(__DN(t) *_dev, ioat_dma_vecctrl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_vecctrl_rawwr(__DN(t) *_dev, ioat_dma_vecctrl_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x200c, _regval);
}

static inline void ioat_dma_vecctrl_wr(__DN(t) *_dev, ioat_dma_vecctrl_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_vecctrl_wr(__DN(t) *_dev, ioat_dma_vecctrl_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_32(_dev->bar, 0x200c, _regval);
}

static inline int ioat_dma_vecctrl_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_vecctrl_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_vecctrl_t _regval = mackerel_read_addr_32(_dev->bar, 0x200c);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register vecctrl (MSI-X Vector Control Registers.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chmask =\t%" PRIx8 "\t(When a bit is set, the channel is prohibited from sending a message)\n", ioat_dma_vecctrl_chmask_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chvecctrlcnst =\t%" PRIx32 "\t(chvecctrlcnst)\n", ioat_dma_vecctrl_chvecctrlcnst_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_vecctrl_chmask_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_vecctrl_chmask_rdf(__DN(t) *_dev)
{
    ioat_dma_vecctrl_t _regval = mackerel_read_addr_32(_dev->bar, 0x200c);
    return(ioat_dma_vecctrl_chmask_extract(_regval));
}

static inline uint32_t ioat_dma_vecctrl_chvecctrlcnst_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_vecctrl_chvecctrlcnst_rdf(__DN(t) *_dev)
{
    ioat_dma_vecctrl_t _regval = mackerel_read_addr_32(_dev->bar, 0x200c);
    return(ioat_dma_vecctrl_chvecctrlcnst_extract(_regval));
}

static inline void ioat_dma_vecctrl_chmask_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_vecctrl_chmask_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_vecctrl_t _regval = 0x1 & (((ioat_dma_vecctrl_t )(_fieldval)) << 0);
    // No pre-read of register required
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x200c, _regval);
    // No shadow register to write to
}

/*
 * Register pendingbits: MSI-X Interrupt Pending Bits Registers.
 * Type: ioat_dma.pendingbits (Implicit type of MSI-X Interrupt Pending Bits Registers. register)
 *   chmsipend	(size 1, offset 0, init 0):	RW	Pending Bit (when set) indicates that the DMA engine has a pending MSI-X
 *   chmsipendcnst	(size 31, offset 1, init 0):	RO	Unused
 */
static inline ioat_dma_pendingbits_t ioat_dma_pendingbits_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pendingbits_t ioat_dma_pendingbits_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x3000));
}

static inline ioat_dma_pendingbits_t ioat_dma_pendingbits_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline ioat_dma_pendingbits_t ioat_dma_pendingbits_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->bar, 0x3000));
}

static inline void ioat_dma_pendingbits_rawwr(__DN(t) *_dev, ioat_dma_pendingbits_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pendingbits_rawwr(__DN(t) *_dev, ioat_dma_pendingbits_t _regval)
{
    mackerel_write_addr_32(_dev->bar, 0x3000, _regval);
}

static inline void ioat_dma_pendingbits_wr(__DN(t) *_dev, ioat_dma_pendingbits_t _regval) __attribute__ ((always_inline));
static inline void ioat_dma_pendingbits_wr(__DN(t) *_dev, ioat_dma_pendingbits_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_32(_dev->bar, 0x3000, _regval);
}

static inline int ioat_dma_pendingbits_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_pendingbits_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    ioat_dma_pendingbits_t _regval = mackerel_read_addr_32(_dev->bar, 0x3000);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register pendingbits (MSI-X Interrupt Pending Bits Registers.): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chmsipend =\t%" PRIx8 "\t(Pending Bit (when set) indicates that the DMA engine has a pending MSI-X)\n", ioat_dma_pendingbits_chmsipend_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " chmsipendcnst =\t%" PRIx32 "\t(Unused)\n", ioat_dma_pendingbits_chmsipendcnst_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t ioat_dma_pendingbits_chmsipend_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t ioat_dma_pendingbits_chmsipend_rdf(__DN(t) *_dev)
{
    ioat_dma_pendingbits_t _regval = mackerel_read_addr_32(_dev->bar, 0x3000);
    return(ioat_dma_pendingbits_chmsipend_extract(_regval));
}

static inline uint32_t ioat_dma_pendingbits_chmsipendcnst_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t ioat_dma_pendingbits_chmsipendcnst_rdf(__DN(t) *_dev)
{
    ioat_dma_pendingbits_t _regval = mackerel_read_addr_32(_dev->bar, 0x3000);
    return(ioat_dma_pendingbits_chmsipendcnst_extract(_regval));
}

static inline void ioat_dma_pendingbits_chmsipend_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void ioat_dma_pendingbits_chmsipend_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    ioat_dma_pendingbits_t _regval = 0x1 & (((ioat_dma_pendingbits_t )(_fieldval)) << 0);
    // No pre-read of register required
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_32(_dev->bar, 0x3000, _regval);
    // No shadow register to write to
}

static inline int ioat_dma_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int ioat_dma_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "-------------------------\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Dump of device ioat_dma (IOAT DMA (Crystal Beach) registers):\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_vid_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_did_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_pcicmd_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_pcists_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_rid_ccr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_clsr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_hdr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_cb_bar_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_svid_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_sdid_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_capptr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_intl_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_intpin_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_devcfg_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_msixcapid_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_msixnxtptr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_msixmsgctl_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_tableoff_bir_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_pbaoff_bir_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_capid_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_nextptr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_expcap_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_devcap_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_devcon_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_devsts_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_devcap2_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_devcon2_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_pmcap_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_pmcsr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dmauncerrsts_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dmauncerrmsk_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dmauncerrsev_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dmauncerrptr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dmaglberrptr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chanerr_int_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chanerrmsk_int_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chanerrsev_int_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chanerrptr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chancnt_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_xfercap_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_genctrl_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_intrctrl_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_attnstatus_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_cbver_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_intrdelay_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_cs_status_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dmacapability_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dcaoffset_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_cbprio_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chanctrl_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dma_comp_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chancmd_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dmacount_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chansts_lo_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chansts_hi_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chainaddr_lo_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chainaddr_hi_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chancmp_lo_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chancmp_hi_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chanerr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_chanerrmsk_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dcactrl_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dca_ver_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dca_reqid_offset_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_csi_capability_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_pcie_capability_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_csi_cap_enable_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_pcie_cap_enable_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_apicid_tag_map_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dca_reqid0_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_dca_reqid1_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_msgaddr_lo_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_msgaddr_hi_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_msgdata_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_vecctrl_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = ioat_dma_pendingbits_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "End of dump of device ioat_dma\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "-------------------------\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

#undef __DN
#endif // __ioat_dma_DEV_H
