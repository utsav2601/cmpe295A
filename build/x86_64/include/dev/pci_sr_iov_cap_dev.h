#ifndef __pci_sr_iov_cap_DEV_H
#define __pci_sr_iov_cap_DEV_H 1
/*
 * DEVICE DEFINITION: PCI SR-IOV Extended Capability
 * 
 * Copyright (c) 2010, ETH Zurich.
 * All rights reserved.
 * 
 * This file is distributed under the terms in the attached LICENSE
 * file. If you do not find this file, copies can be found by
 * writing to:
 * ETH Zurich D-INFK, Universitaetstr. 6, CH-8092 Zurich.
 * Attn: Systems Group.
 * 
 * THIS FILE IS AUTOMATICALLY GENERATED BY MACKEREL: DO NOT EDIT!
 */
#include <mackerel/mackerel.h>
#include <inttypes.h>
#undef __DN
#define __DN(x) pci_sr_iov_cap ## _ ## x
/*
 * Register type: pci_sr_iov_cap_hdr_t
 * Description: Implicit type of Extended Capabilities Header register
 * Fields:
 *   id	(size 16, offset 0, init 0):	RO	PCI Express Extended Capability ID
 *   ver	(size 4, offset 16, init 0):	RO	Capability Version
 *   next	(size 12, offset 20, init 0):	RO	Next Capability Offset
 */
typedef uint32_t pci_sr_iov_cap_hdr_t;
#define pci_sr_iov_cap_hdr_default 0x0
static inline uint16_t pci_sr_iov_cap_hdr_id_extract(pci_sr_iov_cap_hdr_t _regval) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_hdr_id_extract(pci_sr_iov_cap_hdr_t _regval)
{
    return((uint16_t )((_regval & 0xffff) >> 0));
}

static inline pci_sr_iov_cap_hdr_t pci_sr_iov_cap_hdr_id_insert(pci_sr_iov_cap_hdr_t _regval, uint16_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_hdr_t pci_sr_iov_cap_hdr_id_insert(pci_sr_iov_cap_hdr_t _regval, uint16_t _fieldval)
{
    return((_regval & 0xffff0000) | (0xffff & (((pci_sr_iov_cap_hdr_t )(_fieldval)) << 0)));
}

static inline uint8_t pci_sr_iov_cap_hdr_ver_extract(pci_sr_iov_cap_hdr_t _regval) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_hdr_ver_extract(pci_sr_iov_cap_hdr_t _regval)
{
    return((uint8_t )((_regval & 0xf0000) >> 16));
}

static inline pci_sr_iov_cap_hdr_t pci_sr_iov_cap_hdr_ver_insert(pci_sr_iov_cap_hdr_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_hdr_t pci_sr_iov_cap_hdr_ver_insert(pci_sr_iov_cap_hdr_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff0ffff) | (0xf0000 & (((pci_sr_iov_cap_hdr_t )(_fieldval)) << 16)));
}

static inline uint16_t pci_sr_iov_cap_hdr_next_extract(pci_sr_iov_cap_hdr_t _regval) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_hdr_next_extract(pci_sr_iov_cap_hdr_t _regval)
{
    return((uint16_t )((_regval & 0xfff00000) >> 20));
}

static inline pci_sr_iov_cap_hdr_t pci_sr_iov_cap_hdr_next_insert(pci_sr_iov_cap_hdr_t _regval, uint16_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_hdr_t pci_sr_iov_cap_hdr_next_insert(pci_sr_iov_cap_hdr_t _regval, uint16_t _fieldval)
{
    return((_regval & 0xfffff) | (0xfff00000 & (((pci_sr_iov_cap_hdr_t )(_fieldval)) << 20)));
}

static inline int pci_sr_iov_cap_hdr_prtval(char *_s, size_t _size, pci_sr_iov_cap_hdr_t _regval) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_hdr_prtval(char *_s, size_t _size, pci_sr_iov_cap_hdr_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " id =\t%" PRIx16 "\t(PCI Express Extended Capability ID)\n", pci_sr_iov_cap_hdr_id_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ver =\t%" PRIx8 "\t(Capability Version)\n", pci_sr_iov_cap_hdr_ver_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " next =\t%" PRIx16 "\t(Next Capability Offset)\n", pci_sr_iov_cap_hdr_next_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: pci_sr_iov_cap_caps_t
 * Description: Implicit type of SR-IOV Capabilities register
 * Fields:
 *   vf_migration	(size 1, offset 0, init 0):	RO	VF Migration Capable
 *   ari_preserved	(size 1, offset 1, init 0):	RO	ARI Capable Hierarchy Preserved
 *   _anon2	(size 19, offset 2, init 0):	RSVD	_
 *   vf_mig_int	(size 11, offset 21, init 0):	RO	VF Migration Interrupt Message Number
 */
typedef uint32_t pci_sr_iov_cap_caps_t;
#define pci_sr_iov_cap_caps_default 0x0
static inline uint8_t pci_sr_iov_cap_caps_vf_migration_extract(pci_sr_iov_cap_caps_t _regval) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_caps_vf_migration_extract(pci_sr_iov_cap_caps_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline pci_sr_iov_cap_caps_t pci_sr_iov_cap_caps_vf_migration_insert(pci_sr_iov_cap_caps_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_caps_t pci_sr_iov_cap_caps_vf_migration_insert(pci_sr_iov_cap_caps_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffe) | (0x1 & (((pci_sr_iov_cap_caps_t )(_fieldval)) << 0)));
}

static inline uint8_t pci_sr_iov_cap_caps_ari_preserved_extract(pci_sr_iov_cap_caps_t _regval) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_caps_ari_preserved_extract(pci_sr_iov_cap_caps_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline pci_sr_iov_cap_caps_t pci_sr_iov_cap_caps_ari_preserved_insert(pci_sr_iov_cap_caps_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_caps_t pci_sr_iov_cap_caps_ari_preserved_insert(pci_sr_iov_cap_caps_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffffd) | (0x2 & (((pci_sr_iov_cap_caps_t )(_fieldval)) << 1)));
}

static inline uint16_t pci_sr_iov_cap_caps_vf_mig_int_extract(pci_sr_iov_cap_caps_t _regval) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_caps_vf_mig_int_extract(pci_sr_iov_cap_caps_t _regval)
{
    return((uint16_t )((_regval & 0xffe00000) >> 21));
}

static inline pci_sr_iov_cap_caps_t pci_sr_iov_cap_caps_vf_mig_int_insert(pci_sr_iov_cap_caps_t _regval, uint16_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_caps_t pci_sr_iov_cap_caps_vf_mig_int_insert(pci_sr_iov_cap_caps_t _regval, uint16_t _fieldval)
{
    return((_regval & 0x1fffff) | (0xffe00000 & (((pci_sr_iov_cap_caps_t )(_fieldval)) << 21)));
}

static inline int pci_sr_iov_cap_caps_prtval(char *_s, size_t _size, pci_sr_iov_cap_caps_t _regval) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_caps_prtval(char *_s, size_t _size, pci_sr_iov_cap_caps_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_migration =\t%" PRIx8 "\t(VF Migration Capable)\n", pci_sr_iov_cap_caps_vf_migration_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ari_preserved =\t%" PRIx8 "\t(ARI Capable Hierarchy Preserved)\n", pci_sr_iov_cap_caps_ari_preserved_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_mig_int =\t%" PRIx16 "\t(VF Migration Interrupt Message Number)\n", pci_sr_iov_cap_caps_vf_mig_int_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: pci_sr_iov_cap_ctrl_t
 * Description: Implicit type of SR-IOV Control register
 * Fields:
 *   vf_enable	(size 1, offset 0, init 0):	RW	VF Enable
 *   vf_mig_enable	(size 1, offset 1, init 0):	RW	VF Migration Enable
 *   vf_mig_int_enable	(size 1, offset 2, init 0):	RW	VF Migration Interrupt Enable
 *   vf_mse	(size 1, offset 3, init 0):	RW	VF MSE
 *   ari_capable	(size 1, offset 4, init 0):	RW	ARI Capable Hierarchy
 *   _anon5	(size 11, offset 5, init 0):	RSVD	_
 */
typedef uint16_t pci_sr_iov_cap_ctrl_t;
#define pci_sr_iov_cap_ctrl_default 0x0
static inline uint8_t pci_sr_iov_cap_ctrl_vf_enable_extract(pci_sr_iov_cap_ctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_ctrl_vf_enable_extract(pci_sr_iov_cap_ctrl_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_vf_enable_insert(pci_sr_iov_cap_ctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_vf_enable_insert(pci_sr_iov_cap_ctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((pci_sr_iov_cap_ctrl_t )(_fieldval)) << 0)));
}

static inline uint8_t pci_sr_iov_cap_ctrl_vf_mig_enable_extract(pci_sr_iov_cap_ctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_ctrl_vf_mig_enable_extract(pci_sr_iov_cap_ctrl_t _regval)
{
    return((uint8_t )((_regval & 0x2) >> 1));
}

static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_vf_mig_enable_insert(pci_sr_iov_cap_ctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_vf_mig_enable_insert(pci_sr_iov_cap_ctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffd) | (0x2 & (((pci_sr_iov_cap_ctrl_t )(_fieldval)) << 1)));
}

static inline uint8_t pci_sr_iov_cap_ctrl_vf_mig_int_enable_extract(pci_sr_iov_cap_ctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_ctrl_vf_mig_int_enable_extract(pci_sr_iov_cap_ctrl_t _regval)
{
    return((uint8_t )((_regval & 0x4) >> 2));
}

static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_vf_mig_int_enable_insert(pci_sr_iov_cap_ctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_vf_mig_int_enable_insert(pci_sr_iov_cap_ctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffb) | (0x4 & (((pci_sr_iov_cap_ctrl_t )(_fieldval)) << 2)));
}

static inline uint8_t pci_sr_iov_cap_ctrl_vf_mse_extract(pci_sr_iov_cap_ctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_ctrl_vf_mse_extract(pci_sr_iov_cap_ctrl_t _regval)
{
    return((uint8_t )((_regval & 0x8) >> 3));
}

static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_vf_mse_insert(pci_sr_iov_cap_ctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_vf_mse_insert(pci_sr_iov_cap_ctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfff7) | (0x8 & (((pci_sr_iov_cap_ctrl_t )(_fieldval)) << 3)));
}

static inline uint8_t pci_sr_iov_cap_ctrl_ari_capable_extract(pci_sr_iov_cap_ctrl_t _regval) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_ctrl_ari_capable_extract(pci_sr_iov_cap_ctrl_t _regval)
{
    return((uint8_t )((_regval & 0x10) >> 4));
}

static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_ari_capable_insert(pci_sr_iov_cap_ctrl_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_ari_capable_insert(pci_sr_iov_cap_ctrl_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xffef) | (0x10 & (((pci_sr_iov_cap_ctrl_t )(_fieldval)) << 4)));
}

static inline int pci_sr_iov_cap_ctrl_prtval(char *_s, size_t _size, pci_sr_iov_cap_ctrl_t _regval) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_ctrl_prtval(char *_s, size_t _size, pci_sr_iov_cap_ctrl_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_enable =\t%" PRIx8 "\t(VF Enable)\n", pci_sr_iov_cap_ctrl_vf_enable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_mig_enable =\t%" PRIx8 "\t(VF Migration Enable)\n", pci_sr_iov_cap_ctrl_vf_mig_enable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_mig_int_enable =\t%" PRIx8 "\t(VF Migration Interrupt Enable)\n", pci_sr_iov_cap_ctrl_vf_mig_int_enable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_mse =\t%" PRIx8 "\t(VF MSE)\n", pci_sr_iov_cap_ctrl_vf_mse_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ari_capable =\t%" PRIx8 "\t(ARI Capable Hierarchy)\n", pci_sr_iov_cap_ctrl_ari_capable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: pci_sr_iov_cap_status_t
 * Description: Implicit type of SR-IOV Status register
 * Fields:
 *   vf_migration	(size 1, offset 0, init 0):	RW	VF Migration Status
 *   _anon1	(size 15, offset 1, init 0):	MBZ	_
 */
typedef uint16_t pci_sr_iov_cap_status_t;
#define pci_sr_iov_cap_status_default 0x0
static inline uint8_t pci_sr_iov_cap_status_vf_migration_extract(pci_sr_iov_cap_status_t _regval) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_status_vf_migration_extract(pci_sr_iov_cap_status_t _regval)
{
    return((uint8_t )((_regval & 0x1) >> 0));
}

static inline pci_sr_iov_cap_status_t pci_sr_iov_cap_status_vf_migration_insert(pci_sr_iov_cap_status_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_status_t pci_sr_iov_cap_status_vf_migration_insert(pci_sr_iov_cap_status_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffe) | (0x1 & (((pci_sr_iov_cap_status_t )(_fieldval)) << 0)));
}

static inline int pci_sr_iov_cap_status_prtval(char *_s, size_t _size, pci_sr_iov_cap_status_t _regval) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_status_prtval(char *_s, size_t _size, pci_sr_iov_cap_status_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_migration =\t%" PRIx8 "\t(VF Migration Status)\n", pci_sr_iov_cap_status_vf_migration_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register type: pci_sr_iov_cap_vf_mig_state_t
 * Description: Implicit type of VF Migration State Array Offset register
 * Fields:
 *   bir	(size 3, offset 0, init 0):	RO	VF Migration State BIR
 *   offset	(size 29, offset 3, init 0):	RO	VF Migration State Offset
 */
typedef uint32_t pci_sr_iov_cap_vf_mig_state_t;
#define pci_sr_iov_cap_vf_mig_state_default 0x0
static inline uint8_t pci_sr_iov_cap_vf_mig_state_bir_extract(pci_sr_iov_cap_vf_mig_state_t _regval) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_vf_mig_state_bir_extract(pci_sr_iov_cap_vf_mig_state_t _regval)
{
    return((uint8_t )((_regval & 0x7) >> 0));
}

static inline pci_sr_iov_cap_vf_mig_state_t pci_sr_iov_cap_vf_mig_state_bir_insert(pci_sr_iov_cap_vf_mig_state_t _regval, uint8_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_vf_mig_state_t pci_sr_iov_cap_vf_mig_state_bir_insert(pci_sr_iov_cap_vf_mig_state_t _regval, uint8_t _fieldval)
{
    return((_regval & 0xfffffff8) | (0x7 & (((pci_sr_iov_cap_vf_mig_state_t )(_fieldval)) << 0)));
}

static inline uint32_t pci_sr_iov_cap_vf_mig_state_offset_extract(pci_sr_iov_cap_vf_mig_state_t _regval) __attribute__ ((always_inline));
static inline uint32_t pci_sr_iov_cap_vf_mig_state_offset_extract(pci_sr_iov_cap_vf_mig_state_t _regval)
{
    return((uint32_t )((_regval & 0xfffffff8) >> 3));
}

static inline pci_sr_iov_cap_vf_mig_state_t pci_sr_iov_cap_vf_mig_state_offset_insert(pci_sr_iov_cap_vf_mig_state_t _regval, uint32_t _fieldval) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_vf_mig_state_t pci_sr_iov_cap_vf_mig_state_offset_insert(pci_sr_iov_cap_vf_mig_state_t _regval, uint32_t _fieldval)
{
    return((_regval & 0x7) | (0xfffffff8 & (((pci_sr_iov_cap_vf_mig_state_t )(_fieldval)) << 3)));
}

static inline int pci_sr_iov_cap_vf_mig_state_prtval(char *_s, size_t _size, pci_sr_iov_cap_vf_mig_state_t _regval) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_vf_mig_state_prtval(char *_s, size_t _size, pci_sr_iov_cap_vf_mig_state_t _regval)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bir =\t%" PRIx8 "\t(VF Migration State BIR)\n", pci_sr_iov_cap_vf_mig_state_bir_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " offset =\t%" PRIx32 "\t(VF Migration State Offset)\n", pci_sr_iov_cap_vf_mig_state_offset_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Device representation structure
 */
struct __DN(t) {
    mackerel_addr_t base;
};
typedef struct __DN(t) __DN(t);

/*
 * Initial register values (currently 0)
 */
enum pci_sr_iov_cap_initials {
    pci_sr_iov_cap_hdr_initial = 0x0,
    pci_sr_iov_cap_caps_initial = 0x0,
    pci_sr_iov_cap_ctrl_initial = 0x0,
    pci_sr_iov_cap_status_initial = 0x0,
    pci_sr_iov_cap_initialvfs_initial = 0x0,
    pci_sr_iov_cap_totalvfs_initial = 0x0,
    pci_sr_iov_cap_numvfs_initial = 0x0,
    pci_sr_iov_cap_fdl_initial = 0x0,
    pci_sr_iov_cap_offset_initial = 0x0,
    pci_sr_iov_cap_stride_initial = 0x0,
    pci_sr_iov_cap_devid_initial = 0x0,
    pci_sr_iov_cap_sup_psize_initial = 0x0,
    pci_sr_iov_cap_sys_psize_initial = 0x0,
    pci_sr_iov_cap_vf_bar_initial = 0x0,
    pci_sr_iov_cap_vf_mig_state_initial = 0x0
};

/*
 * Device Initialization function
 */
static inline void pci_sr_iov_cap_initialize(__DN(t) *_dev, mackerel_addr_t base) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_initialize(__DN(t) *_dev, mackerel_addr_t base)
{
    _dev->base = base;
}

/*
 * Register hdr: Extended Capabilities Header
 * Type: pci_sr_iov_cap.hdr (Implicit type of Extended Capabilities Header register)
 *   id	(size 16, offset 0, init 0):	RO	PCI Express Extended Capability ID
 *   ver	(size 4, offset 16, init 0):	RO	Capability Version
 *   next	(size 12, offset 20, init 0):	RO	Next Capability Offset
 */
static inline pci_sr_iov_cap_hdr_t pci_sr_iov_cap_hdr_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_hdr_t pci_sr_iov_cap_hdr_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->base, 0x0));
}

static inline pci_sr_iov_cap_hdr_t pci_sr_iov_cap_hdr_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_hdr_t pci_sr_iov_cap_hdr_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->base, 0x0));
}

static inline void pci_sr_iov_cap_hdr_rawwr(__DN(t) *_dev, pci_sr_iov_cap_hdr_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_hdr_rawwr(__DN(t) *_dev, pci_sr_iov_cap_hdr_t _regval)
{
    mackerel_write_addr_32(_dev->base, 0x0, _regval);
}

// Register hdr is not writeable
static inline int pci_sr_iov_cap_hdr_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_hdr_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    pci_sr_iov_cap_hdr_t _regval = mackerel_read_addr_32(_dev->base, 0x0);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register hdr (Extended Capabilities Header): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " id =\t%" PRIx16 "\t(PCI Express Extended Capability ID)\n", pci_sr_iov_cap_hdr_id_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ver =\t%" PRIx8 "\t(Capability Version)\n", pci_sr_iov_cap_hdr_ver_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " next =\t%" PRIx16 "\t(Next Capability Offset)\n", pci_sr_iov_cap_hdr_next_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint16_t pci_sr_iov_cap_hdr_id_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_hdr_id_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_hdr_t _regval = mackerel_read_addr_32(_dev->base, 0x0);
    return(pci_sr_iov_cap_hdr_id_extract(_regval));
}

static inline uint8_t pci_sr_iov_cap_hdr_ver_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_hdr_ver_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_hdr_t _regval = mackerel_read_addr_32(_dev->base, 0x0);
    return(pci_sr_iov_cap_hdr_ver_extract(_regval));
}

static inline uint16_t pci_sr_iov_cap_hdr_next_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_hdr_next_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_hdr_t _regval = mackerel_read_addr_32(_dev->base, 0x0);
    return(pci_sr_iov_cap_hdr_next_extract(_regval));
}

/*
 * Register caps: SR-IOV Capabilities
 * Type: pci_sr_iov_cap.caps (Implicit type of SR-IOV Capabilities register)
 *   vf_migration	(size 1, offset 0, init 0):	RO	VF Migration Capable
 *   ari_preserved	(size 1, offset 1, init 0):	RO	ARI Capable Hierarchy Preserved
 *   _anon2	(size 19, offset 2, init 0):	RSVD	_
 *   vf_mig_int	(size 11, offset 21, init 0):	RO	VF Migration Interrupt Message Number
 */
static inline pci_sr_iov_cap_caps_t pci_sr_iov_cap_caps_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_caps_t pci_sr_iov_cap_caps_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->base, 0x4));
}

static inline pci_sr_iov_cap_caps_t pci_sr_iov_cap_caps_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_caps_t pci_sr_iov_cap_caps_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->base, 0x4));
}

static inline void pci_sr_iov_cap_caps_rawwr(__DN(t) *_dev, pci_sr_iov_cap_caps_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_caps_rawwr(__DN(t) *_dev, pci_sr_iov_cap_caps_t _regval)
{
    mackerel_write_addr_32(_dev->base, 0x4, _regval);
}

// Register caps is not writeable
static inline int pci_sr_iov_cap_caps_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_caps_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    pci_sr_iov_cap_caps_t _regval = mackerel_read_addr_32(_dev->base, 0x4);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register caps (SR-IOV Capabilities): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_migration =\t%" PRIx8 "\t(VF Migration Capable)\n", pci_sr_iov_cap_caps_vf_migration_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ari_preserved =\t%" PRIx8 "\t(ARI Capable Hierarchy Preserved)\n", pci_sr_iov_cap_caps_ari_preserved_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon2 is anonymous
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_mig_int =\t%" PRIx16 "\t(VF Migration Interrupt Message Number)\n", pci_sr_iov_cap_caps_vf_mig_int_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t pci_sr_iov_cap_caps_vf_migration_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_caps_vf_migration_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_caps_t _regval = mackerel_read_addr_32(_dev->base, 0x4);
    return(pci_sr_iov_cap_caps_vf_migration_extract(_regval));
}

static inline uint8_t pci_sr_iov_cap_caps_ari_preserved_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_caps_ari_preserved_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_caps_t _regval = mackerel_read_addr_32(_dev->base, 0x4);
    return(pci_sr_iov_cap_caps_ari_preserved_extract(_regval));
}

static inline uint16_t pci_sr_iov_cap_caps_vf_mig_int_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_caps_vf_mig_int_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_caps_t _regval = mackerel_read_addr_32(_dev->base, 0x4);
    return(pci_sr_iov_cap_caps_vf_mig_int_extract(_regval));
}

/*
 * Register ctrl: SR-IOV Control
 * Type: pci_sr_iov_cap.ctrl (Implicit type of SR-IOV Control register)
 *   vf_enable	(size 1, offset 0, init 0):	RW	VF Enable
 *   vf_mig_enable	(size 1, offset 1, init 0):	RW	VF Migration Enable
 *   vf_mig_int_enable	(size 1, offset 2, init 0):	RW	VF Migration Interrupt Enable
 *   vf_mse	(size 1, offset 3, init 0):	RW	VF MSE
 *   ari_capable	(size 1, offset 4, init 0):	RW	ARI Capable Hierarchy
 *   _anon5	(size 11, offset 5, init 0):	RSVD	_
 */
static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0x8));
}

static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_ctrl_t pci_sr_iov_cap_ctrl_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0x8));
}

static inline void pci_sr_iov_cap_ctrl_rawwr(__DN(t) *_dev, pci_sr_iov_cap_ctrl_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_ctrl_rawwr(__DN(t) *_dev, pci_sr_iov_cap_ctrl_t _regval)
{
    mackerel_write_addr_16(_dev->base, 0x8, _regval);
}

static inline void pci_sr_iov_cap_ctrl_wr(__DN(t) *_dev, pci_sr_iov_cap_ctrl_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_ctrl_wr(__DN(t) *_dev, pci_sr_iov_cap_ctrl_t _regval)
{
    _regval = (_regval & 0x1f);
    // No MB1 fields present
    _regval = (_regval | (0xffe0 & mackerel_read_addr_16(_dev->base, 0x8)));
    mackerel_write_addr_16(_dev->base, 0x8, _regval);
}

static inline int pci_sr_iov_cap_ctrl_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_ctrl_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    pci_sr_iov_cap_ctrl_t _regval = mackerel_read_addr_16(_dev->base, 0x8);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register ctrl (SR-IOV Control): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_enable =\t%" PRIx8 "\t(VF Enable)\n", pci_sr_iov_cap_ctrl_vf_enable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_mig_enable =\t%" PRIx8 "\t(VF Migration Enable)\n", pci_sr_iov_cap_ctrl_vf_mig_enable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_mig_int_enable =\t%" PRIx8 "\t(VF Migration Interrupt Enable)\n", pci_sr_iov_cap_ctrl_vf_mig_int_enable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_mse =\t%" PRIx8 "\t(VF MSE)\n", pci_sr_iov_cap_ctrl_vf_mse_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " ari_capable =\t%" PRIx8 "\t(ARI Capable Hierarchy)\n", pci_sr_iov_cap_ctrl_ari_capable_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon5 is anonymous
    return(_r);
}

static inline uint8_t pci_sr_iov_cap_ctrl_vf_enable_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_ctrl_vf_enable_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_ctrl_t _regval = mackerel_read_addr_16(_dev->base, 0x8);
    return(pci_sr_iov_cap_ctrl_vf_enable_extract(_regval));
}

static inline uint8_t pci_sr_iov_cap_ctrl_vf_mig_enable_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_ctrl_vf_mig_enable_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_ctrl_t _regval = mackerel_read_addr_16(_dev->base, 0x8);
    return(pci_sr_iov_cap_ctrl_vf_mig_enable_extract(_regval));
}

static inline uint8_t pci_sr_iov_cap_ctrl_vf_mig_int_enable_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_ctrl_vf_mig_int_enable_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_ctrl_t _regval = mackerel_read_addr_16(_dev->base, 0x8);
    return(pci_sr_iov_cap_ctrl_vf_mig_int_enable_extract(_regval));
}

static inline uint8_t pci_sr_iov_cap_ctrl_vf_mse_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_ctrl_vf_mse_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_ctrl_t _regval = mackerel_read_addr_16(_dev->base, 0x8);
    return(pci_sr_iov_cap_ctrl_vf_mse_extract(_regval));
}

static inline uint8_t pci_sr_iov_cap_ctrl_ari_capable_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_ctrl_ari_capable_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_ctrl_t _regval = mackerel_read_addr_16(_dev->base, 0x8);
    return(pci_sr_iov_cap_ctrl_ari_capable_extract(_regval));
}

static inline void pci_sr_iov_cap_ctrl_vf_enable_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_ctrl_vf_enable_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    pci_sr_iov_cap_ctrl_t _regval = 0x1 & (((pci_sr_iov_cap_ctrl_t )(_fieldval)) << 0);
    _regval = (_regval | (0xfffe & mackerel_read_addr_16(_dev->base, 0x8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->base, 0x8, _regval);
    // No shadow register to write to
}

static inline void pci_sr_iov_cap_ctrl_vf_mig_enable_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_ctrl_vf_mig_enable_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    pci_sr_iov_cap_ctrl_t _regval = 0x2 & (((pci_sr_iov_cap_ctrl_t )(_fieldval)) << 1);
    _regval = (_regval | (0xfffd & mackerel_read_addr_16(_dev->base, 0x8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->base, 0x8, _regval);
    // No shadow register to write to
}

static inline void pci_sr_iov_cap_ctrl_vf_mig_int_enable_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_ctrl_vf_mig_int_enable_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    pci_sr_iov_cap_ctrl_t _regval = 0x4 & (((pci_sr_iov_cap_ctrl_t )(_fieldval)) << 2);
    _regval = (_regval | (0xfffb & mackerel_read_addr_16(_dev->base, 0x8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->base, 0x8, _regval);
    // No shadow register to write to
}

static inline void pci_sr_iov_cap_ctrl_vf_mse_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_ctrl_vf_mse_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    pci_sr_iov_cap_ctrl_t _regval = 0x8 & (((pci_sr_iov_cap_ctrl_t )(_fieldval)) << 3);
    _regval = (_regval | (0xfff7 & mackerel_read_addr_16(_dev->base, 0x8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->base, 0x8, _regval);
    // No shadow register to write to
}

static inline void pci_sr_iov_cap_ctrl_ari_capable_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_ctrl_ari_capable_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    pci_sr_iov_cap_ctrl_t _regval = 0x10 & (((pci_sr_iov_cap_ctrl_t )(_fieldval)) << 4);
    _regval = (_regval | (0xffef & mackerel_read_addr_16(_dev->base, 0x8)));
    // No read of register shadow required
    // No MB0 fields present
    // No MB1 fields present
    mackerel_write_addr_16(_dev->base, 0x8, _regval);
    // No shadow register to write to
}

/*
 * Register status: SR-IOV Status
 * Type: pci_sr_iov_cap.status (Implicit type of SR-IOV Status register)
 *   vf_migration	(size 1, offset 0, init 0):	RW	VF Migration Status
 *   _anon1	(size 15, offset 1, init 0):	MBZ	_
 */
static inline pci_sr_iov_cap_status_t pci_sr_iov_cap_status_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_status_t pci_sr_iov_cap_status_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0xa));
}

static inline pci_sr_iov_cap_status_t pci_sr_iov_cap_status_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_status_t pci_sr_iov_cap_status_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0xa));
}

static inline void pci_sr_iov_cap_status_rawwr(__DN(t) *_dev, pci_sr_iov_cap_status_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_status_rawwr(__DN(t) *_dev, pci_sr_iov_cap_status_t _regval)
{
    mackerel_write_addr_16(_dev->base, 0xa, _regval);
}

static inline void pci_sr_iov_cap_status_wr(__DN(t) *_dev, pci_sr_iov_cap_status_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_status_wr(__DN(t) *_dev, pci_sr_iov_cap_status_t _regval)
{
    _regval = (_regval & 0x1);
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_16(_dev->base, 0xa, _regval);
}

static inline int pci_sr_iov_cap_status_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_status_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    pci_sr_iov_cap_status_t _regval = mackerel_read_addr_16(_dev->base, 0xa);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register status (SR-IOV Status): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " vf_migration =\t%" PRIx8 "\t(VF Migration Status)\n", pci_sr_iov_cap_status_vf_migration_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    // _anon1 is anonymous
    return(_r);
}

static inline uint8_t pci_sr_iov_cap_status_vf_migration_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_status_vf_migration_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_status_t _regval = mackerel_read_addr_16(_dev->base, 0xa);
    return(pci_sr_iov_cap_status_vf_migration_extract(_regval));
}

static inline void pci_sr_iov_cap_status_vf_migration_wrf(__DN(t) *_dev, uint8_t _fieldval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_status_vf_migration_wrf(__DN(t) *_dev, uint8_t _fieldval)
{
    pci_sr_iov_cap_status_t _regval = 0x1 & (((pci_sr_iov_cap_status_t )(_fieldval)) << 0);
    // No pre-read of register required
    // No read of register shadow required
    _regval = (_regval & 0x1);
    // No MB1 fields present
    mackerel_write_addr_16(_dev->base, 0xa, _regval);
    // No shadow register to write to
}

/*
 * Register initialvfs: InitialVFs
 * Type: pci_sr_iov_cap.uint16 (primitive type)
 */
static inline uint16_t pci_sr_iov_cap_initialvfs_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_initialvfs_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0xc));
}

static inline uint16_t pci_sr_iov_cap_initialvfs_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_initialvfs_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0xc));
}

static inline void pci_sr_iov_cap_initialvfs_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_initialvfs_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->base, 0xc, _regval);
}

// Register initialvfs is not writeable
static inline int pci_sr_iov_cap_initialvfs_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_initialvfs_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->base, 0xc);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register initialvfs (InitialVFs): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register totalvfs: TotalVFs
 * Type: pci_sr_iov_cap.uint16 (primitive type)
 */
static inline uint16_t pci_sr_iov_cap_totalvfs_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_totalvfs_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0xe));
}

static inline uint16_t pci_sr_iov_cap_totalvfs_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_totalvfs_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0xe));
}

static inline void pci_sr_iov_cap_totalvfs_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_totalvfs_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->base, 0xe, _regval);
}

// Register totalvfs is not writeable
static inline int pci_sr_iov_cap_totalvfs_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_totalvfs_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->base, 0xe);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register totalvfs (TotalVFs): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register numvfs: NumVFs
 * Type: pci_sr_iov_cap.uint16 (primitive type)
 */
static inline uint16_t pci_sr_iov_cap_numvfs_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_numvfs_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0x10));
}

static inline uint16_t pci_sr_iov_cap_numvfs_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_numvfs_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0x10));
}

static inline void pci_sr_iov_cap_numvfs_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_numvfs_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->base, 0x10, _regval);
}

static inline void pci_sr_iov_cap_numvfs_wr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_numvfs_wr(__DN(t) *_dev, uint16_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_16(_dev->base, 0x10, _regval);
}

static inline int pci_sr_iov_cap_numvfs_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_numvfs_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->base, 0x10);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register numvfs (NumVFs): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register fdl: Function Dependency Link
 * Type: pci_sr_iov_cap.uint8 (primitive type)
 */
static inline uint8_t pci_sr_iov_cap_fdl_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_fdl_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->base, 0x12));
}

static inline uint8_t pci_sr_iov_cap_fdl_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_fdl_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_8(_dev->base, 0x12));
}

static inline void pci_sr_iov_cap_fdl_rawwr(__DN(t) *_dev, uint8_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_fdl_rawwr(__DN(t) *_dev, uint8_t _regval)
{
    mackerel_write_addr_8(_dev->base, 0x12, _regval);
}

// Register fdl is not writeable
static inline int pci_sr_iov_cap_fdl_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_fdl_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint8_t _regval = mackerel_read_addr_8(_dev->base, 0x12);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register fdl (Function Dependency Link): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx8 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register offset: First VF Offset
 * Type: pci_sr_iov_cap.uint16 (primitive type)
 */
static inline uint16_t pci_sr_iov_cap_offset_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_offset_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0x14));
}

static inline uint16_t pci_sr_iov_cap_offset_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_offset_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0x14));
}

static inline void pci_sr_iov_cap_offset_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_offset_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->base, 0x14, _regval);
}

// Register offset is not writeable
static inline int pci_sr_iov_cap_offset_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_offset_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->base, 0x14);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register offset (First VF Offset): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register stride: VF Stride
 * Type: pci_sr_iov_cap.uint16 (primitive type)
 */
static inline uint16_t pci_sr_iov_cap_stride_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_stride_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0x16));
}

static inline uint16_t pci_sr_iov_cap_stride_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_stride_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0x16));
}

static inline void pci_sr_iov_cap_stride_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_stride_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->base, 0x16, _regval);
}

// Register stride is not writeable
static inline int pci_sr_iov_cap_stride_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_stride_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->base, 0x16);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register stride (VF Stride): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register devid: VF Device ID
 * Type: pci_sr_iov_cap.uint16 (primitive type)
 */
static inline uint16_t pci_sr_iov_cap_devid_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_devid_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0x1a));
}

static inline uint16_t pci_sr_iov_cap_devid_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint16_t pci_sr_iov_cap_devid_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_16(_dev->base, 0x1a));
}

static inline void pci_sr_iov_cap_devid_rawwr(__DN(t) *_dev, uint16_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_devid_rawwr(__DN(t) *_dev, uint16_t _regval)
{
    mackerel_write_addr_16(_dev->base, 0x1a, _regval);
}

// Register devid is not writeable
static inline int pci_sr_iov_cap_devid_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_devid_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint16_t _regval = mackerel_read_addr_16(_dev->base, 0x1a);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register devid (VF Device ID): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx16 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register sup_psize: Supported Page Sizes
 * Type: pci_sr_iov_cap.uint32 (primitive type)
 */
static inline uint32_t pci_sr_iov_cap_sup_psize_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t pci_sr_iov_cap_sup_psize_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->base, 0x1c));
}

static inline uint32_t pci_sr_iov_cap_sup_psize_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t pci_sr_iov_cap_sup_psize_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->base, 0x1c));
}

static inline void pci_sr_iov_cap_sup_psize_rawwr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_sup_psize_rawwr(__DN(t) *_dev, uint32_t _regval)
{
    mackerel_write_addr_32(_dev->base, 0x1c, _regval);
}

// Register sup_psize is not writeable
static inline int pci_sr_iov_cap_sup_psize_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_sup_psize_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint32_t _regval = mackerel_read_addr_32(_dev->base, 0x1c);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register sup_psize (Supported Page Sizes): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx32 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register sys_psize: System Page Size
 * Type: pci_sr_iov_cap.uint32 (primitive type)
 */
static inline uint32_t pci_sr_iov_cap_sys_psize_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t pci_sr_iov_cap_sys_psize_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->base, 0x20));
}

static inline uint32_t pci_sr_iov_cap_sys_psize_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t pci_sr_iov_cap_sys_psize_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->base, 0x20));
}

static inline void pci_sr_iov_cap_sys_psize_rawwr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_sys_psize_rawwr(__DN(t) *_dev, uint32_t _regval)
{
    mackerel_write_addr_32(_dev->base, 0x20, _regval);
}

static inline void pci_sr_iov_cap_sys_psize_wr(__DN(t) *_dev, uint32_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_sys_psize_wr(__DN(t) *_dev, uint32_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_32(_dev->base, 0x20, _regval);
}

static inline int pci_sr_iov_cap_sys_psize_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_sys_psize_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint32_t _regval = mackerel_read_addr_32(_dev->base, 0x20);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register sys_psize (System Page Size): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx32 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

/*
 * Register array vf_bar: VF BAR
 * Type: pci_sr_iov_cap.uint32 (primitive type)
 */
static const size_t pci_sr_iov_cap_vf_bar_length = 6;
static inline uint32_t pci_sr_iov_cap_vf_bar_rawrd(__DN(t) *_dev, int _i) __attribute__ ((always_inline));
static inline uint32_t pci_sr_iov_cap_vf_bar_rawrd(__DN(t) *_dev, int _i)
{
    return(mackerel_read_addr_32(_dev->base, 0x24 + (_i * (32 / 8))));
}

static inline uint32_t pci_sr_iov_cap_vf_bar_rd(__DN(t) *_dev, int _i) __attribute__ ((always_inline));
static inline uint32_t pci_sr_iov_cap_vf_bar_rd(__DN(t) *_dev, int _i)
{
    return(mackerel_read_addr_32(_dev->base, 0x24 + (_i * (32 / 8))));
}

static inline void pci_sr_iov_cap_vf_bar_rawwr(__DN(t) *_dev, int _i, uint32_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_vf_bar_rawwr(__DN(t) *_dev, int _i, uint32_t _regval)
{
    mackerel_write_addr_32(_dev->base, 0x24 + (_i * (32 / 8)), _regval);
}

static inline void pci_sr_iov_cap_vf_bar_wr(__DN(t) *_dev, int _i, uint32_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_vf_bar_wr(__DN(t) *_dev, int _i, uint32_t _regval)
{
    // No MB0 or RSVD fields present
    // No MB1 fields present
    // No pre-read of register required
    mackerel_write_addr_32(_dev->base, 0x24 + (_i * (32 / 8)), _regval);
}

static inline int pci_sr_iov_cap_vf_bar_pri(char *_s, size_t _size, __DN(t) *_dev, int _i) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_vf_bar_pri(char *_s, size_t _size, __DN(t) *_dev, int _i)
{
    int _r = 0;
    int _avail;
    int _rc;
    uint32_t _regval = mackerel_read_addr_32(_dev->base, 0x24 + (_i * (32 / 8)));
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register %s[%d] (%s): ", "vf_bar", _i, "VF BAR");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\t%" PRIx32 "\n", _regval);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline int pci_sr_iov_cap_vf_bar_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_vf_bar_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    int _i;
    for( _i = 0; _i < 6; _i++) {
        _avail = ((_r > _size) ? 0 : (_size - _r));
        _rc = pci_sr_iov_cap_vf_bar_pri(_s + _r, _avail, _dev, _i);
        if ((_rc > 0) && (_rc < _avail)) {
            _r = (_r + _rc);
        }
    }
    return(_r);
}

/*
 * Register vf_mig_state: VF Migration State Array Offset
 * Type: pci_sr_iov_cap.vf_mig_state (Implicit type of VF Migration State Array Offset register)
 *   bir	(size 3, offset 0, init 0):	RO	VF Migration State BIR
 *   offset	(size 29, offset 3, init 0):	RO	VF Migration State Offset
 */
static inline pci_sr_iov_cap_vf_mig_state_t pci_sr_iov_cap_vf_mig_state_rawrd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_vf_mig_state_t pci_sr_iov_cap_vf_mig_state_rawrd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->base, 0x3c));
}

static inline pci_sr_iov_cap_vf_mig_state_t pci_sr_iov_cap_vf_mig_state_rd(__DN(t) *_dev) __attribute__ ((always_inline));
static inline pci_sr_iov_cap_vf_mig_state_t pci_sr_iov_cap_vf_mig_state_rd(__DN(t) *_dev)
{
    return(mackerel_read_addr_32(_dev->base, 0x3c));
}

static inline void pci_sr_iov_cap_vf_mig_state_rawwr(__DN(t) *_dev, pci_sr_iov_cap_vf_mig_state_t _regval) __attribute__ ((always_inline));
static inline void pci_sr_iov_cap_vf_mig_state_rawwr(__DN(t) *_dev, pci_sr_iov_cap_vf_mig_state_t _regval)
{
    mackerel_write_addr_32(_dev->base, 0x3c, _regval);
}

// Register vf_mig_state is not writeable
static inline int pci_sr_iov_cap_vf_mig_state_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_vf_mig_state_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    pci_sr_iov_cap_vf_mig_state_t _regval = mackerel_read_addr_32(_dev->base, 0x3c);
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Register vf_mig_state (VF Migration State Array Offset): ");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " bir =\t%" PRIx8 "\t(VF Migration State BIR)\n", pci_sr_iov_cap_vf_mig_state_bir_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, " offset =\t%" PRIx32 "\t(VF Migration State Offset)\n", pci_sr_iov_cap_vf_mig_state_offset_extract(_regval));
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

static inline uint8_t pci_sr_iov_cap_vf_mig_state_bir_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint8_t pci_sr_iov_cap_vf_mig_state_bir_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_vf_mig_state_t _regval = mackerel_read_addr_32(_dev->base, 0x3c);
    return(pci_sr_iov_cap_vf_mig_state_bir_extract(_regval));
}

static inline uint32_t pci_sr_iov_cap_vf_mig_state_offset_rdf(__DN(t) *_dev) __attribute__ ((always_inline));
static inline uint32_t pci_sr_iov_cap_vf_mig_state_offset_rdf(__DN(t) *_dev)
{
    pci_sr_iov_cap_vf_mig_state_t _regval = mackerel_read_addr_32(_dev->base, 0x3c);
    return(pci_sr_iov_cap_vf_mig_state_offset_extract(_regval));
}

static inline int pci_sr_iov_cap_pr(char *_s, size_t _size, __DN(t) *_dev) __attribute__ ((always_inline));
static inline int pci_sr_iov_cap_pr(char *_s, size_t _size, __DN(t) *_dev)
{
    int _r = 0;
    int _avail;
    int _rc;
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "-------------------------\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "Dump of device pci_sr_iov_cap (PCI SR-IOV Extended Capability):\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_hdr_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_caps_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_ctrl_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_status_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_initialvfs_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_totalvfs_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_numvfs_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_fdl_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_offset_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_stride_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_devid_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_sup_psize_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_sys_psize_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_vf_bar_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = pci_sr_iov_cap_vf_mig_state_pr(_s + _r, _avail, _dev);
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "End of dump of device pci_sr_iov_cap\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    _avail = ((_r > _size) ? 0 : (_size - _r));
    _rc = snprintf(_s + _r, _avail, "-------------------------\n");
    if ((_rc > 0) && (_rc < _avail)) {
        _r = (_r + _rc);
    }
    return(_r);
}

#undef __DN
#endif // __pci_sr_iov_cap_DEV_H
