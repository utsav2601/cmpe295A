#ifndef __ioat_dma_mgr_IF_H
#define __ioat_dma_mgr_IF_H 1
/*
 * Copyright (c) 2010, ETH Zurich.
 * All rights reserved.
 * 
 * INTERFACE NAME: ioat_dma_mgr
 * INTEFACE FILE: ../if/ioat_dma_mgr.if
 * INTERFACE DESCRIPTION: IOAT DMA manager interface
 * 
 * This file is distributed under the terms in the attached LICENSE
 * file. If you do not find this file, copies can be found by
 * writing to:
 * ETH Zurich D-INFK, Universitaetstr.6, CH-8092 Zurich.
 * Attn: Systems Group.
 * 
 * THIS FILE IS AUTOMATICALLY GENERATED BY FLOUNDER: DO NOT EDIT!
 */

#include <flounder/flounder.h>

/*
 * Concrete type definitions
 */
typedef uint64_t ioat_dma_mgr_genpaddr_t;
typedef uint64_t ioat_dma_mgr_genvaddr_t;
typedef uint32_t ioat_dma_mgr_rsrcid_t;
typedef uint64_t ioat_dma_mgr_errval_t;
typedef uint64_t ioat_dma_mgr_cycles_t;
typedef uint32_t ioat_dma_mgr_iref_t;
typedef uint8_t ioat_dma_mgr_coreid_t;
typedef uint32_t ioat_dma_mgr_domainid_t;

/*
 * Forward declaration of binding type
 */
struct ioat_dma_mgr_binding;

/*
 * Contination (callback) and control function types
 */
typedef  void ioat_dma_mgr_bind_continuation_fn(void *st, errval_t err, struct ioat_dma_mgr_binding *_binding);
typedef  bool ioat_dma_mgr_can_send_fn(struct ioat_dma_mgr_binding *_binding);
typedef  errval_t ioat_dma_mgr_register_send_fn(struct ioat_dma_mgr_binding *_binding, struct waitset *ws, struct event_closure _continuation);
typedef  errval_t ioat_dma_mgr_change_waitset_fn(struct ioat_dma_mgr_binding *_binding, struct waitset *ws);
typedef  errval_t ioat_dma_mgr_control_fn(struct ioat_dma_mgr_binding *_binding, idc_control_t control);
typedef  void ioat_dma_mgr_error_handler_fn(struct ioat_dma_mgr_binding *_binding, errval_t err);

/*
 * Enumeration for message numbers
 */
typedef enum ioat_dma_mgr_msg_enum {
    ioat_dma_mgr___dummy__msgnum = 0,
    ioat_dma_mgr___bind__msgnum = 1,
    ioat_dma_mgr___bind_reply__msgnum = 2,
    ioat_dma_mgr_request_call__msgnum = 3,
    ioat_dma_mgr_request_response__msgnum = 4,
    ioat_dma_mgr_release_call__msgnum = 5,
    ioat_dma_mgr_release_response__msgnum = 6
} ioat_dma_mgr_msg_enum;

/*
 * Message type signatures (transmit)
 */
typedef  errval_t ioat_dma_mgr_request_call__tx_method_fn(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation);
typedef  errval_t ioat_dma_mgr_request_response__tx_method_fn(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation, uint8_t devid, struct capref device_frame);
typedef  errval_t ioat_dma_mgr_release_call__tx_method_fn(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation, uint8_t devid);
typedef  errval_t ioat_dma_mgr_release_response__tx_method_fn(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation);

/*
 * Message type signatures (receive)
 */
typedef  void ioat_dma_mgr_request_call__rx_method_fn(struct ioat_dma_mgr_binding *_binding);
typedef  void ioat_dma_mgr_request_response__rx_method_fn(struct ioat_dma_mgr_binding *_binding, uint8_t devid, struct capref device_frame);
typedef  void ioat_dma_mgr_release_call__rx_method_fn(struct ioat_dma_mgr_binding *_binding, uint8_t devid);
typedef  void ioat_dma_mgr_release_response__rx_method_fn(struct ioat_dma_mgr_binding *_binding);

/*
 * Struct type for holding the args for each msg
 */
struct ioat_dma_mgr_request_response__args {
    uint8_t devid;
    struct capref device_frame;
};
struct ioat_dma_mgr_release_call__args {
    uint8_t devid;
};

/*
 * Union type for all message arguments
 */
union ioat_dma_mgr_arg_union {
    struct ioat_dma_mgr_request_response__args request_response;
    struct ioat_dma_mgr_release_call__args release_call;
};

/*
 * VTable struct definition for the interface (transmit)
 */
struct ioat_dma_mgr_tx_vtbl {
    ioat_dma_mgr_request_call__tx_method_fn *request_call;
    ioat_dma_mgr_request_response__tx_method_fn *request_response;
    ioat_dma_mgr_release_call__tx_method_fn *release_call;
    ioat_dma_mgr_release_response__tx_method_fn *release_response;
};

/*
 * VTable struct definition for the interface (receive)
 */
struct ioat_dma_mgr_rx_vtbl {
    ioat_dma_mgr_request_call__rx_method_fn *request_call;
    ioat_dma_mgr_request_response__rx_method_fn *request_response;
    ioat_dma_mgr_release_call__rx_method_fn *release_call;
    ioat_dma_mgr_release_response__rx_method_fn *release_response;
};

/*
 * Incoming connect callback type
 */
typedef  errval_t ioat_dma_mgr_connect_fn(void *st, struct ioat_dma_mgr_binding *binding);

/*
 * Export state struct
 */
struct ioat_dma_mgr_export {
    struct idc_export common;
    ioat_dma_mgr_connect_fn *connect_cb;
    struct waitset *waitset;
    void *st;
};

/*
 * Export function
 */
extern  errval_t ioat_dma_mgr_export(void *st, idc_export_callback_fn *export_cb, ioat_dma_mgr_connect_fn *connect_cb, struct waitset *ws, idc_export_flags_t flags);

/*
 * The message buffer structure (for accept/connect)
 */
struct ioat_dma_mgr_frameinfo {
    /* Physical address of send buffer */
    lpaddr_t sendbase;
    
    /* Pointer to incoming message buffer */
    void *inbuf;
    
    /* Size of the incoming buffer in bytes */
    size_t inbufsize;
    
    /* Pointer to outgoing message buffer */
    void *outbuf;
    
    /* Size of the outgoing buffer in bytes */
    size_t outbufsize;
    
};

/*
 * Accept function over already shared frame
 */
extern  errval_t ioat_dma_mgr_accept(struct ioat_dma_mgr_frameinfo *_frameinfo, void *st, ioat_dma_mgr_bind_continuation_fn *_continuation, struct waitset *ws, idc_export_flags_t flags);

/*
 * The Binding structure
 */
struct ioat_dma_mgr_binding {
    /* Arbitrary user state pointer */
    void *st;
    
    /* Waitset used for receive handlers and send continuations */
    struct waitset *waitset;
    
    /* Mutex for the use of user code. */
    /* Must be held before any operation where there is a possibility of */
    /* concurrent access to the same binding (eg. multiple threads, or */
    /* asynchronous event handlers that use the same binding object). */
    struct event_mutex mutex;
    
    /* returns true iff a message could currently be accepted by the binding */
    ioat_dma_mgr_can_send_fn *can_send;
    
    /* register an event for when a message is likely to be able to be sent */
    ioat_dma_mgr_register_send_fn *register_send;
    
    /* change the waitset used by a binding */
    ioat_dma_mgr_change_waitset_fn *change_waitset;
    
    /* perform control operations */
    ioat_dma_mgr_control_fn *control;
    
    /* error handler for any async errors associated with this binding */
    /* must be filled-in by user */
    ioat_dma_mgr_error_handler_fn *error_handler;
    
    /* Message send functions (filled in by binding) */
    struct ioat_dma_mgr_tx_vtbl tx_vtbl;
    
    /* Incoming message handlers (filled in by user) */
    struct ioat_dma_mgr_rx_vtbl rx_vtbl;
    
    /* Private state belonging to the binding implementation */
    union ioat_dma_mgr_arg_union tx_union;
    union ioat_dma_mgr_arg_union rx_union;
    struct waitset_chanstate register_chanstate;
    struct waitset_chanstate tx_cont_chanstate;
    enum ioat_dma_mgr_msg_enum tx_msgnum;
    enum ioat_dma_mgr_msg_enum rx_msgnum;
    int tx_msg_fragment;
    int rx_msg_fragment;
    size_t tx_str_pos;
    size_t rx_str_pos;
    size_t tx_str_len;
    size_t rx_str_len;
    struct event_queue_node event_qnode;
    ioat_dma_mgr_bind_continuation_fn *bind_cont;
};

/*
 * Generic bind function
 */
extern  errval_t ioat_dma_mgr_bind(iref_t i, ioat_dma_mgr_bind_continuation_fn *_continuation, void *st, struct waitset *waitset, idc_bind_flags_t flags);

/*
 * Generic connect function over already shared frame
 */
extern  errval_t ioat_dma_mgr_connect(struct ioat_dma_mgr_frameinfo *_frameinfo, ioat_dma_mgr_bind_continuation_fn *_continuation, void *st, struct waitset *ws, idc_bind_flags_t flags);

/*
 * Send wrappers
 */
static inline errval_t ioat_dma_mgr_request_call__tx(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation) __attribute__ ((always_inline));
static inline errval_t ioat_dma_mgr_request_call__tx(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation)
{
    return(((_binding->tx_vtbl).request_call)(_binding, _continuation));
}

static inline errval_t ioat_dma_mgr_request_response__tx(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation, uint8_t devid, struct capref device_frame) __attribute__ ((always_inline));
static inline errval_t ioat_dma_mgr_request_response__tx(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation, uint8_t devid, struct capref device_frame)
{
    return(((_binding->tx_vtbl).request_response)(_binding, _continuation, devid, device_frame));
}

static inline errval_t ioat_dma_mgr_release_call__tx(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation, uint8_t devid) __attribute__ ((always_inline));
static inline errval_t ioat_dma_mgr_release_call__tx(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation, uint8_t devid)
{
    return(((_binding->tx_vtbl).release_call)(_binding, _continuation, devid));
}

static inline errval_t ioat_dma_mgr_release_response__tx(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation) __attribute__ ((always_inline));
static inline errval_t ioat_dma_mgr_release_response__tx(struct ioat_dma_mgr_binding *_binding, struct event_closure _continuation)
{
    return(((_binding->tx_vtbl).release_response)(_binding, _continuation));
}


/*
 * Backend-specific includes
 */
#ifdef CONFIG_FLOUNDER_BACKEND_LMP
#include <if/ioat_dma_mgr_lmp_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_LMP
#ifdef CONFIG_FLOUNDER_BACKEND_UMP
#include <if/ioat_dma_mgr_ump_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_UMP
#ifdef CONFIG_FLOUNDER_BACKEND_UMP_IPI
#include <if/ioat_dma_mgr_ump_ipi_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_UMP_IPI
#ifdef CONFIG_FLOUNDER_BACKEND_MULTIHOP
#include <if/ioat_dma_mgr_multihop_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_MULTIHOP
/*
 * And we're done
 */
#endif // __ioat_dma_mgr_IF_H
