#ifndef __xcorecapbench_IF_H
#define __xcorecapbench_IF_H 1
/*
 * Copyright (c) 2010, ETH Zurich.
 * All rights reserved.
 * 
 * INTERFACE NAME: xcorecapbench
 * INTEFACE FILE: ../if/xcorecapbench.if
 * INTERFACE DESCRIPTION: Cross core capability benchmark interface
 * 
 * This file is distributed under the terms in the attached LICENSE
 * file. If you do not find this file, copies can be found by
 * writing to:
 * ETH Zurich D-INFK, Universitaetstr.6, CH-8092 Zurich.
 * Attn: Systems Group.
 * 
 * THIS FILE IS AUTOMATICALLY GENERATED BY FLOUNDER: DO NOT EDIT!
 */

#include <flounder/flounder.h>

/*
 * Concrete type definitions
 */
typedef uint64_t xcorecapbench_genpaddr_t;
typedef uint64_t xcorecapbench_genvaddr_t;
typedef uint32_t xcorecapbench_rsrcid_t;
typedef uint64_t xcorecapbench_errval_t;
typedef uint64_t xcorecapbench_cycles_t;
typedef uint32_t xcorecapbench_iref_t;
typedef uint8_t xcorecapbench_coreid_t;
typedef uint32_t xcorecapbench_domainid_t;

/*
 * Forward declaration of binding type
 */
struct xcorecapbench_binding;

/*
 * Contination (callback) and control function types
 */
typedef  void xcorecapbench_bind_continuation_fn(void *st, errval_t err, struct xcorecapbench_binding *_binding);
typedef  bool xcorecapbench_can_send_fn(struct xcorecapbench_binding *_binding);
typedef  errval_t xcorecapbench_register_send_fn(struct xcorecapbench_binding *_binding, struct waitset *ws, struct event_closure _continuation);
typedef  errval_t xcorecapbench_change_waitset_fn(struct xcorecapbench_binding *_binding, struct waitset *ws);
typedef  errval_t xcorecapbench_control_fn(struct xcorecapbench_binding *_binding, idc_control_t control);
typedef  void xcorecapbench_error_handler_fn(struct xcorecapbench_binding *_binding, errval_t err);

/*
 * Enumeration for message numbers
 */
typedef enum xcorecapbench_msg_enum {
    xcorecapbench___dummy__msgnum = 0,
    xcorecapbench___bind__msgnum = 1,
    xcorecapbench___bind_reply__msgnum = 2,
    xcorecapbench_connect__msgnum = 3,
    xcorecapbench_start_sending__msgnum = 4,
    xcorecapbench_start_retyping__msgnum = 5,
    xcorecapbench_send_cap__msgnum = 6,
    xcorecapbench_barrier_done__msgnum = 7
} xcorecapbench_msg_enum;

/*
 * Message type signatures (transmit)
 */
typedef  errval_t xcorecapbench_connect__tx_method_fn(struct xcorecapbench_binding *_binding, struct event_closure _continuation);
typedef  errval_t xcorecapbench_start_sending__tx_method_fn(struct xcorecapbench_binding *_binding, struct event_closure _continuation);
typedef  errval_t xcorecapbench_start_retyping__tx_method_fn(struct xcorecapbench_binding *_binding, struct event_closure _continuation);
typedef  errval_t xcorecapbench_send_cap__tx_method_fn(struct xcorecapbench_binding *_binding, struct event_closure _continuation, struct capref cap);
typedef  errval_t xcorecapbench_barrier_done__tx_method_fn(struct xcorecapbench_binding *_binding, struct event_closure _continuation, uint64_t cycles);

/*
 * Message type signatures (receive)
 */
typedef  void xcorecapbench_connect__rx_method_fn(struct xcorecapbench_binding *_binding);
typedef  void xcorecapbench_start_sending__rx_method_fn(struct xcorecapbench_binding *_binding);
typedef  void xcorecapbench_start_retyping__rx_method_fn(struct xcorecapbench_binding *_binding);
typedef  void xcorecapbench_send_cap__rx_method_fn(struct xcorecapbench_binding *_binding, struct capref cap);
typedef  void xcorecapbench_barrier_done__rx_method_fn(struct xcorecapbench_binding *_binding, uint64_t cycles);

/*
 * Struct type for holding the args for each msg
 */
struct xcorecapbench_send_cap__args {
    struct capref cap;
};
struct xcorecapbench_barrier_done__args {
    uint64_t cycles;
};

/*
 * Union type for all message arguments
 */
union xcorecapbench_arg_union {
    struct xcorecapbench_send_cap__args send_cap;
    struct xcorecapbench_barrier_done__args barrier_done;
};

/*
 * VTable struct definition for the interface (transmit)
 */
struct xcorecapbench_tx_vtbl {
    xcorecapbench_connect__tx_method_fn *connect;
    xcorecapbench_start_sending__tx_method_fn *start_sending;
    xcorecapbench_start_retyping__tx_method_fn *start_retyping;
    xcorecapbench_send_cap__tx_method_fn *send_cap;
    xcorecapbench_barrier_done__tx_method_fn *barrier_done;
};

/*
 * VTable struct definition for the interface (receive)
 */
struct xcorecapbench_rx_vtbl {
    xcorecapbench_connect__rx_method_fn *connect;
    xcorecapbench_start_sending__rx_method_fn *start_sending;
    xcorecapbench_start_retyping__rx_method_fn *start_retyping;
    xcorecapbench_send_cap__rx_method_fn *send_cap;
    xcorecapbench_barrier_done__rx_method_fn *barrier_done;
};

/*
 * Incoming connect callback type
 */
typedef  errval_t xcorecapbench_connect_fn(void *st, struct xcorecapbench_binding *binding);

/*
 * Export state struct
 */
struct xcorecapbench_export {
    struct idc_export common;
    xcorecapbench_connect_fn *connect_cb;
    struct waitset *waitset;
    void *st;
};

/*
 * Export function
 */
extern  errval_t xcorecapbench_export(void *st, idc_export_callback_fn *export_cb, xcorecapbench_connect_fn *connect_cb, struct waitset *ws, idc_export_flags_t flags);

/*
 * The message buffer structure (for accept/connect)
 */
struct xcorecapbench_frameinfo {
    /* Physical address of send buffer */
    lpaddr_t sendbase;
    
    /* Pointer to incoming message buffer */
    void *inbuf;
    
    /* Size of the incoming buffer in bytes */
    size_t inbufsize;
    
    /* Pointer to outgoing message buffer */
    void *outbuf;
    
    /* Size of the outgoing buffer in bytes */
    size_t outbufsize;
    
};

/*
 * Accept function over already shared frame
 */
extern  errval_t xcorecapbench_accept(struct xcorecapbench_frameinfo *_frameinfo, void *st, xcorecapbench_bind_continuation_fn *_continuation, struct waitset *ws, idc_export_flags_t flags);

/*
 * The Binding structure
 */
struct xcorecapbench_binding {
    /* Arbitrary user state pointer */
    void *st;
    
    /* Waitset used for receive handlers and send continuations */
    struct waitset *waitset;
    
    /* Mutex for the use of user code. */
    /* Must be held before any operation where there is a possibility of */
    /* concurrent access to the same binding (eg. multiple threads, or */
    /* asynchronous event handlers that use the same binding object). */
    struct event_mutex mutex;
    
    /* returns true iff a message could currently be accepted by the binding */
    xcorecapbench_can_send_fn *can_send;
    
    /* register an event for when a message is likely to be able to be sent */
    xcorecapbench_register_send_fn *register_send;
    
    /* change the waitset used by a binding */
    xcorecapbench_change_waitset_fn *change_waitset;
    
    /* perform control operations */
    xcorecapbench_control_fn *control;
    
    /* error handler for any async errors associated with this binding */
    /* must be filled-in by user */
    xcorecapbench_error_handler_fn *error_handler;
    
    /* Message send functions (filled in by binding) */
    struct xcorecapbench_tx_vtbl tx_vtbl;
    
    /* Incoming message handlers (filled in by user) */
    struct xcorecapbench_rx_vtbl rx_vtbl;
    
    /* Private state belonging to the binding implementation */
    union xcorecapbench_arg_union tx_union;
    union xcorecapbench_arg_union rx_union;
    struct waitset_chanstate register_chanstate;
    struct waitset_chanstate tx_cont_chanstate;
    enum xcorecapbench_msg_enum tx_msgnum;
    enum xcorecapbench_msg_enum rx_msgnum;
    int tx_msg_fragment;
    int rx_msg_fragment;
    size_t tx_str_pos;
    size_t rx_str_pos;
    size_t tx_str_len;
    size_t rx_str_len;
    struct event_queue_node event_qnode;
    xcorecapbench_bind_continuation_fn *bind_cont;
};

/*
 * Generic bind function
 */
extern  errval_t xcorecapbench_bind(iref_t i, xcorecapbench_bind_continuation_fn *_continuation, void *st, struct waitset *waitset, idc_bind_flags_t flags);

/*
 * Generic connect function over already shared frame
 */
extern  errval_t xcorecapbench_connect(struct xcorecapbench_frameinfo *_frameinfo, xcorecapbench_bind_continuation_fn *_continuation, void *st, struct waitset *ws, idc_bind_flags_t flags);

/*
 * Send wrappers
 */
static inline errval_t xcorecapbench_connect__tx(struct xcorecapbench_binding *_binding, struct event_closure _continuation) __attribute__ ((always_inline));
static inline errval_t xcorecapbench_connect__tx(struct xcorecapbench_binding *_binding, struct event_closure _continuation)
{
    return(((_binding->tx_vtbl).connect)(_binding, _continuation));
}

static inline errval_t xcorecapbench_start_sending__tx(struct xcorecapbench_binding *_binding, struct event_closure _continuation) __attribute__ ((always_inline));
static inline errval_t xcorecapbench_start_sending__tx(struct xcorecapbench_binding *_binding, struct event_closure _continuation)
{
    return(((_binding->tx_vtbl).start_sending)(_binding, _continuation));
}

static inline errval_t xcorecapbench_start_retyping__tx(struct xcorecapbench_binding *_binding, struct event_closure _continuation) __attribute__ ((always_inline));
static inline errval_t xcorecapbench_start_retyping__tx(struct xcorecapbench_binding *_binding, struct event_closure _continuation)
{
    return(((_binding->tx_vtbl).start_retyping)(_binding, _continuation));
}

static inline errval_t xcorecapbench_send_cap__tx(struct xcorecapbench_binding *_binding, struct event_closure _continuation, struct capref cap) __attribute__ ((always_inline));
static inline errval_t xcorecapbench_send_cap__tx(struct xcorecapbench_binding *_binding, struct event_closure _continuation, struct capref cap)
{
    return(((_binding->tx_vtbl).send_cap)(_binding, _continuation, cap));
}

static inline errval_t xcorecapbench_barrier_done__tx(struct xcorecapbench_binding *_binding, struct event_closure _continuation, uint64_t cycles) __attribute__ ((always_inline));
static inline errval_t xcorecapbench_barrier_done__tx(struct xcorecapbench_binding *_binding, struct event_closure _continuation, uint64_t cycles)
{
    return(((_binding->tx_vtbl).barrier_done)(_binding, _continuation, cycles));
}


/*
 * Backend-specific includes
 */
#ifdef CONFIG_FLOUNDER_BACKEND_LMP
#include <if/xcorecapbench_lmp_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_LMP
#ifdef CONFIG_FLOUNDER_BACKEND_UMP
#include <if/xcorecapbench_ump_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_UMP
#ifdef CONFIG_FLOUNDER_BACKEND_UMP_IPI
#include <if/xcorecapbench_ump_ipi_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_UMP_IPI
#ifdef CONFIG_FLOUNDER_BACKEND_MULTIHOP
#include <if/xcorecapbench_multihop_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_MULTIHOP
/*
 * And we're done
 */
#endif // __xcorecapbench_IF_H
