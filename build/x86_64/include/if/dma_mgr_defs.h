#ifndef __dma_mgr_IF_H
#define __dma_mgr_IF_H 1
/*
 * Copyright (c) 2010, ETH Zurich.
 * All rights reserved.
 * 
 * INTERFACE NAME: dma_mgr
 * INTEFACE FILE: ../if/dma_mgr.if
 * INTERFACE DESCRIPTION: DMA Manager Interface
 * 
 * This file is distributed under the terms in the attached LICENSE
 * file. If you do not find this file, copies can be found by
 * writing to:
 * ETH Zurich D-INFK, Universitaetstr.6, CH-8092 Zurich.
 * Attn: Systems Group.
 * 
 * THIS FILE IS AUTOMATICALLY GENERATED BY FLOUNDER: DO NOT EDIT!
 */

#include <flounder/flounder.h>

/*
 * Concrete type definitions
 */
typedef uint64_t dma_mgr_genpaddr_t;
typedef uint64_t dma_mgr_genvaddr_t;
typedef uint32_t dma_mgr_rsrcid_t;
typedef uint64_t dma_mgr_errval_t;
typedef uint64_t dma_mgr_cycles_t;
typedef uint32_t dma_mgr_iref_t;
typedef uint8_t dma_mgr_coreid_t;
typedef uint32_t dma_mgr_domainid_t;

/*
 * Forward declaration of binding type
 */
struct dma_mgr_binding;

/*
 * Contination (callback) and control function types
 */
typedef  void dma_mgr_bind_continuation_fn(void *st, errval_t err, struct dma_mgr_binding *_binding);
typedef  bool dma_mgr_can_send_fn(struct dma_mgr_binding *_binding);
typedef  errval_t dma_mgr_register_send_fn(struct dma_mgr_binding *_binding, struct waitset *ws, struct event_closure _continuation);
typedef  errval_t dma_mgr_change_waitset_fn(struct dma_mgr_binding *_binding, struct waitset *ws);
typedef  errval_t dma_mgr_control_fn(struct dma_mgr_binding *_binding, idc_control_t control);
typedef  void dma_mgr_error_handler_fn(struct dma_mgr_binding *_binding, errval_t err);

/*
 * Enumeration for message numbers
 */
typedef enum dma_mgr_msg_enum {
    dma_mgr___dummy__msgnum = 0,
    dma_mgr___bind__msgnum = 1,
    dma_mgr___bind_reply__msgnum = 2,
    dma_mgr_register_driver_call__msgnum = 3,
    dma_mgr_register_driver_response__msgnum = 4,
    dma_mgr_lookup_driver_call__msgnum = 5,
    dma_mgr_lookup_driver_response__msgnum = 6,
    dma_mgr_lookup_driver_by_iref_call__msgnum = 7,
    dma_mgr_lookup_driver_by_iref_response__msgnum = 8
} dma_mgr_msg_enum;

/*
 * Message type signatures (transmit)
 */
typedef  errval_t dma_mgr_register_driver_call__tx_method_fn(struct dma_mgr_binding *_binding, struct event_closure _continuation, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type, iref_t svc_iref);
typedef  errval_t dma_mgr_register_driver_response__tx_method_fn(struct dma_mgr_binding *_binding, struct event_closure _continuation, dma_mgr_errval_t msgerr);
typedef  errval_t dma_mgr_lookup_driver_call__tx_method_fn(struct dma_mgr_binding *_binding, struct event_closure _continuation, uint64_t base, uint64_t size, uint8_t numa);
typedef  errval_t dma_mgr_lookup_driver_response__tx_method_fn(struct dma_mgr_binding *_binding, struct event_closure _continuation, dma_mgr_errval_t msgerr, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type, iref_t svc_iref);
typedef  errval_t dma_mgr_lookup_driver_by_iref_call__tx_method_fn(struct dma_mgr_binding *_binding, struct event_closure _continuation, iref_t iref);
typedef  errval_t dma_mgr_lookup_driver_by_iref_response__tx_method_fn(struct dma_mgr_binding *_binding, struct event_closure _continuation, dma_mgr_errval_t msgerr, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type);

/*
 * Message type signatures (receive)
 */
typedef  void dma_mgr_register_driver_call__rx_method_fn(struct dma_mgr_binding *_binding, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type, iref_t svc_iref);
typedef  void dma_mgr_register_driver_response__rx_method_fn(struct dma_mgr_binding *_binding, dma_mgr_errval_t msgerr);
typedef  void dma_mgr_lookup_driver_call__rx_method_fn(struct dma_mgr_binding *_binding, uint64_t base, uint64_t size, uint8_t numa);
typedef  void dma_mgr_lookup_driver_response__rx_method_fn(struct dma_mgr_binding *_binding, dma_mgr_errval_t msgerr, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type, iref_t svc_iref);
typedef  void dma_mgr_lookup_driver_by_iref_call__rx_method_fn(struct dma_mgr_binding *_binding, iref_t iref);
typedef  void dma_mgr_lookup_driver_by_iref_response__rx_method_fn(struct dma_mgr_binding *_binding, dma_mgr_errval_t msgerr, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type);

/*
 * Struct type for holding the args for each msg
 */
struct dma_mgr_register_driver_call__args {
    uint64_t mem_low;
    uint64_t mem_high;
    uint8_t numa_node;
    uint8_t type;
    iref_t svc_iref;
};
struct dma_mgr_register_driver_response__args {
    dma_mgr_errval_t msgerr;
};
struct dma_mgr_lookup_driver_call__args {
    uint64_t base;
    uint64_t size;
    uint8_t numa;
};
struct dma_mgr_lookup_driver_response__args {
    dma_mgr_errval_t msgerr;
    uint64_t mem_low;
    uint64_t mem_high;
    uint8_t numa_node;
    uint8_t type;
    iref_t svc_iref;
};
struct dma_mgr_lookup_driver_by_iref_call__args {
    iref_t iref;
};
struct dma_mgr_lookup_driver_by_iref_response__args {
    dma_mgr_errval_t msgerr;
    uint64_t mem_low;
    uint64_t mem_high;
    uint8_t numa_node;
    uint8_t type;
};

/*
 * Union type for all message arguments
 */
union dma_mgr_arg_union {
    struct dma_mgr_register_driver_call__args register_driver_call;
    struct dma_mgr_register_driver_response__args register_driver_response;
    struct dma_mgr_lookup_driver_call__args lookup_driver_call;
    struct dma_mgr_lookup_driver_response__args lookup_driver_response;
    struct dma_mgr_lookup_driver_by_iref_call__args lookup_driver_by_iref_call;
    struct dma_mgr_lookup_driver_by_iref_response__args lookup_driver_by_iref_response;
};

/*
 * VTable struct definition for the interface (transmit)
 */
struct dma_mgr_tx_vtbl {
    dma_mgr_register_driver_call__tx_method_fn *register_driver_call;
    dma_mgr_register_driver_response__tx_method_fn *register_driver_response;
    dma_mgr_lookup_driver_call__tx_method_fn *lookup_driver_call;
    dma_mgr_lookup_driver_response__tx_method_fn *lookup_driver_response;
    dma_mgr_lookup_driver_by_iref_call__tx_method_fn *lookup_driver_by_iref_call;
    dma_mgr_lookup_driver_by_iref_response__tx_method_fn *lookup_driver_by_iref_response;
};

/*
 * VTable struct definition for the interface (receive)
 */
struct dma_mgr_rx_vtbl {
    dma_mgr_register_driver_call__rx_method_fn *register_driver_call;
    dma_mgr_register_driver_response__rx_method_fn *register_driver_response;
    dma_mgr_lookup_driver_call__rx_method_fn *lookup_driver_call;
    dma_mgr_lookup_driver_response__rx_method_fn *lookup_driver_response;
    dma_mgr_lookup_driver_by_iref_call__rx_method_fn *lookup_driver_by_iref_call;
    dma_mgr_lookup_driver_by_iref_response__rx_method_fn *lookup_driver_by_iref_response;
};

/*
 * Incoming connect callback type
 */
typedef  errval_t dma_mgr_connect_fn(void *st, struct dma_mgr_binding *binding);

/*
 * Export state struct
 */
struct dma_mgr_export {
    struct idc_export common;
    dma_mgr_connect_fn *connect_cb;
    struct waitset *waitset;
    void *st;
};

/*
 * Export function
 */
extern  errval_t dma_mgr_export(void *st, idc_export_callback_fn *export_cb, dma_mgr_connect_fn *connect_cb, struct waitset *ws, idc_export_flags_t flags);

/*
 * The message buffer structure (for accept/connect)
 */
struct dma_mgr_frameinfo {
    /* Physical address of send buffer */
    lpaddr_t sendbase;
    
    /* Pointer to incoming message buffer */
    void *inbuf;
    
    /* Size of the incoming buffer in bytes */
    size_t inbufsize;
    
    /* Pointer to outgoing message buffer */
    void *outbuf;
    
    /* Size of the outgoing buffer in bytes */
    size_t outbufsize;
    
};

/*
 * Accept function over already shared frame
 */
extern  errval_t dma_mgr_accept(struct dma_mgr_frameinfo *_frameinfo, void *st, dma_mgr_bind_continuation_fn *_continuation, struct waitset *ws, idc_export_flags_t flags);

/*
 * The Binding structure
 */
struct dma_mgr_binding {
    /* Arbitrary user state pointer */
    void *st;
    
    /* Waitset used for receive handlers and send continuations */
    struct waitset *waitset;
    
    /* Mutex for the use of user code. */
    /* Must be held before any operation where there is a possibility of */
    /* concurrent access to the same binding (eg. multiple threads, or */
    /* asynchronous event handlers that use the same binding object). */
    struct event_mutex mutex;
    
    /* returns true iff a message could currently be accepted by the binding */
    dma_mgr_can_send_fn *can_send;
    
    /* register an event for when a message is likely to be able to be sent */
    dma_mgr_register_send_fn *register_send;
    
    /* change the waitset used by a binding */
    dma_mgr_change_waitset_fn *change_waitset;
    
    /* perform control operations */
    dma_mgr_control_fn *control;
    
    /* error handler for any async errors associated with this binding */
    /* must be filled-in by user */
    dma_mgr_error_handler_fn *error_handler;
    
    /* Message send functions (filled in by binding) */
    struct dma_mgr_tx_vtbl tx_vtbl;
    
    /* Incoming message handlers (filled in by user) */
    struct dma_mgr_rx_vtbl rx_vtbl;
    
    /* Private state belonging to the binding implementation */
    union dma_mgr_arg_union tx_union;
    union dma_mgr_arg_union rx_union;
    struct waitset_chanstate register_chanstate;
    struct waitset_chanstate tx_cont_chanstate;
    enum dma_mgr_msg_enum tx_msgnum;
    enum dma_mgr_msg_enum rx_msgnum;
    int tx_msg_fragment;
    int rx_msg_fragment;
    size_t tx_str_pos;
    size_t rx_str_pos;
    size_t tx_str_len;
    size_t rx_str_len;
    struct event_queue_node event_qnode;
    dma_mgr_bind_continuation_fn *bind_cont;
};

/*
 * Generic bind function
 */
extern  errval_t dma_mgr_bind(iref_t i, dma_mgr_bind_continuation_fn *_continuation, void *st, struct waitset *waitset, idc_bind_flags_t flags);

/*
 * Generic connect function over already shared frame
 */
extern  errval_t dma_mgr_connect(struct dma_mgr_frameinfo *_frameinfo, dma_mgr_bind_continuation_fn *_continuation, void *st, struct waitset *ws, idc_bind_flags_t flags);

/*
 * Send wrappers
 */
static inline errval_t dma_mgr_register_driver_call__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type, iref_t svc_iref) __attribute__ ((always_inline));
static inline errval_t dma_mgr_register_driver_call__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type, iref_t svc_iref)
{
    return(((_binding->tx_vtbl).register_driver_call)(_binding, _continuation, mem_low, mem_high, numa_node, type, svc_iref));
}

static inline errval_t dma_mgr_register_driver_response__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, dma_mgr_errval_t msgerr) __attribute__ ((always_inline));
static inline errval_t dma_mgr_register_driver_response__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, dma_mgr_errval_t msgerr)
{
    return(((_binding->tx_vtbl).register_driver_response)(_binding, _continuation, msgerr));
}

static inline errval_t dma_mgr_lookup_driver_call__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, uint64_t base, uint64_t size, uint8_t numa) __attribute__ ((always_inline));
static inline errval_t dma_mgr_lookup_driver_call__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, uint64_t base, uint64_t size, uint8_t numa)
{
    return(((_binding->tx_vtbl).lookup_driver_call)(_binding, _continuation, base, size, numa));
}

static inline errval_t dma_mgr_lookup_driver_response__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, dma_mgr_errval_t msgerr, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type, iref_t svc_iref) __attribute__ ((always_inline));
static inline errval_t dma_mgr_lookup_driver_response__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, dma_mgr_errval_t msgerr, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type, iref_t svc_iref)
{
    return(((_binding->tx_vtbl).lookup_driver_response)(_binding, _continuation, msgerr, mem_low, mem_high, numa_node, type, svc_iref));
}

static inline errval_t dma_mgr_lookup_driver_by_iref_call__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, iref_t iref) __attribute__ ((always_inline));
static inline errval_t dma_mgr_lookup_driver_by_iref_call__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, iref_t iref)
{
    return(((_binding->tx_vtbl).lookup_driver_by_iref_call)(_binding, _continuation, iref));
}

static inline errval_t dma_mgr_lookup_driver_by_iref_response__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, dma_mgr_errval_t msgerr, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type) __attribute__ ((always_inline));
static inline errval_t dma_mgr_lookup_driver_by_iref_response__tx(struct dma_mgr_binding *_binding, struct event_closure _continuation, dma_mgr_errval_t msgerr, uint64_t mem_low, uint64_t mem_high, uint8_t numa_node, uint8_t type)
{
    return(((_binding->tx_vtbl).lookup_driver_by_iref_response)(_binding, _continuation, msgerr, mem_low, mem_high, numa_node, type));
}


/*
 * Backend-specific includes
 */
#ifdef CONFIG_FLOUNDER_BACKEND_LMP
#include <if/dma_mgr_lmp_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_LMP
#ifdef CONFIG_FLOUNDER_BACKEND_UMP
#include <if/dma_mgr_ump_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_UMP
#ifdef CONFIG_FLOUNDER_BACKEND_UMP_IPI
#include <if/dma_mgr_ump_ipi_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_UMP_IPI
#ifdef CONFIG_FLOUNDER_BACKEND_MULTIHOP
#include <if/dma_mgr_multihop_defs.h>
#endif // CONFIG_FLOUNDER_BACKEND_MULTIHOP
/*
 * And we're done
 */
#endif // __dma_mgr_IF_H
